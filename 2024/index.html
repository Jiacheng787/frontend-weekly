<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-list-page plugin-blog plugin-id-2024">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.3.1">
<title data-rh="true">Blog | Frontend Weekly</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/frontend-weekly/2024"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="Blog | Frontend Weekly"><meta data-rh="true" name="description" content="Blog"><meta data-rh="true" property="og:description" content="Blog"><meta data-rh="true" name="docusaurus_tag" content="blog_posts_list"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_posts_list"><link data-rh="true" rel="icon" href="/frontend-weekly/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/frontend-weekly/2024"><link data-rh="true" rel="alternate" href="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/frontend-weekly/2024" hreflang="en"><link data-rh="true" rel="alternate" href="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/frontend-weekly/2024" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/frontend-weekly/2024/rss.xml" title="Frontend Weekly RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/frontend-weekly/2024/atom.xml" title="Frontend Weekly Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/frontend-weekly/2023/rss.xml" title="Frontend Weekly RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/frontend-weekly/2023/atom.xml" title="Frontend Weekly Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/frontend-weekly/2022/rss.xml" title="Frontend Weekly RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/frontend-weekly/2022/atom.xml" title="Frontend Weekly Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/frontend-weekly/2021/rss.xml" title="Frontend Weekly RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/frontend-weekly/2021/atom.xml" title="Frontend Weekly Atom Feed"><link rel="stylesheet" href="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/css/styles.52862517.css">
<link rel="preload" href="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/js/runtime~main.14a8a14b.js" as="script">
<link rel="preload" href="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/js/main.90d1b645.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_Rzz1" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/frontend-weekly/"><div class="navbar__logo"><img src="/frontend-weekly/img/logo.svg" alt="My Site Logo" class="themedImage_DeRy themedImage--light_hbln"><img src="/frontend-weekly/img/logo.svg" alt="My Site Logo" class="themedImage_DeRy themedImage--dark_qgR1"></div><b class="navbar__title text--truncate">Frontend Weekly</b></a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a aria-current="page" class="navbar__link active" aria-haspopup="true" aria-expanded="false" role="button" href="/frontend-weekly/2024">Blog of 2024</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/frontend-weekly/2024">2024</a></li><li><a class="dropdown__link" href="/frontend-weekly/2023">2023</a></li><li><a class="dropdown__link" href="/frontend-weekly/2022">2022</a></li><li><a class="dropdown__link" href="/frontend-weekly/2021">2021</a></li></ul></div><a href="https://github.com/garfield-dev-team/frontend-weekly/tree/main/static/img/IMG_0058.JPG" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">⭐️ 前端交流群<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://github.com/garfield-dev-team/frontend-weekly" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_HPIb colorModeToggle_KItF"><button class="clean-btn toggleButton_yRlM toggleButtonDisabled_oHIz" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_Vljy"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_lcNQ"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_mmj0"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_NWrx"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_J5VD thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_ZkTY margin-bottom--md">All posts in 2024</div><ul class="sidebarItemList_Jaez clean-list"><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/welcome">置顶内容</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/7月14日内容汇总">7月14日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/7月7日内容汇总">7月7日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/6月30日内容汇总">6月30日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/6月23日内容汇总">6月23日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/6月16日内容汇总">6月16日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/6月9日内容汇总">6月9日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/6月2日内容汇总">6月2日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/5月26日内容汇总">5月26日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/5月19日内容汇总">5月19日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/5月12日内容汇总">5月12日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/5月5日内容汇总">5月5日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/4月28日内容汇总">4月28日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/4月21日内容汇总">4月21日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/4月14日内容汇总">4月14日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/4月7日内容汇总">4月7日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/3月31日内容汇总">3月31日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/3月24日内容汇总">3月24日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/3月17日内容汇总">3月17日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/3月10日内容汇总">3月10日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/3月3日内容汇总">3月3日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/2月25日内容汇总">2月25日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/2月18日内容汇总">2月18日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/2月11日内容汇总">2月11日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/2月4日内容汇总">2月4日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/1月28日内容汇总">1月28日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/1月21日内容汇总">1月21日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/1月14日内容汇总">1月14日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/1月7日内容汇总">1月7日内容汇总</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/welcome">置顶内容</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-12-12T00:00:00.000Z" itemprop="datePublished">December 12, 2024</time> · <!-- -->145 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>⭐️ 每周更新优质技术文章，欢迎点赞关注！</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_HAaO padding--none margin-left--sm"><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/type-script">TypeScript</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/前端框架">前端框架</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/webpack">Webpack</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/源码系列">源码系列</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/业务成长">业务成长</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/性能优化">性能优化</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/组件库实战">组件库实战</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/网络相关">网络相关</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/机器学习">机器学习</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/java">Java</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/golang">Golang</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about 置顶内容" href="/frontend-weekly/2024/welcome"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/7月14日内容汇总">7月14日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-07-14T00:00:00.000Z" itemprop="datePublished">July 14, 2024</time> · <!-- -->19 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/maxresdefault-ffb8f11e1c31c2d1464780924ffb5d89.jpg" width="1280" height="720" class="img_astN"></p><p>封面图：Safe by construction - Roberto Clapis</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><div class="theme-admonition theme-admonition-tip alert alert--success admonition_kCt_"><div class="admonitionHeading_oZsk"><span class="admonitionIcon_tnIl"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>技术资讯</div><div class="admonitionContent_m8BQ"><ul><li><a href="https://lilianweng.github.io/posts/2024-07-07-hallucination/" target="_blank" rel="noopener noreferrer">Extrinsic Hallucinations in LLMs</a></li><li><a href="https://twitter.com/qdrant_engine/status/1811451520698716262" target="_blank" rel="noopener noreferrer">Building Smarter Agents with @llama_index and Qdrant&#x27;s Hybrid Search 🦙🔍</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1811468293326205117" target="_blank" rel="noopener noreferrer">FlashAttention-3 is now available. 1.5-2.0x faster than FlashAttention-2 with FP16, up to 740 TFLOPS 🤯</a></li><li>Producthunt上个月的第一名产品。<a href="https://getrecall.ai" target="_blank" rel="noopener noreferrer">Recall</a>是一款帮助你总结和管理在线内容的工具。支持YouTube视频、文章、播客、PDF文件等总结摘要。自动分类并保存在个人知识库中，支持二次编辑。内容自动会生成知识卡片，通过知识图谱建立内容关联。另外，Recall用科学间隔重复和主动回忆方法复习，就是基于内容生成问答题，每天选择题复习。<a href="https://twitter.com/vista8/status/1811667592748368126" target="_blank" rel="noopener noreferrer">[<!-- -->1<!-- -->]</a></li><li>伯克利提出 《从模型到复合人工智能系统的转变》，而 @FireworksAI_HQ 最近融资 5.5 亿美金也是帮企业构建 Compound AI🔥，即：<a href="https://twitter.com/tuturetom/status/1811647025404088448" target="_blank" rel="noopener noreferrer">[<!-- -->2<!-- -->]</a><ul><li>组合框架和策略</li><li>使用 DSPy 等自动优化 Prompt 质量</li><li>使用 FrugalGPT 等实现 LLM 负载均衡以及意图路由</li><li>构建良好的 LLMOps/DataOps 系统</li></ul></li><li><a href="https://twitter.com/rohanpaul_ai/status/1811451148920062186" target="_blank" rel="noopener noreferrer">Reinforcement Learning from Human Feedback (RLHF) workflow and implementation with @MSFTDeepSpeed - A long thread 👇</a></li><li><a href="https://twitter.com/tuturetom/status/1811587747532231046" target="_blank" rel="noopener noreferrer">从任意非结构化数据构建知识图谱！@neo4j 正式开源 GraphRAG 的图谱构建工具 LLM Graph Builder！ 🔥</a></li><li><a href="https://twitter.com/llama_index/status/1811462543535464796" target="_blank" rel="noopener noreferrer">We’re excited to feature LlamaTrace - a collaborative effort with @arizeai to introduce advanced LLM tracing, observability, and evaluation for any LLM application workflows 🦙🔥</a></li><li><a href="https://twitter.com/tuturetom/status/1811585264864886879" target="_blank" rel="noopener noreferrer">GraphRAG 是 RAG 领域可以造就下一个 Google 的技术！随着最近微软开源 GraphRAG 并将其带上热点顶峰，Neo4j 接着就发布《GraphRAG 宣言》！🔥</a><ul><li>介绍了 GraphRAG 最全面的技术，包括学习教程，以及端到端的开源技术栈，同时 GraphRAG 在 43 个业务问题中准确性平均提高 3x ⚡️</li></ul></li><li><a href="https://twitter.com/HiTw93/status/1811550036120994026" target="_blank" rel="noopener noreferrer">逛 Github 的时候看到一个用简单英语来学习 Rust 的教程「Rust explained using easy English」挺有意思，很适合中文程序员去阅读，甚至没有太大压力的方式可以跟着教程学习，即可当做 Rust 基础了解，也可以当做英语复习，挺不错。</a></li><li><a href="https://twitter.com/tuturetom/status/1811405928824184933" target="_blank" rel="noopener noreferrer">不出意外 🤨  大模型/机器学习版本的 LeetCode 来了！目前已经有 26 道题目，经典的矩阵、线性回归、反向传播单神经元实现等题目都有</a><ul><li>感觉 AI Engineer 目前还没有特别的面试标准，但是未来企业又缺口巨大，这里面可能有一些机会🧐</li></ul></li><li><a href="https://twitter.com/rohanpaul_ai/status/1811458648532775202" target="_blank" rel="noopener noreferrer">This paper claims that Llama3-8B+BoT (Buffer of Thoughts) has the potential to surpass Llama3-70B model. 🤯</a></li><li><a href="https://twitter.com/jmtang42/status/1810996138813640984" target="_blank" rel="noopener noreferrer">🚀Excited to introduce Quest: an efficient long-context LLM inference framework, accepted by ICML 2024!🌟</a></li><li><a href="https://twitter.com/llama_index/status/1811147950388916420" target="_blank" rel="noopener noreferrer">Last week we launched llama-agents, a brand new multi-agent deployment framework, and the response has been enthusiastic -- the repo is at 1100 stars and counting!</a></li><li><a href="https://twitter.com/tuturetom/status/1811261990670881124" target="_blank" rel="noopener noreferrer">这一期播客还挺有意思的，大概定义了 AI Native 的产品研发方式：从迭代确定性的逻辑转向迭代 「测试集」和 「训练集」</a></li><li><a href="https://twitter.com/Stephen4171127/status/1810898816746606707" target="_blank" rel="noopener noreferrer">Prompt越写越多，而且有版本管理的需求，想找一个管理工具。发现了Pezzo</a></li><li><a href="https://twitter.com/AnthropicAI/status/1811084348692517323" target="_blank" rel="noopener noreferrer">You can now fine-tune Claude 3 Haiku—our fastest and most cost-effective model—in Amazon Bedrock</a></li><li><a href="https://twitter.com/tuturetom/status/1811214388566905319" target="_blank" rel="noopener noreferrer">超实用，Perplexity Pages 开源平替！可浏览网络生成长达「几万字」的长篇文章/研究论文，免费使用还带引用！🔥 斯坦福 Storm 2.0 重磅发布⚡️</a></li><li><a href="https://twitter.com/aigclink/status/1810585574568526029" target="_blank" rel="noopener noreferrer">11个AI程序员（偏后端）项目汇总</a></li><li><a href="https://twitter.com/tuturetom/status/1810854169794039983" target="_blank" rel="noopener noreferrer">RAG 2.0 新范式来了 ！11.3 K Star 🌟 的RAGFlow 0.8 版本正式发布 Agentic Workflow，基于有环图为 RAG 引入带反思的 Agent 能力</a></li><li><a href="https://twitter.com/tuturetom/status/1810704272151163316" target="_blank" rel="noopener noreferrer">学术福音⚡️！基于交互式，可实操的 Demo 理解 CNN/Transformer 的工作原理，已开源 7.6K Star 🌟</a></li><li><a href="https://twitter.com/AnthropicAI/status/1810747792807342395" target="_blank" rel="noopener noreferrer">We&#x27;ve added new features to the Anthropic Console. Claude can generate prompts, create test variables, and show you the outputs of prompts side by side</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1810751310016434378" target="_blank" rel="noopener noreferrer">HippoRAG is able to obtain comparable performance to iterative RAG methods (IRCoT) while being 10-30x faster and 6-13x cheaper. 🤯</a></li><li><a href="https://twitter.com/jerryjliu0/status/1810469098327068880" target="_blank" rel="noopener noreferrer">We’re excited to release a comprehensive set of video tutorials on GraphRAG 🧑‍🏫, using the latest property graph abstractions in  @llama_index</a></li><li><a href="https://twitter.com/tuturetom/status/1809925799874814417" target="_blank" rel="noopener noreferrer">解决 RAG 最致命的「验证信息可信度」问题，将人类 「海马体」机制引入大模型 RAG 技术的 HippoRAG 发布！⚡️</a><ul><li>无需微调，引入知识图谱、PageRank和检索编码器技术</li><li>在多跳问题回答上，性能提升 3～20%</li><li>相比迭代式 RAG（如 IRCoT），成本优化 10～30 倍，速度快 6～13 倍</li></ul></li><li><a href="https://twitter.com/HiTw93/status/1809191495078981870" target="_blank" rel="noopener noreferrer">Andrej Karpathy 大神的这个「让我们来搞一个GPT-2」很值得跟着学习一遍，124分钟的长视频，受限构建 GPT-2 网络，然后优化对应训练速度，并按照 GPT-2 和 GPT-3 论文参数设置训练运行，挺适合周末时间我们来照着视频学习一下。</a></li><li><a href="https://twitter.com/tuturetom/status/1810263265911648581" target="_blank" rel="noopener noreferrer">160+ 行代码手搓 GPT-4o 演示版的实时音视频通话能力并开源🔥，作者还录制了教程视频！⚡️</a></li><li><a href="https://twitter.com/tuturetom/status/1810344492459061712" target="_blank" rel="noopener noreferrer">英伟达又在 RAG 领域整了个大活！🔥，RankRAG 来了！无需微调，利用基于 Llama3 的 Retrieve-Rerank-Generate 流程，在 9 个知识密集型基准测试中明显优于 GPT-4⚡️</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1810329112558371089" target="_blank" rel="noopener noreferrer">Incredible results for the RAG world from @nvidia model 👏. Llama3-RankRAG from @nvidia significantly outperforms GPT-4 models on 9 knowledge-intensive benchmarks. 🤯</a></li><li><a href="https://twitter.com/aigclink/status/1810195830282014900" target="_blank" rel="noopener noreferrer">增强LLM具备AI产品化能力的17种RAG技术</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1810003520243863754" target="_blank" rel="noopener noreferrer">One Single Script to run the all the three steps of Reinforcement Learning from Human Feedback (RLHF) Training with DeepSpeed-Chat</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1809587148313505941" target="_blank" rel="noopener noreferrer">Wrote quite a lengthy blog - &quot;Reinforcement Learning from Human Feedback (RLHF) in Practice: A Deep Dive&quot;  👨‍🔧</a></li><li><a href="https://twitter.com/tuturetom/status/1809445355832111312" target="_blank" rel="noopener noreferrer">LlamaIndex 创始人 @jerryjliu0 在 AI Engineer 世界大会 @aiDotEngineer 上分享《知识助手的未来》，并正式发布并开源 Agentic RAG 框架 - LlamaAgents 🔥，目前 878 Star 🌟</a><ul><li>多 Agent 框架，使用 Docker/K8S 部署</li><li>完善可观测、显示的 Control 模式、发布为 Tool/API</li></ul></li><li>HippoRAG 无需微调，使用现成技术：<ul><li>LLM 推理关键点和意图</li><li>知识图谱构建知识关联性</li><li>检索+个性化PageRank从知识图谱里面整合最关联的片段，并实现高效搜索</li><li>感觉后续大模型 RAG 技术进一步发展就是传统算法+LLM 结合，进入下一个阶段，而非知识裸的检索然后丢给模型答一下 🤔</li></ul></li><li><a href="https://twitter.com/tuturetom/status/1810126865207873818" target="_blank" rel="noopener noreferrer">斯坦福爆火的 Prompt 编程框架 DSPy 的 TypeScript 实现来了！ax 实现了 DSPy 支持构建复杂 Agentic Workflow，目前已开源，697 Star 🌟</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1809705861096350198" target="_blank" rel="noopener noreferrer">The &quot;Multi-token Prediction&quot; paper (April-2024) from @AIatMeta and behind the Chameleon family of models is such an innovative idea</a></li><li><a href="https://twitter.com/vikingmute/status/1809756568730382756" target="_blank" rel="noopener noreferrer">Shadcn/UI 推出全新的图表了，好看！</a></li><li><a href="https://twitter.com/HiTw93/status/1810094948399845571" target="_blank" rel="noopener noreferrer">Laisky 的这个「面向 Web2 工程师的 Web3 入门」Slides 挺值得一看，让 Web2 工程师更好理解，介绍以区块链技术为核心的 Web3 相关基础知识，主要围绕 blockchain 的基本概念，主要关注技术实现和日常操作。</a></li><li><a href="https://twitter.com/tuturetom/status/1809604390216511542" target="_blank" rel="noopener noreferrer">获 YC 投资，为企业构建一站式内部 Agent 和 RAG 应用解决方案的 Mintplex Labs 开源其跨端应用 anything-llm，并冲上 Github Trending 第一名🔥，目前 16.8K Star 🌟</a></li></ul></div></div><p><a href="https://mp.weixin.qq.com/s/pWzp9r4mWHkEtwoNatGNZg" target="_blank" rel="noopener noreferrer">Meta | 提出System 2蒸馏方法，Llama 2对话模型任务准确率接近100%！</a></p><p><a href="https://mp.weixin.qq.com/s/MsRdzVxRnCWZGaN5qeSkXA" target="_blank" rel="noopener noreferrer">LLM之RAG实战（二十五）| 使用LlamaIndex和BM25重排序实践</a></p><p><a href="https://mp.weixin.qq.com/s/dK0wxP5AUxSQ_poIs-cpPQ" target="_blank" rel="noopener noreferrer">Hybrid Search: 利用BM25算法和语义搜索提升RAG系统性能</a></p><p><a href="https://mp.weixin.qq.com/s/wzqXhkFlvCeJkSGPrM9TxQ" target="_blank" rel="noopener noreferrer">Lookback Lens：用注意力图检测和减轻llm的幻觉</a></p><p><a href="https://mp.weixin.qq.com/s/iXpB_sX_lAnaGut2SZZmSw" target="_blank" rel="noopener noreferrer">LLM代理应用实战：构建Plotly数据可视化代理</a></p><p><a href="https://mp.weixin.qq.com/s/dECT5RWRQd06r9ZUb0A-aw" target="_blank" rel="noopener noreferrer">Stability AI修改协议Stable Diffusion 3 Medium可以免费商业化应用</a></p><p><a href="https://mp.weixin.qq.com/s/YTe-G8jlmf7DfvNr1jXmiQ" target="_blank" rel="noopener noreferrer">RouteLLM：高效LLM路由框架，可以动态选择优化成本与响应质量的平衡</a></p><p><a href="https://mp.weixin.qq.com/s/UGcui0rLW2Vz7y2Mt4atqA" target="_blank" rel="noopener noreferrer">OpenAI Lilian Weng万字长文解读LLM幻觉：从理解到克服</a></p><p><a href="https://mp.weixin.qq.com/s/t8qQCirCG5_JggvBOkGdQQ" target="_blank" rel="noopener noreferrer">OpenAI新模型「草莓」曝光：强推理/长任务规划/超大规模训练！还给出AGI分级</a></p><p><a href="https://mp.weixin.qq.com/s/fxG3YIZtB4QqePUmOkxJmQ" target="_blank" rel="noopener noreferrer">ICML 2024 | 梯度检查点太慢？不降速、省显存，LowMemoryBP大幅提升反向传播显存效率</a></p><p><a href="https://mp.weixin.qq.com/s/VjZrRUPiqLiDpcIeSOI0Fw" target="_blank" rel="noopener noreferrer">五年后的今天，训练GPT-2只需不到700刀、24小时，Karpathy又整新活</a></p><p><a href="https://mp.weixin.qq.com/s/Zc0_Oe8DsJKUTYwgGX_GRQ" target="_blank" rel="noopener noreferrer">又来一个RAG：RankRAG，英伟达RAG新思路</a></p><p><a href="https://mp.weixin.qq.com/s/5PJRryX7WrUUDjlY2SPLiQ" target="_blank" rel="noopener noreferrer">Modelscope-Agent 增强RAG能力：（二）多源召回，自定义图片解析</a></p><p><a href="https://mp.weixin.qq.com/s/l-fGuCMvnRngznYbmqOWhA" target="_blank" rel="noopener noreferrer">AI慢思考蒸馏进快思考，Llama2跃升至GPT-4水平，不写过程也能做对题</a></p><p><a href="https://mp.weixin.qq.com/s/yiYC-I0gB6aU9hUuB4pacA" target="_blank" rel="noopener noreferrer">万字长文，代码详解Memory3：革命性RAG模型如何重新定义大规模语言模型</a></p><p><a href="https://mp.weixin.qq.com/s/oRsNUD8L5Fj3_1oYNBGUpw" target="_blank" rel="noopener noreferrer">综述！清华 &amp;&amp; 剑桥 | 深入探讨大模型（LLMs）知识冲突的研究进展及挑战</a></p><p><a href="https://mp.weixin.qq.com/s/pEgovnuuIAJEuULYwDYRhw" target="_blank" rel="noopener noreferrer">绘梦有形，快手开源「可图 Kolors」，等你来玩</a></p><p><a href="https://mp.weixin.qq.com/s/gcTyTIXDoS0M31weqNO6Vg" target="_blank" rel="noopener noreferrer">社区供稿 | 源大模型的快速部署与高效推理——GGUF格式模型介绍与使用教程</a></p><p><a href="https://mp.weixin.qq.com/s/lhv1HHRw0EvGK71UwX52Qg" target="_blank" rel="noopener noreferrer">谷歌 | 提出新型层设计：PEER，可对百万专家进行稀疏检索，超越密集前馈、稀疏MoE</a></p><p><a href="https://mp.weixin.qq.com/s/KL40M1bR3EPlAGWYYEghCg" target="_blank" rel="noopener noreferrer">人人可做提示工程师！Claude上新：一键生成、测试和评估prompt</a></p><p><a href="https://mp.weixin.qq.com/s/Sy_q8VSjvpliJbdekWOK1g" target="_blank" rel="noopener noreferrer">平安科技新成果：PCA，基于外部决策工具的智能客服框架</a></p><p><a href="https://mp.weixin.qq.com/s/pk0JZw_XwkC0TWagRg0OBg" target="_blank" rel="noopener noreferrer">深入探讨提示工程的攻击与防范：从理论到实践【附大语言模型提示注入攻击安全风险分析报告】</a></p><p><a href="https://mp.weixin.qq.com/s/33Xs00kFiT8miKyfmtpNew" target="_blank" rel="noopener noreferrer">BM42横空出世！BM25统御搜索引擎40年，终于要落幕了</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/03-AaxCbIzzUHWknXy_CNA" target="_blank" rel="noopener noreferrer">源码解读 - 微软GraphRAG框架</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/Evt23LNEVrzd-ZNofjb9WQ" target="_blank" rel="noopener noreferrer">LLM 大模型学习必知必会系列(四)：LLM训练理论篇以及Transformer结构模型详解</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/ZgwHUsadhzV1d5dXTqSjeA" target="_blank" rel="noopener noreferrer">斯坦福最新警示 | 别被RAG模型骗了：看LLM如何通过Prompt权衡先验知识与RAG检索</a></p><p><a href="https://mp.weixin.qq.com/s/eFt0VFD-4x5ckHW7bqJ-lg" target="_blank" rel="noopener noreferrer">RAG还得靠大佬！NVIDIA新模型让GPT-4都吃灰</a></p><p><a href="https://mp.weixin.qq.com/s/QipN4AtSQ82ITrIgsDZREg" target="_blank" rel="noopener noreferrer">苹果大模型Siri将至；InternLM2.5-7B可免费商用；TTT超越Transformer和Mamba｜青稞日报07.08</a></p><p><a href="https://mp.weixin.qq.com/s/EG66INwRyNaeKtrYcAnZ0Q" target="_blank" rel="noopener noreferrer">不是H100租不起，而GPU混布更有性价比！</a></p><p><a href="https://mp.weixin.qq.com/s/U1yg3qsJYfpFTmSZtM9lpA" target="_blank" rel="noopener noreferrer">多模态模型(VLM)部署方法抛砖引玉</a></p><p><a href="https://mp.weixin.qq.com/s/y21ii5AxErt-x3mFsAXW2w" target="_blank" rel="noopener noreferrer">微软&amp;清华提出全新预训练范式，指令预训练让8B模型实力暴涨！实力碾压70B模型</a></p><p><a href="https://mp.weixin.qq.com/s/-MzRdrg014VhgbXV1kcUjA" target="_blank" rel="noopener noreferrer">IAAR &amp;&amp; 北大 | 为大模型配备显式记忆，降低成本，提升大模型推理速度！</a></p><p><a href="https://mp.weixin.qq.com/s/QSw9PKB_HhSxeO7agnzBgQ" target="_blank" rel="noopener noreferrer">彻底改变语言模型：全新架构TTT超越Transformer，ML模型代替RNN隐藏状态</a></p><p><a href="https://mp.weixin.qq.com/s/4fH5e2FBTzw73j5lO8z_EQ" target="_blank" rel="noopener noreferrer">理解时间戳的视频理解大模型CogVLM2开源！视频生成、视频摘要等任务有力工具！</a></p><p><a href="https://mp.weixin.qq.com/s/TCoSeYi1gvEatf2B7eiT-g" target="_blank" rel="noopener noreferrer">激活函数的进化之旅：从Sigmoid到SwiGLU，深度学习的神经触发器</a></p><p><a href="https://mp.weixin.qq.com/s/DgoyEpjLkqlRu0k2cb9XpA" target="_blank" rel="noopener noreferrer">Mobile-Agent-V1/V2：基于多模态Agent架构的手机智能体</a></p><p><a href="https://mp.weixin.qq.com/s/OUaVLkxlk1zhFb1cvMCFjg" target="_blank" rel="noopener noreferrer">开源VLM新标杆 InternVL 2.0 怎么用？部署、微调尽在魔搭社区！</a></p><p><a href="https://mp.weixin.qq.com/s/AEZXjBXEaj6rXWUGBxEtoA" target="_blank" rel="noopener noreferrer">微软 MInference：百万 Token 序列，10x 加速</a></p><p><a href="https://mp.weixin.qq.com/s/TvK2JtJ68NKSSyR7ntDduA" target="_blank" rel="noopener noreferrer">压缩下一个token通向超过人类的智能</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><div class="theme-admonition theme-admonition-tip alert alert--success admonition_kCt_"><div class="admonitionHeading_oZsk"><span class="admonitionIcon_tnIl"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>技术资讯</div><div class="admonitionContent_m8BQ"><ul><li><a href="https://github.com/SeekStorm/SeekStorm" target="_blank" rel="noopener noreferrer">SeekStorm - 一个亚毫秒级的全文搜索引擎</a><ul><li>非常快。同时还支持多租户系统。这个项目是由其它项目转过来用Rust重写的，之前那个项目已经搞了很多年了。</li></ul></li><li><a href="https://www.howtocodeit.com/articles/rust-ownership-explained-linked-lists" target="_blank" rel="noopener noreferrer">blog：通过合并链接表来学习Rust的所有权</a></li><li><a href="https://datacrayon.com/data-analysis-with-rust-notebooks/setup-anaconda-jupyter-and-rust/" target="_blank" rel="noopener noreferrer">使用 Rust, Jupyter 和 Anaconda 来做数据分析</a><ul><li>已经有专门的使用Rust来做数据分析和处理的书了。现在AI pipeline中，使用Rust来代替python做预训练前的数据准备工作已经成了一种趋势了。</li></ul></li><li><a href="https://dev.to/hieunguyendev/backend-project-structure-go-1ph8" target="_blank" rel="noopener noreferrer">Backend Project Structure Go</a></li><li><a href="https://dev.to/crusty0gphr/tricky-golang-interview-questions-part-6-nonblocking-read-aj1" target="_blank" rel="noopener noreferrer">Tricky Golang interview questions - Part 6: NonBlocking Read</a></li><li><a href="https://github.com/trzsz/trzsz-ssh" target="_blank" rel="noopener noreferrer">A Go-based SSH client designed as a drop-in replacement for the OpenSSH client</a></li><li><a href="https://github.com/Caknoooo/go-gin-clean-starter" target="_blank" rel="noopener noreferrer">A simple backend implementation of Clean Architecture using Gin/Gorm with Dependency Injection</a></li><li><a href="https://dev.to/siashish/understanding-gos-garbage-collector-a-detailed-guide-kj4" target="_blank" rel="noopener noreferrer">Understanding Go&#x27;s Garbage Collector: A Detailed Guide</a></li><li><a href="https://twitter.com/HiTw93/status/1810822744008950139" target="_blank" rel="noopener noreferrer">发现一个可以把日志文件高亮的命令行工具 Tailspin，安装后把原来查看命令换成 tspin 即可看到下面这种效果的日志，更加便于阅读和排查问题。</a></li><li><a href="https://twitter.com/golangch/status/1810559700221464656" target="_blank" rel="noopener noreferrer">An interesting article: &quot;How I write HTTP services in Go after 13 years&quot;</a></li><li><a href="https://twitter.com/zigo_101/status/1810051521264202192" target="_blank" rel="noopener noreferrer">If you have many equal strings which don&#x27;t share underlying bytes memory, then, since #Golang 1.23, you can use the following shown Canonicalize function to let them share underlying bytes memory, so that much memory will get freed</a></li><li><a href="https://twitter.com/zigo_101/status/1810358112467165343" target="_blank" rel="noopener noreferrer">Go 1.23 adds a &quot;CopyFS&quot; function in the &quot;os&quot; std package</a></li><li><a href="https://twitter.com/TheGoDev/status/1810345348482650547" target="_blank" rel="noopener noreferrer">Learn how to build your own distributed key-value storage system using the etcd Raft library. Dive into the architecture and code analysis! </a></li></ul></div></div><p><a href="https://mp.weixin.qq.com/s/o-5Cf83RyFoMuI6Itsre5w" target="_blank" rel="noopener noreferrer">构建并运行 eBPF 应用 - Part 1</a></p><p><a href="https://mp.weixin.qq.com/s/0kNuWh0eFAxSY-FZ_IT0zQ" target="_blank" rel="noopener noreferrer">想知道海外技术面试都考些什么吗</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/dDa13waA_hpkSwV5uqIwsw" target="_blank" rel="noopener noreferrer">[<!-- -->译<!-- -->]<!-- --> Rust标准库有些特殊，让我们改变它</a></p><p><a href="https://mp.weixin.qq.com/s/2Nl0sh0rYEAN7YneAUYDxA" target="_blank" rel="noopener noreferrer">Go语言标准库中<code>math/rand</code>包的改进和<code>math/rand/v2</code>包的引入</a></p><p><a href="https://mp.weixin.qq.com/s/gcy1IWCFuMg8XpgT94oGmg" target="_blank" rel="noopener noreferrer">代码提交即部署：Argo Workflows 与 EventBridge 构建自动化 CI</a></p><p><a href="https://mp.weixin.qq.com/s/PdqL6OMm1f5zqXZRfCHddQ" target="_blank" rel="noopener noreferrer">链路追踪详解（六）：Zipkin 和 Jaeger 的安装方法</a></p><p><a href="https://mp.weixin.qq.com/s/EiXTTJlK2-7GO20P1_nqYg" target="_blank" rel="noopener noreferrer">Kubernets的NVIDIA设备插件安装方案实践</a></p><p><a href="https://mp.weixin.qq.com/s/9A8w4CvYQszeLUftc7OQXw" target="_blank" rel="noopener noreferrer">Go 1.23 的 os.CopyFS：告别第三方库，轻松复制目录</a></p><p><a href="https://mp.weixin.qq.com/s/3AanFtF-gzvV5R3Rs92hpA" target="_blank" rel="noopener noreferrer">在Go项目中使用Redis的几个实用建议</a></p><p><a href="https://mp.weixin.qq.com/s/u8BcfQKmtWIB86B4GetULQ" target="_blank" rel="noopener noreferrer">使用SIMD优化二叉搜索树</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/mKcyv7cq5ZC4CsNyu5apkg" target="_blank" rel="noopener noreferrer">5 Better ways to code in Rust</a></p><p><a href="https://mp.weixin.qq.com/s/Av9iOvoe6LRs5WEzeT6RYQ" target="_blank" rel="noopener noreferrer">全面掌握 Go 语言 errors 标准库：使用指南与源码深度解析</a></p><p><a href="https://mp.weixin.qq.com/s/d6e02RbtWALq-nLX_ptpog" target="_blank" rel="noopener noreferrer">Go 语言 API 限流实战：保障系统稳定性的护盾</a></p><p><a href="https://mp.weixin.qq.com/s/_zELlhcrOpZSPqaIgvXp5g" target="_blank" rel="noopener noreferrer">Go 性能度量利器，完全替代 io.Reader 和 io.Writer！</a></p><p><a href="https://mp.weixin.qq.com/s/7j0FvbY6Y0ig3WFDY7p2uA" target="_blank" rel="noopener noreferrer">rsc 给 Go 社区写了个 AI 机器人，他很满意！</a></p><p><a href="https://mp.weixin.qq.com/s/YvWF0XWCze15v3goZ5_w-g" target="_blank" rel="noopener noreferrer">Rust多线程编程和异步编程</a></p><p><a href="https://mp.weixin.qq.com/s/s58sTdxlvIs59Ton2X600g" target="_blank" rel="noopener noreferrer">震惊! Go 1.23中Timer无buffer的实现方式竟是这样!</a></p><p><a href="https://mp.weixin.qq.com/s/vEGdgaMhisowj5SK5EyoSQ" target="_blank" rel="noopener noreferrer">Golang Channel 模式：Retry timeout</a></p><p><a href="https://mp.weixin.qq.com/s/hQz70C_-BzYqef9UMaq9uA" target="_blank" rel="noopener noreferrer">对过去一年多的 AI 轮子们碎碎念</a></p><p><a href="https://mp.weixin.qq.com/s/eATqcq-Lwc5JoKKBryKTlQ" target="_blank" rel="noopener noreferrer">cgo 内存优化后续 - 修了个 bug</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p>🌟 <a href="https://mp.weixin.qq.com/s/yiCpy3RoZNGX04Yawvca_A" target="_blank" rel="noopener noreferrer">万字聊一聊DDD领域驱动设计理论</a></p><p><a href="https://mp.weixin.qq.com/s/fVT1M-Gy_85scPufhCoHoA" target="_blank" rel="noopener noreferrer">快停下，Redis 都要被你玩坏了</a></p><p><a href="https://mp.weixin.qq.com/s/8Ncrz8GPZra-pbIS2hAEfA" target="_blank" rel="noopener noreferrer">国内用户如何使用 DuckDB 访问 Hugging Face 上超15万 数据集</a></p><p><a href="https://mp.weixin.qq.com/s/hrt6SpWhMir77TjGvRVg_g" target="_blank" rel="noopener noreferrer">紧急生产问题：线上kafka百万消息积压如何处理</a></p><p><a href="https://mp.weixin.qq.com/s/Qle0nZeTdHeuaitNdWY_Cw" target="_blank" rel="noopener noreferrer">微服务循环依赖引发惨案，有坑！</a></p><p><a href="https://mp.weixin.qq.com/s/qDTZR-HaJCU9z4tLpOObBw" target="_blank" rel="noopener noreferrer">写出漂亮代码的45个小技巧，你知道几个？还不收藏</a></p><p><a href="https://mp.weixin.qq.com/s/eYN9pmLenYJuBXaZh-coVw" target="_blank" rel="noopener noreferrer">3个企业级最佳实践，教你ByteHouse云数仓这么用</a></p><p><a href="https://mp.weixin.qq.com/s/w0rzwuBgWOei5fhqsf8b4A" target="_blank" rel="noopener noreferrer">阿里面试：canal+MQ，会有乱序的问题吗</a></p><p><a href="https://mp.weixin.qq.com/s/dbpOykMBZeZYoCxYLIkxDQ" target="_blank" rel="noopener noreferrer">在线人数统计功能怎么实现</a></p><p><a href="https://mp.weixin.qq.com/s/SsWiEaMJYx3Lzr6JWN6ZhQ" target="_blank" rel="noopener noreferrer">12 个电商核心业务系统，如此复杂的中台业务一篇文章就能讲明白</a></p><p><a href="https://mp.weixin.qq.com/s/hnYViDVL1rwnyP3-Z2INlw" target="_blank" rel="noopener noreferrer">Rust 中跨平台获取 MAC 地址</a></p><p><a href="https://mp.weixin.qq.com/s/CVwppNImK6roZ2UmmJh6bg" target="_blank" rel="noopener noreferrer">秒杀圣经(2): 16大绝招，完成10Wqps秒杀架构（3万字架构长文）</a></p><p><a href="https://mp.weixin.qq.com/s/s3N34Y3sHHAhMdwMV2iRFA" target="_blank" rel="noopener noreferrer">干货 | 携程门票「秒杀系统」的设计与实践</a></p><p><a href="https://mp.weixin.qq.com/s/YjO03H-oqMeGgKSm5TnAeA" target="_blank" rel="noopener noreferrer">在过去三年中，DuckDB 的速度提升了 3-25 倍</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/Sg5FsGvXjFzVFWPy-QBoVQ" target="_blank" rel="noopener noreferrer">如何开发一款 JSSDK</a></p><p><a href="https://mp.weixin.qq.com/s/z5ncEVZ1yGPMDBaj4MHEQQ" target="_blank" rel="noopener noreferrer">数据智能｜交互新探索：大模型时代可视化应用的交互新可能</a></p><p><a href="https://mp.weixin.qq.com/s/1jXt_tosJTYlPmCG0AuIEQ" target="_blank" rel="noopener noreferrer">性能飙升50%，react-virtualized-list如何优化大数据集滚动渲染</a></p><p><a href="https://mp.weixin.qq.com/s/95Kb3tX5h4ecLGE88Cez2Q" target="_blank" rel="noopener noreferrer">Next.js 项目写 Tailwind CSS 基本都会遇到的两个问题</a></p><p><a href="https://mp.weixin.qq.com/s/7thawb1Qj4816s7Zu2rbuw" target="_blank" rel="noopener noreferrer">构建更快的 Web 体验 - 使用 postTask 调度器</a></p><p><a href="https://mp.weixin.qq.com/s/sw4-MYTPr5henmZ6dw_2Lw" target="_blank" rel="noopener noreferrer">前端工程化系列二：编码提效</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/7月7日内容汇总">7月7日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-07-07T00:00:00.000Z" itemprop="datePublished">July 7, 2024</time> · <!-- -->17 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/maxresdefault-ffb8f11e1c31c2d1464780924ffb5d89.jpg" width="1280" height="720" class="img_astN"></p><p>封面图：Safe by construction - Roberto Clapis</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><div class="theme-admonition theme-admonition-tip alert alert--success admonition_kCt_"><div class="admonitionHeading_oZsk"><span class="admonitionIcon_tnIl"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>技术资讯</div><div class="admonitionContent_m8BQ"><ul><li><a href="https://twitter.com/llama_index/status/1808898730638389262" target="_blank" rel="noopener noreferrer">Reflection as a Service 🪞</a></li><li><a href="https://twitter.com/op7418/status/1809059959264719115" target="_blank" rel="noopener noreferrer">昨天上海 AI lab 开源了一个非常强的多模态 LLM  InternLM-XComposer-2.5</a></li><li><a href="https://twitter.com/tuturetom/status/1809053337825989009" target="_blank" rel="noopener noreferrer">从 Prompt Engineering 到 Flow Engineering🔥 @CodiumAI 开源了一个 PR-Agent，目前 4.8K Star 🌟，自动基于你提交的代码进行分析，给于评论反馈与意见，生成 PR 描述！</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1809032437814439973" target="_blank" rel="noopener noreferrer">Nice overview kind of Paper - &quot;Searching for Best Practices in Retrieval-Augmented Generation&quot;</a></li><li><a href="https://twitter.com/omarsar0/status/1808887392503279758" target="_blank" rel="noopener noreferrer">麻省理工这本《深入理解深度学习》的免费书可太好了。深入讲解了深度学习的大部分概念。而且每个章节都有搭配的PPT可以下载，还有对应练习的Python代码。内容包括监督学习、神经网络、损失函数、正则化、卷积网络、Transformers、扩散模型、强化学习等。</a></li><li><a href="https://twitter.com/indigo11/status/1808786759914041537" target="_blank" rel="noopener noreferrer">🏆如何实现财务自由的21条准则：顶级商学院课件 深入浅出 初学专业兼具底层思维分享</a></li><li><a href="https://twitter.com/dotey/status/1808731046751375748" target="_blank" rel="noopener noreferrer">非常值得一看的视频，OpenAI 联合创始人 Andrej Karpathy 在2024年加州大学伯克利分校人工智能黑客马拉松颁奖典礼上的主题演讲</a></li><li><a href="https://twitter.com/9hills/status/1808003554353074245" target="_blank" rel="noopener noreferrer">大模型产品化第一年​：战术、运营与战略</a></li><li><a href="https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/" target="_blank" rel="noopener noreferrer">What We Learned from a Year of Building with LLMs (Part I)</a></li><li><a href="https://twitter.com/tuturetom/status/1808549893822370297" target="_blank" rel="noopener noreferrer">支持 10+ 翻译器的漫画或图片翻译神器  - Image/Manga Translator 开源！🔥目前 4 6K Star</a></li><li><a href="https://twitter.com/HiTw93/status/1808649423037067750" target="_blank" rel="noopener noreferrer">Reddit 上的这个 lectures 频道，包含很多值得一听的视频讲座、演讲和有趣的公开演讲，包括数学、物理、计算机科学、编程、工程、生物、医学、经济学、政治、社会科学这类学科的知识</a></li><li><a href="https://twitter.com/dotey/status/1808221582793626012" target="_blank" rel="noopener noreferrer">转译：《如何使用ChatGPT撰写科学研究论文？- Dr Asma Jabeen》</a></li><li><a href="https://twitter.com/cn_LittleYu/status/1808399143557386555" target="_blank" rel="noopener noreferrer">刚才翻 MySQL 文档，切文档版本的时候，发现 MySQL 9.0 发布了</a></li><li><a href="https://twitter.com/MSFTResearch/status/1808168761565798833" target="_blank" rel="noopener noreferrer">GraphRAG, a graph-based approach to retrieval-augmented generation (RAG) that significantly improves question-answering over private or previously unseen datasets, is now available on GitHub</a></li><li><a href="https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/" target="_blank" rel="noopener noreferrer">GraphRAG: New tool for complex data discovery now on GitHub</a></li><li><a href="https://twitter.com/tuturetom/status/1808320407583576163" target="_blank" rel="noopener noreferrer">下一代 RAG 技术来了！微软正式开源 GraphRAG🔥 通过 LLM 构建知识图谱结合图机器学习，极大增强 LLM 在处理私有数据时的性能，同时 GraphRAG 具备连点成线的跨大型数据集的复杂语义问题推理能力</a></li><li><a href="https://blog.monsterapi.ai/blogs/finetuning-a-large-language-model/" target="_blank" rel="noopener noreferrer">How to Fine-tune a Large Language Model</a></li><li><a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf" target="_blank" rel="noopener noreferrer">Gemma 2: Improving Open Language Models at a Practical Size</a></li><li><a href="https://www.bilibili.com/video/BV1Qy411z7uh" target="_blank" rel="noopener noreferrer">ncnn Vulkan 机器学习最新进展</a></li><li><a href="https://twitter.com/llama_index/status/1808164468708499482" target="_blank" rel="noopener noreferrer">The Future of Knowledge Assistants 🤖</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1808082423181115735" target="_blank" rel="noopener noreferrer">Cool repo from @huggingface - local-gemma: Gemma 2 optimized for your local machine 🔥</a></li><li><a href="https://twitter.com/AxtonLiu/status/1808261617718907267" target="_blank" rel="noopener noreferrer">Claude 3.5 的 Artifacts 确实非常惊艳，在跟他讨论问题时，他不但耐心地给你仔细分析优缺点，还随手抓过一张纸开始画流程图，边画边说。。。</a></li><li><a href="https://twitter.com/shao__meng/status/1808038130123198744" target="_blank" rel="noopener noreferrer">RAG 最佳实践探索</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1807561583079367086" target="_blank" rel="noopener noreferrer">A recent Q* Paper - On MATH, surpasses GPT-4 and Gemini Ultra.  🔥</a></li><li><a href="https://twitter.com/i/lists/1278784207641284609" target="_blank" rel="noopener noreferrer">假如你想看 AI 相关的最新消息，可以关注这个推特 AI 列表 「AI Leaders」，时效性会快于国内翻译搬运的好几天，甚至可以置顶到列表项方便阅读</a></li><li><a href="https://twitter.com/aigclink/status/1807977557968708010" target="_blank" rel="noopener noreferrer">一个基于LangChain 实现RAG（检索增强型生成）的指南！</a></li><li><a href="https://twitter.com/eyishazyer/status/1807732216484536399" target="_blank" rel="noopener noreferrer">60 AI Tools to Start Your Profitable Online Business in 2024</a></li><li>Mooncake 是 Moonshot AI 提供的领先的 LLM 服务 Kimi 的服务平台，目前已经在知乎发表 3 偏技术报告：<ul><li><a href="https://zhuanlan.zhihu.com/p/705754254" target="_blank" rel="noopener noreferrer">Mooncake (1): 在月之暗面做月饼，Kimi 以 KVCache 为中心的分离式推理架构</a></li><li><a href="https://zhuanlan.zhihu.com/p/705910725" target="_blank" rel="noopener noreferrer">关于 Mooncake 的碎碎念</a></li><li><a href="https://zhuanlan.zhihu.com/p/706204757" target="_blank" rel="noopener noreferrer">Mooncake (2)：Kimi “泼天的流量”怎么接，分离架构下基于预测的调度策略</a></li></ul></li><li>Mooncake 技术报告中提出 3 个论点：<ul><li>存算分离的 KVCache 策略是长期趋势（立马就可以省钱</li><li>与 MLA、KVCache 压缩方案正交，KVCache 变小意味着 Mooncake 方案收益明显</li><li>为芯片设计提供参考，未来 2～3 年可能会是趋势</li><li>中文解读版本：<a href="https://mp.weixin.qq.com/s/MgJ01ZcQ922BX0-UHGdRKg" target="_blank" rel="noopener noreferrer">月之暗面kimi底层推理系统方案揭秘</a></li></ul></li><li><a href="https://twitter.com/shao__meng/status/1807735962296090849" target="_blank" rel="noopener noreferrer">为 RAG 场景微调嵌入模型</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1807828746625507758" target="_blank" rel="noopener noreferrer">Fantastic paper for Reward Model Training in RLHF ✨</a></li><li><a href="https://twitter.com/jerryjliu0/status/1807935920882266231" target="_blank" rel="noopener noreferrer">Multi-agents on k8s 🤖</a></li><li><a href="https://twitter.com/HiTw93/status/1807325505240383677" target="_blank" rel="noopener noreferrer">置身事内 - 中国政府与经济发展</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1807774433550950816" target="_blank" rel="noopener noreferrer">Brilliant new paper, HUGE for LLM&#x27;s internalized knowledge 🔥</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1807202397548134760" target="_blank" rel="noopener noreferrer">A very intriguing recent paper &quot;Nested Jailbreak Prompts can Fool LLMs Easily&quot; - reveals the inadequacy of current defense methods in safeguarding LLMs.</a></li><li><a href="https://twitter.com/tuturetom/status/1807446334175428629" target="_blank" rel="noopener noreferrer">专为 LLM 打造的智能缓存技术 - GPTCache 开源并发布论文，目前 6.7K Star 🌟</a></li><li><a href="https://twitter.com/dotey/status/1807147430460244446" target="_blank" rel="noopener noreferrer">用 DALL-E 给文章配图我是这么用的</a></li><li><a href="https://twitter.com/tuturetom/status/1807643529805738355" target="_blank" rel="noopener noreferrer">支持爬取网页、解析音视频/PDF 等 10+ 格式文件🔥，LlamaIndex LlamaParse 开源平替，超强的 AI 数据源解析器 - OmniParse 开源，目前 457 Star 🌟！</a></li><li><a href="https://twitter.com/interjc/status/1807608783755169921" target="_blank" rel="noopener noreferrer">原来微软的这套《Generative AI for Beginners》还有中文版。内容不深，作为入门教程快速通读一遍还是可以的</a></li><li><a href="https://twitter.com/eviljer/status/1807297926894678315" target="_blank" rel="noopener noreferrer">💻 Gemini 推出代码解析器：Code execution</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1807141330411487553" target="_blank" rel="noopener noreferrer">This 76-page paper on Prompting Techniques has become quite popular. A nice read for your weekend</a></li></ul></div></div><p><a href="https://juejin.cn/post/7300470358817243145" target="_blank" rel="noopener noreferrer">LLM+本地知识库？简单又没那么简单</a></p><p><a href="https://mp.weixin.qq.com/s/LhfEfbpmoDNTfyC8wnE9xA" target="_blank" rel="noopener noreferrer">你想要的GraphRAG的内容都在这了</a></p><p><a href="https://mp.weixin.qq.com/s/Q9rJ5eWnaMRYyAtA2C_ZTA" target="_blank" rel="noopener noreferrer">2024年6月后2周重要的大语言模型论文总结：LLM进展、微调、推理和对齐</a></p><p><a href="https://mp.weixin.qq.com/s/YTe-G8jlmf7DfvNr1jXmiQ" target="_blank" rel="noopener noreferrer">RouteLLM：高效LLM路由框架，可以动态选择优化成本与响应质量的平衡</a></p><p><a href="https://mp.weixin.qq.com/s/XDuIFyCwMW67HBuPHQqKKg" target="_blank" rel="noopener noreferrer">2分钟，需求文档变产品，国产大模型开发神器火爆WAIC</a></p><p><a href="https://mp.weixin.qq.com/s/wk3nlPU0rKAcHCiELUCr1A" target="_blank" rel="noopener noreferrer">RAGFlow开源Star量破万，是时候思考下RAG的未来是什么了</a></p><p><a href="https://mp.weixin.qq.com/s/nKGk4rzJqWwilWgPOg74Hw" target="_blank" rel="noopener noreferrer">详解这一年多模态视觉-语言大模型的架构演进</a></p><p><a href="https://mp.weixin.qq.com/s/t5ETfG_H9oi1G3XMcyfHMw" target="_blank" rel="noopener noreferrer">社区供稿 | 加速基于 Arm Neoverse N2 的大语言模型推理</a></p><p><a href="https://mp.weixin.qq.com/s/u9RG7zuDUO62CbrmGyZtOA" target="_blank" rel="noopener noreferrer">Kimi论文自曝推理架构，80%流量都靠它承担</a></p><p><a href="https://mp.weixin.qq.com/s/Ut_a35mnFcf-noh_28ISMQ" target="_blank" rel="noopener noreferrer">LLaMA Factory：从预训练到RLHF，大模型高效训练框架</a></p><p><a href="https://mp.weixin.qq.com/s/Nh_NmOSGdx5nOIr8Y_ysIA" target="_blank" rel="noopener noreferrer">大语言模型超参数入门调参手册</a></p><p><a href="https://mp.weixin.qq.com/s/swrU7CfPLcksrf5mYL_LXA" target="_blank" rel="noopener noreferrer">图解大模型计算加速系列：分离式推理架构1，从DistServe谈起</a></p><p><a href="https://mp.weixin.qq.com/s/_2yhRu4XjcTCepC4JvA47A" target="_blank" rel="noopener noreferrer">关键点检测标注文件解析（姿态估计）——COCO数据集</a></p><p><a href="https://mp.weixin.qq.com/s/UaAbSZRqITdgkFE-ACvJQQ" target="_blank" rel="noopener noreferrer">可控细节的长文档摘要，探索开源LLM工具与实践</a></p><p><a href="https://mp.weixin.qq.com/s/n54ejG_c-BZs1apeEe1pDw" target="_blank" rel="noopener noreferrer">GPT-4预测股票涨跌更更更准了！东京大学新框架LLMFactor提升显著 ｜ ACL 2024</a></p><p><a href="https://mp.weixin.qq.com/s/NMo3gLZPskH766vxoYJipg" target="_blank" rel="noopener noreferrer">使用‘消除’技术绕过LLM的安全机制，不用训练就可以创建自己的nsfw模型</a></p><p><a href="https://mp.weixin.qq.com/s/Xeu9XQhvz3wubK6d7Sd7qQ" target="_blank" rel="noopener noreferrer">SOFTS: 时间序列预测的最新模型以及Python使用示例</a></p><p><a href="https://mp.weixin.qq.com/s/69Hy2M_a9lVuIumFDFoXjA" target="_blank" rel="noopener noreferrer">Claude 3.5 Sonnet 超越 GPT-4o成为最智能的模型，新功能artifacts可以实时查看和迭代生成的代码</a></p><p><a href="https://mp.weixin.qq.com/s/vK2mPxWUooVqUb8H4YnRrA" target="_blank" rel="noopener noreferrer">Llama也能做图像生成！港大字节推出开源自回归文生图模型，在线体验已开放</a></p><p><a href="https://mp.weixin.qq.com/s/26HAPNf8AAScPPE9OEA6zQ" target="_blank" rel="noopener noreferrer">240万亿巨量数据被洗出，足够训出18个GPT-4！全球23所机构联手，清洗秘籍公开</a></p><p><a href="https://mp.weixin.qq.com/s/6t-QJoy8q87dlpcsCc1vFQ" target="_blank" rel="noopener noreferrer">2024 SOTA多模态大模型架构设计的最佳实践</a></p><p><a href="https://mp.weixin.qq.com/s/Zo274CCITKGRn0dKD8WNJA" target="_blank" rel="noopener noreferrer">人类偏好对齐训练技术解析</a></p><p><a href="https://mp.weixin.qq.com/s/-9MjgNOLRrUdaQUF5tVv9w" target="_blank" rel="noopener noreferrer">ICML 2024 Spotlight | 在解码中重新对齐，让语言模型更少幻觉、更符合人类偏好</a></p><p><a href="https://mp.weixin.qq.com/s/Wo0cky9k6x_kAG4xXTNFvQ" target="_blank" rel="noopener noreferrer">Web2Code：一款用于网页转代码的全套数据集（含训练数据和评估框架），得分显著提升</a></p><p><a href="https://mp.weixin.qq.com/s/AunfS2qA8n0_d0rdN1NMJA" target="_blank" rel="noopener noreferrer">AIOps的工业化应用：有 42%的机会让Meta在发现故障后几分钟内就定位到潜在的根本原因</a></p><p><a href="https://mp.weixin.qq.com/s/PSnTouVkP6Gl7Rc5-yvClQ" target="_blank" rel="noopener noreferrer">大模型国产化适配10-快速迁移大模型到昇腾910B保姆级教程（Pytorch版）</a></p><p><a href="https://mp.weixin.qq.com/s/Nh5vlWno2siU4kGog3crdw" target="_blank" rel="noopener noreferrer">详解这一年多模态视觉-语言大模型的架构演进</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/MgJ01ZcQ922BX0-UHGdRKg" target="_blank" rel="noopener noreferrer">月之暗面kimi底层推理系统方案揭秘</a></p><p><a href="https://mp.weixin.qq.com/s/PRVQwMjWw_mQ7v58UeFuEg" target="_blank" rel="noopener noreferrer">使用CXX进行Rust和C++的安全互操作</a></p><p><a href="https://mp.weixin.qq.com/s/5LryZXmLLurDa-XEAdLOGg" target="_blank" rel="noopener noreferrer">Florence-2，小模型推进视觉任务的统一表征</a></p><p><a href="https://mp.weixin.qq.com/s/AfRwiXv-5zIM33IcIa7Kfw" target="_blank" rel="noopener noreferrer">ICML 2024 | 无需LayerNorm简化Attention，精度无损推理效率大幅提升</a></p><p><a href="https://mp.weixin.qq.com/s/JE0w-ksh5TRby_TRfjWbzw" target="_blank" rel="noopener noreferrer">拆分Transformer注意力，韩国团队让大模型解码提速20倍</a></p><p><a href="https://mp.weixin.qq.com/s/uxoxE2SjOhEDTwiVGu_zpg" target="_blank" rel="noopener noreferrer">模型实操 | 从零开始，用英伟达T4、A10训练小型文生视频模型</a></p><p><a href="https://mp.weixin.qq.com/s/RMNwgrXfwHFcg7wg4m4Mvw" target="_blank" rel="noopener noreferrer">BigCodeBench: 继 HumanEval 之后的新一代代码生成测试基准</a></p><p><a href="https://mp.weixin.qq.com/s/6hmEMT7XJlOgHmItx8tV_w" target="_blank" rel="noopener noreferrer">打败GPT4！仅用1/24成本的混合智能体架构逆袭 (mixture of agents)</a></p><p><a href="https://mp.weixin.qq.com/s/iZghbBw6SF3lHKucOS884w" target="_blank" rel="noopener noreferrer">Meta：悄悄发布多款模型、研究和数据集</a></p><p><a href="https://mp.weixin.qq.com/s/pvhncazfvw47kaE4z2MmCA" target="_blank" rel="noopener noreferrer">llama-index团队开源面向生产级多智能体系统的开源框架：llama-agent</a></p><p><a href="https://mp.weixin.qq.com/s/hBhvAn5MiUuaB9rmwwmNlA" target="_blank" rel="noopener noreferrer">提示工程策略：利用【慢思考】的双过程理论减少模型有害输出</a></p><p><a href="https://mp.weixin.qq.com/s/fXUH7GESEXjplLStti2C2g" target="_blank" rel="noopener noreferrer">从零开始，用英伟达T4、A10训练小型文生视频模型，几小时搞定</a></p><p><a href="https://mp.weixin.qq.com/s/I0cQdS7dPyiujh7FZKp02w" target="_blank" rel="noopener noreferrer">ICML2024 &amp; 北大｜探究Transformer如何进行推理？基于样例还是基于规则</a></p><p><a href="https://mp.weixin.qq.com/s/7dPr0B4-Pb8q9_ouaoM8Cg" target="_blank" rel="noopener noreferrer">LLM Agent的规划能力如何重塑AI的未来</a></p><p><a href="https://mp.weixin.qq.com/s/ow7n7W2Or9VmmtxRxaj9Hg" target="_blank" rel="noopener noreferrer">kimi chat大模型的200万长度无损上下文可能是如何做到的</a></p><p><a href="https://mp.weixin.qq.com/s/leRUUUTHRyH8nApUVJGmCg" target="_blank" rel="noopener noreferrer">大模型推理优化技术-KV Cache</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><div class="theme-admonition theme-admonition-tip alert alert--success admonition_kCt_"><div class="admonitionHeading_oZsk"><span class="admonitionIcon_tnIl"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>技术资讯</div><div class="admonitionContent_m8BQ"><ul><li><a href="https://www.firezone.dev/blog/sans-io" target="_blank" rel="noopener noreferrer">sans-IO 高性能网络服务实现：Firezone公司用Rust实现了他们网络服务中的一个关键组件，并总结了一套关于高性能安全开发网络服务的心得。并实现在了 sans-IO 中</a></li><li><a href="https://dev.to/paradeto/implement-react-v18-from-scratch-using-wasm-and-rust-16-implement-react-noop-38a8" target="_blank" rel="noopener noreferrer">使用 WASM 和 Rust 从零实现 React v18：这是一个系列文章的第 16 部分，介绍如何从零开始使用 WASM 和 Rust 实现 React v18 的核心功能</a></li><li><a href="https://github.com/letmutex/htmd" target="_blank" rel="noopener noreferrer">htmd: HTML to Markdown for Rust</a></li><li><a href="https://dev.to/olvrng/ezpkgio-collection-of-packages-to-make-writing-go-code-easier-2fid" target="_blank" rel="noopener noreferrer">ezpkg.io - Collection of packages to make writing Go code easier</a></li><li><a href="https://twitter.com/GolangTrends/status/1807933708285919382" target="_blank" rel="noopener noreferrer">How to Implement Two-Factor #Authentication (2FA) in #Golang</a></li></ul></div></div><p><a href="https://juejin.cn/post/7380222254195638284" target="_blank" rel="noopener noreferrer">Golang 开发不能错过的优质的开源项目</a></p><p><a href="https://juejin.cn/post/7382775817581051904" target="_blank" rel="noopener noreferrer">从 Docker Hub 拉取镜像受阻？这些解决方案帮你轻松应对</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/yaJnbGZDSKPn-bd5uusu2g" target="_blank" rel="noopener noreferrer">从零开始：使用 pyo3-arrow 打造高效的 Python-Rust 数据桥梁</a></p><p><a href="https://mp.weixin.qq.com/s/N_MIkcINvqxuuYmRArT9uQ" target="_blank" rel="noopener noreferrer">Go 的 iota 并非枚举</a></p><p><a href="https://mp.weixin.qq.com/s/xL1PN0R02qT1-4-xizwxRA" target="_blank" rel="noopener noreferrer">Go语言助力安全测试：24小时内发送5亿次HTTP/1.1请求</a></p><p><a href="https://mp.weixin.qq.com/s/830wxM4ECYm-vAjYyeEzJw" target="_blank" rel="noopener noreferrer">使用 Go 提供的 Cookie 库简化 Cookie 操作</a></p><p><a href="https://mp.weixin.qq.com/s/ULlA9zi62-HS04M-mRcKOQ" target="_blank" rel="noopener noreferrer">在 Rust 中轻松转换 HTML 到 Markdown</a></p><p><a href="https://mp.weixin.qq.com/s/_EczFx3SYYi_Q11udm_hsQ" target="_blank" rel="noopener noreferrer">Golang 编写范型集合，官方文档未提及的诀窍</a></p><p><a href="https://mp.weixin.qq.com/s/cIWs8JQybOps64cws_uySg" target="_blank" rel="noopener noreferrer">以 Go 语言为例解释什么是伪共享以及如何解决</a></p><p><a href="https://mp.weixin.qq.com/s/tGOb4BFCvkl64rK9bzv-IQ" target="_blank" rel="noopener noreferrer">[<!-- -->Go Official<!-- -->]<!-- -->Go 1.22 升级后的更加鲁棒的切片操作</a></p><p><a href="https://mp.weixin.qq.com/s/IB-EQEcOQcUIqosz0RMveg" target="_blank" rel="noopener noreferrer">Go 1.23中的自定义迭代器与iter包</a></p><p><a href="https://mp.weixin.qq.com/s/icGvEVrjnRGopzZ130Co3A" target="_blank" rel="noopener noreferrer">Go必知必会：解锁 Go 语言函数的玩法</a></p><p><a href="https://mp.weixin.qq.com/s/BFx3G1wrghbqBc8sl-Bdpw" target="_blank" rel="noopener noreferrer">如何架构优秀的Go后端REST API服务</a></p><p><a href="https://mp.weixin.qq.com/s/Cm73sI2cq7Id2TeZFbFIsA" target="_blank" rel="noopener noreferrer">Go 1.22.5 修复 net/http 包中由于不正确的 100-continue 处理而拒绝服务的安全问题</a></p><p><a href="https://mp.weixin.qq.com/s/6KqG53y_9QwFCKAFe66D4w" target="_blank" rel="noopener noreferrer">在 Go 中如何检查结构体是否为空</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/8kWCH_X6-OVigM67WApCzQ" target="_blank" rel="noopener noreferrer">gaby：基于大模型的GitHub助手亮相Go项目</a></p><p><a href="https://mp.weixin.qq.com/s/FkU_48cG_ws8b7WNd_Cc2Q" target="_blank" rel="noopener noreferrer">Golang 对接并部署 helm charts</a></p><p><a href="https://mp.weixin.qq.com/s/C4qDhKIe5-4uZx09vrSmiA" target="_blank" rel="noopener noreferrer">Go 使用 interface 时的 7 个常见错误</a></p><p><a href="https://mp.weixin.qq.com/s/uL3p9_5wCBMUJv8s7RpBAw" target="_blank" rel="noopener noreferrer">Docker镜像拉取最优解！养一只小猫，利用crproxy高速无感镜像拉取</a></p><p><a href="https://mp.weixin.qq.com/s/wHjOxZFz0I3F1_a43-zGoQ" target="_blank" rel="noopener noreferrer">qsv：Rust实现一个处理CSV文件的简单，快速和可组合的命令行工具</a></p><p><a href="https://mp.weixin.qq.com/s/vR15Z_beG-7T3fgtHeessA" target="_blank" rel="noopener noreferrer">如何设计一个分布式数据实时同步系统</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://juejin.cn/post/7379960023407804428" target="_blank" rel="noopener noreferrer">告别面条代码，让代码一开始就简洁</a></p><p><a href="https://juejin.cn/post/7350936959060541480" target="_blank" rel="noopener noreferrer">不是，你还在随便设计数据库字段类型和长度</a></p><p><a href="https://mp.weixin.qq.com/s/_xFqDks7tVoGCjh42XE7vA" target="_blank" rel="noopener noreferrer">秒杀圣经：10Wqps高并发秒杀，16大架构杀招，帮你秒变架构师</a></p><p><a href="https://mp.weixin.qq.com/s/LBcOfwO6ScOd2HNUfver8g" target="_blank" rel="noopener noreferrer">从一个服务预热不生效问题谈微服务无损上线</a></p><p><a href="https://mp.weixin.qq.com/s/SBlNFsZzl5haHsZugdudSg" target="_blank" rel="noopener noreferrer">Spring Cloud + Nacos + 负载均衡器实现全链路灰度发布实战</a></p><p><a href="https://mp.weixin.qq.com/s/iYa41K9jITQV3ikoO-Ka3w" target="_blank" rel="noopener noreferrer">Navicat 竟然免费了？可惜我有更好用的。。</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/YBLcpIEmi-yyiTWtBqBSJA" target="_blank" rel="noopener noreferrer">MySQL日志15连问，你能抗住嘛</a></p><p><a href="https://mp.weixin.qq.com/s/1Evn8Sl_FwWce0uMcVFs0g" target="_blank" rel="noopener noreferrer">【收藏】MySQL 超全优化清单（可执行系列）</a></p><p><a href="https://mp.weixin.qq.com/s/e77LVBMXzILs74o4HO2mrQ" target="_blank" rel="noopener noreferrer">电商后端开发，COLA 状态机在订单系统中的实战</a></p><p><a href="https://mp.weixin.qq.com/s/jh8KrwtCx-4kvqczgYzoLA" target="_blank" rel="noopener noreferrer">熔断、隔离、重试、降级、超时、限流，一文帮你顺理高可用架构流量治理</a></p><p><a href="https://mp.weixin.qq.com/s/_sPs0NB4zWef-pW17DKimg" target="_blank" rel="noopener noreferrer">架构之道：人人都是架构师</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/mjiu3J7rscTpX_BewLyqkg" target="_blank" rel="noopener noreferrer">11个高可用设计实战技巧，轻松应对大厂面试</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/tcpmpt7jiYbsz-FslKElMw" target="_blank" rel="noopener noreferrer">订单支付超时如何处理？盘点延迟任务的11种实现方式，你知道几种</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/gSMUzIGCe8Vxlc5NPzMSbw" target="_blank" rel="noopener noreferrer">DuckDB 纯 SQL 实现混合搜索：精准与语义兼得</a></p><p><a href="https://mp.weixin.qq.com/s/z-_ixPeksB_PjFMNL7NA8Q" target="_blank" rel="noopener noreferrer">DuckDB实战：单机2.5小时处理450GB投票数据</a></p><p><a href="https://mp.weixin.qq.com/s/vif0SAvqz-PpBlhViYCFhA" target="_blank" rel="noopener noreferrer">使用懒加载 + 零拷贝后，程序的秒开率提升至99.99%</a></p><p><a href="https://mp.weixin.qq.com/s/ZqUa-weWXBTUPLhZ-UeHVQ" target="_blank" rel="noopener noreferrer">elasticSearch 是什么？工作原理是怎么样的</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/LEfevL6O70RyBbLhG1ScoA" target="_blank" rel="noopener noreferrer">React 19 新 hook —— useActionState 与 Next.js Server Actions 绝佳搭配</a></p><p><a href="https://mp.weixin.qq.com/s/vlYiMpPiWD4yo-5s0N9dPA" target="_blank" rel="noopener noreferrer">实现一个支持@的输入框</a></p><p><a href="https://mp.weixin.qq.com/s/NuH-sga13okeMVGDFZWFtQ" target="_blank" rel="noopener noreferrer">前端工程化系列一：序言</a></p><p><a href="https://mp.weixin.qq.com/s/E6GTSOJd2LY5NdeBQqIdzw" target="_blank" rel="noopener noreferrer">前端项目路径别名终极解决方案</a></p><p><a href="https://mp.weixin.qq.com/s/AOsLfzUXevvQhgeLiJhbiA" target="_blank" rel="noopener noreferrer">老板：给你20天，写一个可拖拽动态表单生成器</a></p><p><a href="https://mp.weixin.qq.com/s/fbrsqWwqIQeckGLoRbx4uA" target="_blank" rel="noopener noreferrer">Chrome 127 内置 AI Gemini 大模型，JS 可直接调用！</a></p><p><a href="https://mp.weixin.qq.com/s/_uG0JRkNI01L3H9x25envw" target="_blank" rel="noopener noreferrer">周百万下载量的 NPM 包可执行任意 JS 代码，数十万网站可能受影响！</a></p><p><a href="https://mp.weixin.qq.com/s/O0YwzJ5AYTn7gvizN4cjag" target="_blank" rel="noopener noreferrer">前端可以玩“锁”了</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/6月30日内容汇总">6月30日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-06-30T00:00:00.000Z" itemprop="datePublished">June 30, 2024</time> · <!-- -->45 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/image-50e4ec0a985d6c9989a4c245cc777605.png" width="900" height="520" class="img_astN"></p><p>封面图：Go 1.23 rc1 已发布，包括极具争议的迭代器</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><div class="theme-admonition theme-admonition-tip alert alert--success admonition_kCt_"><div class="admonitionHeading_oZsk"><span class="admonitionIcon_tnIl"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>技术资讯</div><div class="admonitionContent_m8BQ"><ul><li><a href="https://twitter.com/rohanpaul_ai/status/1806501254937313407" target="_blank" rel="noopener noreferrer">OpenAI is training a new model CriticGPT, to catch bugs in GPT-4’s code and to reduce hallucinations</a></li><li><a href="https://twitter.com/karpathy/status/1799949853289804266" target="_blank" rel="noopener noreferrer">New 4 hour (lol) video lecture on YouTube: &quot;Let’s reproduce GPT-2 (124M)&quot;</a></li><li><a href="https://twitter.com/shao__meng/status/1806479762975752352" target="_blank" rel="noopener noreferrer">OmniParse：可将任何非结构化数据提取/解析为针对 LLM 应用优化的结构化、可操作数据</a></li><li><a href="https://twitter.com/tuturetom/status/1806312637883703331" target="_blank" rel="noopener noreferrer">DB-GPT: 构建生产级别的 AI Native Agent 应用！⚡️🔥蚂蚁开源首个 GraphRAG 框架！支持图可视化和详细示例代码！</a></li><li><a href="https://twitter.com/tuturetom/status/1806507828791939098" target="_blank" rel="noopener noreferrer">自动化数据标注更进一步！Human in the Loop 🥳 OpenAI 发布新模型 CriticGPT「LLM 评论家」并公布论文⚡️</a></li><li><a href="https://twitter.com/AIatMeta/status/1806361623831171318" target="_blank" rel="noopener noreferrer">Announcing Meta LLM Compiler: a family of models built on Meta Code Llama with additional code optimization and compiler capabilities</a></li><li><a href="https://twitter.com/jerryjliu0/status/1806353914125861376" target="_blank" rel="noopener noreferrer">Announcing llama-agents： a framework for turning your set of agent functions into microservices that can communicate via an API interface</a></li><li><a href="https://twitter.com/tuturetom/status/1806360256857211364" target="_blank" rel="noopener noreferrer">力压 Llama3！最强开源模型来了！😆就在刚刚！Google I/O 柏林宣布开源 Gemma2！🔥9B/27B模型</a></li><li>这个 prompt 确实不错：“用逐渐增加复杂度的方式解释 XXX”</li><li><a href="https://twitter.com/aigclink/status/1806493149763932275" target="_blank" rel="noopener noreferrer">Meta推出了Meta LLM 编译器（Meta Large Language Model Compiler）</a></li><li><a href="https://twitter.com/hongming731/status/1805941651405479970" target="_blank" rel="noopener noreferrer">深度剖析字节豆包 AI</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1806100957710991670" target="_blank" rel="noopener noreferrer">Very powerful prompt: &quot;Explain it with gradually increasing complexity.&quot;</a></li><li><a href="https://twitter.com/Saboo_Shubham_/status/1805789990431211686" target="_blank" rel="noopener noreferrer">Find all the awesome LLM Apps demo with RAG in the following Github Repo</a></li><li><a href="https://twitter.com/HiTw93/status/1806113714522804259" target="_blank" rel="noopener noreferrer">发现一个很不错的 AI 学习网站 Emergent Mind，通过抓取 arXiv 上 AI 最新研究论文，再用 GPT 去总结，通过分类、趋势流行度、时间来筛选，很适合学术研究，需静下心来看看</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1806100283853779166" target="_blank" rel="noopener noreferrer">A great dataset just arrived in @huggingface</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1805896032602997201" target="_blank" rel="noopener noreferrer">You can do A MASSIVE cost saving (up to 10x)💰 and Boost Speed by upto 100x ⚡ for your OpenAI/HuggingFace Hub/Bard/Anthropic API calls by using caching with GPTCache library</a></li><li><a href="https://twitter.com/eviljer/status/1805902754239656141" target="_blank" rel="noopener noreferrer">一键「代码可视化」辅助工具设计</a></li><li><a href="https://twitter.com/aigclink/status/1805827636272546123" target="_blank" rel="noopener noreferrer">Claude官方给的这个提示库非常好，包含了从生成电子表格、创建网站到会议记录、分析推文等多种类型的高品质提示词等</a></li><li><a href="https://twitter.com/shao__meng/status/1805397985498644972" target="_blank" rel="noopener noreferrer">系统设计入门 @donne_martin 262k✨</a></li><li><a href="https://twitter.com/llama_index/status/1805622494130586078" target="_blank" rel="noopener noreferrer">Building Optimized RAG with LlamaIndex + DSPy</a></li><li><a href="https://twitter.com/shao__meng/status/1805601464922128536" target="_blank" rel="noopener noreferrer">RAG 十二个痛点和解决方案</a></li><li><a href="https://twitter.com/HiTw93/status/1805743777128013841" target="_blank" rel="noopener noreferrer">看到一个全栈 DS / DA 数据分析岗位养成手册，来自一名哥大数据科学的学生 Jace 整理的，很适合数据分析科学入门学习使用，结合了不少国内的案例来分析学习</a></li><li><a href="https://twitter.com/eviljer/status/1805270212025209140" target="_blank" rel="noopener noreferrer">🔮 手搓 Figma 插件，接入 #Gemini Vision</a></li><li><a href="https://twitter.com/HiTw93/status/1805386673968365669" target="_blank" rel="noopener noreferrer">假如你在有意识的去学理财，这个 TradingView 会很好用，特别对于买股票的小伙伴，可以很清楚看到世界股票的排名以及各种维度的分析，比如这个「按市值计算的全球最大公司排名」，我经常用它来分析一些关注的股票很好用，从一些科学维度来看是否该买这支</a></li><li><a href="https://twitter.com/snehilsanyal/status/1804750939519357028" target="_blank" rel="noopener noreferrer">🤗🤗 @huggingface Community-led Computer Vision Course</a></li><li><a href="https://twitter.com/rohanpaul_ai/status/1804932544263012793" target="_blank" rel="noopener noreferrer">Claude 3.5 Sonnet&#x27;s coding skills and the Artifacts are just insane. 👨‍🔧 </a></li><li><a href="https://twitter.com/eviljer/status/1804837427468779879" target="_blank" rel="noopener noreferrer">GPT-4 中做思维导图，一些可行的方法参考</a></li></ul></div></div><ul><li><p><a href="https://mp.weixin.qq.com/s/BesgaZ-Dj0DosZks1mvuRg" target="_blank" rel="noopener noreferrer">2024稀土开发者大会精彩亮点|代码不止 掘金不停</a></p><ul><li>本文作者介绍了在2024稀土开发者大会上，五位技术嘉宾分享了开源生态、新技术发现及应对技术变革的策略，探讨了AI在多媒体内容生成、教育等领域的应用，以及如何通过开放生态系统推动企业人工智能的发展。</li><li>演讲嘉宾还讨论了生成式AI对现实世界的影响、AI编程工具的未来发展方向、大模型部署成本降低策略，以及Mistral模型的发展和应用，强调了评估在生成式AI开发过程中的重要性，并探讨了AI基础设施的优化策略。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/ZJTfCkWOrE8omRZEhrj_3g" target="_blank" rel="noopener noreferrer">Semantic Kernel:微软开源的 LangChain 替代</a></p><ul><li>本文作者介绍了微软开源的Semantic Kernel，这是一个轻量级的开源软件开发工具包（SDK），旨在帮助开发者将AI功能集成到应用程序中。它提供了灵活的插件架构、AI驱动的插件编排和多语言支持（C#、Python和Java）。</li><li>文章详细比较了Semantic Kernel与LangChain的特点和优势，强调了Semantic Kernel在企业级功能、安全性、模块化和自动化业务流程方面的优势，适合构建需要与现有系统集成的企业级AI应用程序。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/Me2PCh_-WUwaZK4s3oK-OA" target="_blank" rel="noopener noreferrer">陈丹琦团队图表解读新基准:新王Claude3.5刚及格，但已是模型最强推理表现</a></p><ul><li>本文作者陈丹琦团队提出了新的图表任务测试基准CharXiv，涵盖2323张来自arXiv论文的真实图表，旨在更好地评估多模态大模型的图表推理能力。与以往的数据集相比，CharXiv难度更大，问题类型更广泛。</li><li>研究发现，尽管Claude 3.5 Sonnet在推理任务中表现最好，但也仅仅及格，整体模型在推理问题上的表现仍不理想。描述能力强的模型通常推理能力也强，但反之不一定成立。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/YtPPIc73rNAiPu-OyMFTYg" target="_blank" rel="noopener noreferrer">谷歌开源系模型第二代免费开放!27B媲美LLaMA3 70B，单H100或TPU主机可跑</a></p><ul><li>本文作者介绍了谷歌开源的Gemma 2模型，该模型在27B参数规模下提供了与LLaMA3 70B相媲美的性能，并且可以在单个NVIDIA H100或TPU主机上运行。Gemma 2还包括一个更轻的9B版本，性能同样出色。</li><li>Gemma 2采用了Gemini同款技术架构，具有更高的推理效率和安全性。其关键特点包括交替使用局部滑动窗口注意力和全局注意力机制，以及分组查询注意力（GQA）。此外，谷歌计划在下个月通过Google Cloud的Vertex AI平台提供Gemma 2的部署和管理服务。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/mS-NhSAb2-T3Ti14HepDAA" target="_blank" rel="noopener noreferrer">别再被大模型骗了，一个小技巧，让LLaMa3诚信度提升65%</a></p><ul><li>本文介绍了华中科技大学团队提出的新框架，通过理论和实践提升大语言模型的诚实性和有益性。他们构建了HoneSet数据集，并设计了针对开源和商业模型的优化方法。实验表明，经过两阶段微调后，LLaMa3的诚信度提升了65%。</li><li>研究重点在于通过提示优化和两阶段微调，使模型在面对不同类型问题时更诚实可靠。该方法在包括GPT-4、ChatGPT和Claude等多个主流模型上均取得了显著成效，展示了其广泛适用性。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/KxaiKjrsMyy8kh7Sju2oJg" target="_blank" rel="noopener noreferrer">RAG、ROG、RCG傻傻分不清?概念辨识及RCG在SimplyRetrieve中的naive实现</a></p><ul><li>本文介绍了RAG（检索增强型生成）、ROG（检索关闭型生成）和RCG（检索中心型生成）的概念及其区别。RAG结合外部数据和模型内在知识，ROG完全依赖模型内在知识，而RCG强调上下文解释与知识记忆的分离，通过检索器提供知识，语言模型负责解释。</li><li>文章还讨论了RCG在SimplyRetrieve中的实现，指出尽管RCG方法被认为更清晰和有效，但在实际应用中通过提示词进行简单区分的方法仍存在可行性和泛化性的问题。RCG的实现难点在于明确区分语言模型和检索器的角色。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/Zy-kM3bvN-1oHondw1VLzw" target="_blank" rel="noopener noreferrer">Bengio团队提出多模态新基准，直指Claude 3.5和GPT-4o弱点</a></p><ul><li>本文作者张天宇介绍了由图灵奖得主Yoshua Bengio团队提出的新视觉问答任务“视觉字幕恢复（VCR）”，该任务旨在评估视觉语言模型（VLM）的推理能力。研究表明，现有模型在处理复杂推理任务时仍存在显著差距，尤其是在被遮挡文字的恢复上，模型表现远不及人类。</li><li>通过构建VCR数据集，研究团队发现大多数模型无法有效利用图像信息来提升准确率，特别是在困难难度下，模型的表现极差。该任务揭示了模型在图像和文本对齐方面的局限性，并为未来多模态模型的训练和评测提供了新的方向。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/OQiRDhRMzwRdF-GHi8-egQ" target="_blank" rel="noopener noreferrer">Multi-Head RAG:多头注意力的激活层作为嵌入进行文档检索</a></p><ul><li>本文由黄继彦介绍了一种新的多头RAG (MRAG)方案，通过利用Transformer模型中的多头注意力层激活，而非传统的前馈层激活来进行文档检索。MRAG能够在不增加存储需求的情况下，捕获数据的多面性，显著提高文档检索的相关性和准确性。</li><li>实验结果表明，MRAG在检索成功率上比标准RAG提高了10-20%，并且在实际应用中，如法律文件合成和工业事故原因分析中，也展示了其优越性。MRAG通过综合评估和实际用例证明了其有效性和广泛适用性。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/Q4NljU7V9YSfiyycF8s74Q" target="_blank" rel="noopener noreferrer">DCGen:一种新的Design-to-Code框架，设计稿转代码有效性提高</a></p><ul><li>本文作者张天宇介绍了DCGen，一个基于分而治之策略的Design-to-Code框架，通过将复杂的设计稿拆分为更小的视觉单元，再利用多模态大模型（MLLM）生成每个单元的代码，最后整合成完整代码。DCGen有效提升了设计稿转代码的准确性和视觉相似性。</li><li>实验表明，DCGen在视觉相似性和代码相似性方面比传统方法提升了14%，特别是在处理复杂网页设计时表现尤为出色。DCGen的创新在于其分割和组装阶段的递归处理方法，使其在多种复杂度的网站中均表现优异。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/5UHSKB_V5Cdtl4jrWE1aQw" target="_blank" rel="noopener noreferrer">Google 发布最新开放大语言模型 Gemma 2，现已登陆 Hugging Face Hub</a></p><ul><li>本文由机器之心发布，介绍了Google最新发布的开放大语言模型Gemma 2。该模型有两种规模：90亿参数和270亿参数，分别有基础（预训练）和指令调优版本。Gemma 2基于Google DeepMind的Gemini，拥有8K Tokens的上下文长度，并在Hugging Face Hub上提供四个开源模型。</li><li>Gemma 2在滑动窗口注意力、Logit软上限、知识蒸馏和模型合并方面进行了技术创新。实验结果显示，Gemma 2在多个基准测试中表现优异，特别是在长上下文情况下生成质量显著提高。用户可以在Hugging Chat上体验Gemma 2，并通过Hugging Face Transformers集成进行使用。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/tP1iLkI5-tcUwmtUqelBKQ" target="_blank" rel="noopener noreferrer">DB-GPT:蚂蚁开源的Text-to-SQL利器</a></p><ul><li>本文由蚂蚁集团介绍了DB-GPT，一个AI原生数据应用开发框架。DB-GPT通过自然语言交互，实现对数据库的高效查询和数据分析，支持多种数据源和大语言模型，并提供私有化部署和数据脱敏功能，确保数据安全。</li><li>DB-GPT的核心特性包括私域问答、数据处理与RAG、向量存储与检索、多源数据连接、生成式商业智能、多模型管理与自动化微调、数据驱动的智能体与插件扩展等，适用于企业内部知识库问答、产品文档智能客服、市场分析、用户画像分析等多种应用场景。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/Gl74YZn4ylxSHAkwUFB-FA" target="_blank" rel="noopener noreferrer">吴恩达:从 Agent 到 Agentic，超越基础模型的下一代 AI</a></p><ul><li>本文由子非AI发布，介绍了吴恩达在2024年Snowflake峰会上的演讲，探讨了Agentic AI的概念及其潜力。Agentic AI不同于传统的被动AI系统，它赋予AI主动思考、规划和执行任务的能力，通过代理型工作流程（Agentic workflow）来提升AI系统的性能。</li><li>吴恩达强调，Agentic AI可以在复杂任务中分解步骤并通过迭代优化结果，展现出比下一代基础模型更大的潜力。实验表明，即使是较弱的模型在采用Agentic workflow后也能超越更强的模型，展示了Agentic AI在代码生成和视觉任务等领域的广泛应用前景。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/VSx4RlyrLYbdDp3IuUF6Cw" target="_blank" rel="noopener noreferrer">Florence-2:微软开源的轻量级视觉基础模型，吊打巨型模型!</a></p><ul><li>本文由子非AI撰写，介绍了微软开源的轻量级视觉基础模型Florence-2。Florence-2包含两个模型：Florence-2-base（2.3亿参数）和Florence-2-large（7.7亿参数），尽管参数规模较小，但在字幕生成、目标检测、定位和分割等多个视觉任务中表现出色，甚至超越了规模更大的模型。</li><li>Florence-2采用多任务学习方法，使用大量高质量的视觉标注进行训练，解决了数据有限和缺乏统一架构的挑战。其核心优势包括轻量级架构、强大功能和统一表示。训练数据集FLD-5B包含1.26亿张图像和54亿个标注，支持多任务学习和数据驱动的智能体扩展。</li></ul></li><li><p>🌟 <a href="https://mp.weixin.qq.com/s/SIL1Xx_GxJOpp26k7p-VUg" target="_blank" rel="noopener noreferrer">LLM推理引擎性能评测:vllm、lmdeploy、tensorrt-llm 请应战!</a></p><ul><li>本文由魔搭社区撰写，评测了三种LLM推理引擎：vllm、lmdeploy和tensorrt-llm。在单并发和多并发情况下，对不同模型和数据集的性能进行了详细对比。评测指标包括吞吐量（Throughput）、首包延迟（TTFT）、每个输出token的时间和整体请求延迟等。</li><li>结果显示，vllm在首包延迟方面表现最好，适合少量用户的高体验需求；lmdeploy在吞吐量上优势明显，适合大规模用户服务；tensorrt-llm尽管需要较高的使用成本，但在特定场景下也有其优势。文章还介绍了使用EvalScope工具进行性能压测的方法。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/hmIvSsZ2-yKEeiXUNRlTQw" target="_blank" rel="noopener noreferrer">Hugging Face Accelerate 两个后端的故事:FSDP 与 DeepSpeed</a></p><ul><li>本文由Matrix Yao翻译，介绍了Hugging Face Accelerate对DeepSpeed和PyTorch FSDP两种零冗余优化器（ZeRO）算法的集成及其差异。通过实验，作者发现DeepSpeed在损失函数收敛性方面表现更好，而FSDP需要根据GPU数量调整学习率才能达到预期效果。</li><li>文章还讨论了两种算法在混合精度训练中的处理方式，指出DeepSpeed强制将主权重保持为fp32精度，而FSDP提供了更大的灵活性。最后，作者通过吞吐量测试对比了两者在实际应用中的表现，并提供了相关的概念指南帮助用户在两者之间迁移。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/ics2qC5sZe7W0T1TSnlXTw" target="_blank" rel="noopener noreferrer">独家 | 进阶RAG-提升RAG效果</a></p><ul><li>本文由黄继彦编辑，讨论了如何优化RAG（Retrieval-Augmented Generation）管道的各个部分，以提升整体性能。文章详细介绍了从Pre-Retrieval、Retrieval到Post-Retrieval的各项优化技术，包括数据清洗、添加元数据、优化索引结构、分块优化、查询重写和微调嵌入模型等。</li><li>通过这些优化技术，RAG系统可以在生成更加准确和高效的回答时，显著提高检索的相关性和响应速度。这些技术适用于各种复杂查询和信息需求，确保系统在生产环境中的高效应用。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/a5jrweBfkDT64prIGCLBOg" target="_blank" rel="noopener noreferrer">最新决议，老黄涨薪60%!英伟达股东大会通过，可老黄在偷偷卖股票</a></p><ul><li>本文由奶茶编辑，报道了英伟达在最新股东大会上通过了CEO黄仁勋薪酬上涨60%的决议，2024财年的总薪酬将达到3416.8万美元。文章还指出，尽管薪酬上涨，黄仁勋近期却在持续出售自己持有的股票，引发了外界的诸多猜测。</li><li>文章详细记录了黄仁勋在股东大会上的发言，讨论了英伟达在自动驾驶、加速计算和生成式人工智能等领域的领先地位，并强调了英伟达对未来计算技术和工业革命的影响。同时，文章也提到英伟达在医疗保健、汽车和数字制造等行业的多元化战略。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/HrZB4qNga69ePxJvcRiHTA" target="_blank" rel="noopener noreferrer">一文梳理有效提升RAG效果的方法</a></p><ul><li>本文由黄继彦编辑，梳理了提升RAG（Retrieval-Augmented Generation）效果的方法，首先介绍了几篇关于RAG优化的论文，包括RAPTOR、Self-RAG、CRAG和Dense X Retrieval等。这些方法通过改进检索和生成过程，提高了RAG系统的准确性和可靠性。</li><li>文章还记录了一些RAG工程实践经验，如文本切割优化、查询重写和混合检索策略等。这些技术帮助RAG系统在处理复杂查询和信息需求时，提高检索的相关性和响应速度，确保系统在生产环境中的高效应用。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/O78XDeG2uQARYAUEh4VbvQ" target="_blank" rel="noopener noreferrer">五个维度，详解LLM-based Agent中的规划(planning)能力</a></p><ul><li>本文由黄继彦编辑，详细梳理了LLM-based Agent中的规划能力，分为任务分解、规划选择、外部辅助规划、反馈和改进、记忆五个维度。每个维度都探讨了相关的研究工作和实践经验，如任务分解方法中的HuggingGPT和Chain-of-Thought (CoT)等。</li><li>文章还讨论了这些方法的优缺点及面临的挑战，包括LLM在复杂任务中的幻觉问题、生成计划的可行性及效率问题等。未来方向包括多模态环境反馈和细粒度评估，以提高LLM在实际应用中的规划能力。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/SW62l1J92xzo108-jCe9pQ" target="_blank" rel="noopener noreferrer">更难、更好、更快、更强:LLM Leaderboard v2 现已发布</a></p><ul><li>本文由RLHF团队撰写，介绍了Open LLM Leaderboard v2的发布背景及其改进。新版本通过更具挑战性的基准测试，如MMLU-Pro、GPQA和MuSR，解决了现有基准测试过度使用和数据污染的问题，以更好地评估大语言模型（LLMs）的实际性能。</li><li>文章还介绍了排行榜的新功能，包括使用标准化得分报告更公平的排名、更新评估套件以确保可复现性，以及引入社区投票系统和维护者推荐，帮助用户找到最有用和高质量的模型。新排行榜旨在推动开放和可复现的模型评估，促进LLM领域的持续进步。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/pxQzCUys3tJfRHVzIjbHsA" target="_blank" rel="noopener noreferrer">迪士尼笑了!陈丹琦团队最新研究，打造AI&quot;版权护盾&quot;，AI创新不侵权</a></p><ul><li>本文由陈丹琦团队撰写，介绍了普林斯顿大学计算机科学系助理教授陈丹琦及其团队开发的新方法，结合提示词重写技术与负面提示词策略，旨在生成过程中规避使用受保护的内容，既保障了创新，又尊重了知识产权，堪称AI领域的&quot;版权护盾&quot;。</li><li>文章还阐述了COPYCAT评估套件的使用，通过对多个主流AI模型进行测试，验证了新方法在降低生成版权角色图像风险方面的有效性，并提出了未来在保护知识产权与发挥AI创造力之间寻求平衡的可能性。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/pAB_ezlEmUCM98n1eQX0ZQ" target="_blank" rel="noopener noreferrer">耳朵没错，是声音太真了，字节豆包语音合成成果Seed-TTS技术揭秘</a></p><ul><li>本文由字节跳动豆包大模型团队撰写，介绍了其最新发布的语音生成大模型Seed-TTS。该模型能够生成几乎与真人无异的语音，包括发音瑕疵，且在模仿人类说话方面表现出色。Seed-TTS通过文本生成全新语音，并能复刻原素材的声音特征。</li><li>文章详细阐述了Seed-TTS在生成细节、自然度和稳定性上的技术挑战和解决方案，以及其在数据覆盖、模型设计和工程方面的创新。Seed-TTS的发布标志着语音生成技术的新高度，应用场景广泛，未来潜力巨大。</li></ul></li><li><p>🌟 <a href="https://mp.weixin.qq.com/s/25eXZi1QgGYIPpXeDzkQrg" target="_blank" rel="noopener noreferrer">我做了一个 AI 搜索引擎</a></p><ul><li>本文由ThinkAny团队撰写，介绍了他们开发的AI搜索引擎ThinkAny。文章详细描述了ThinkAny的技术架构、发展历程及其在全球市场的冷启动成功经验。ThinkAny利用RAG（检索增强生成）技术，结合多语言支持和高效的AI回答功能，目标是实现更快、更准的搜索体验。</li><li>文章还探讨了AI搜索引擎的核心要素，如准确度、响应速度和高可用性，并介绍了ThinkAny在多模式使用、多模型对话和多模态检索等方面的创新功能。作者分享了对AI搜索市场的看法，认为准确度和平台化是未来发展的关键，并强调了成本优化和差异化创新的重要性。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/uQ_MQwAo5FbVsaGSGKzaQA" target="_blank" rel="noopener noreferrer">大模型综述:万字长文详解AI大模型的原理、应用与未来趋势</a></p><ul><li>本文由AI领域专家撰写，详细介绍了大语言模型（LLMs）的发展历程、独特魅力及其在现实世界中的多彩应用。文章回顾了从统计语言模型到神经语言模型再到预训练语言模型的演进过程，强调了LLMs在上下文理解、少样本学习、多模态融合、推理和问题解决以及持续学习和适应方面的强大能力。</li><li>文章还探讨了LLMs在日常生活、工作场景、教育、创意写作和商业世界中的应用，展示了其在智能手机输入法、编程助手、AI助教、创意写作辅助和客户服务等方面的广泛应用前景。通过实际案例和代码示例，文章生动展示了LLMs在各领域带来的革命性变革。</li></ul></li><li><p>🌟 <a href="https://mp.weixin.qq.com/s/Cj39J18hXOAkIzHd7HAjXw" target="_blank" rel="noopener noreferrer">Qwen2大模型微调入门实战-命名实体识别(NER)任务</a></p><ul><li>本文由通义千问团队撰写，介绍了如何使用阿里云通义实验室研发的Qwen2大语言模型进行命名实体识别（NER）任务的指令微调。文章详细描述了指令微调的概念及其在提升模型理解和执行特定指令能力方面的作用，并通过实际案例展示了微调后的模型在NER任务中的应用。</li><li>文章提供了从环境安装、数据准备、模型加载到训练过程的详细步骤，并介绍了如何使用SwanLab工具监控训练过程和评估模型效果。通过LoRA方法训练，Qwen2-1.5B模型能够在显存需求较低的情况下实现高精度的NER任务，展示了大模型在实际NLP应用中的强大能力和广泛前景。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/V4Mg1e4I6aHsF_D9-rrQBQ" target="_blank" rel="noopener noreferrer">CodeRAG-Bench:RAG遇到了Coder，哪个模型在RAG的加持下最会写代码?</a></p><ul><li>本文由AI研究团队撰写，介绍了CodeRAG-Bench评估基准，用于检验检索增强生成（RAG）技术在代码生成任务中的效果。文章详细描述了CodeRAG-Bench的构建流程，包括编程问题分类、检索资料收集、标注标准文档和设置评估流程，并测试了多个顶尖代码生成模型在不同任务中的表现。</li><li>文章探讨了高质量上下文对代码生成的显著提升作用，但也指出了当前检索器和生成器在处理复杂上下文和整合信息方面的不足。研究发现，尽管RAG技术能提升代码生成的准确性，但仍需优化检索系统和模型处理上下文的能力，以实现更高效的代码生成。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/a0EETNnbWBEzXJBaLJ_zAA" target="_blank" rel="noopener noreferrer">开源模型破局OpenAI服务限制，15分钟灵活搭建RAG和Agent应用</a></p><ul><li>本文由AI实验团队撰写，介绍了如何在15分钟内利用开源模型替代OpenAI服务，灵活搭建RAG和Agent应用。文章通过两个实验展示了Qwen2与Ollama、LlamaIndex及LangChain的结合应用，详细描述了从环境安装、模型下载、配置文件创建到代码运行的全过程。</li><li>实验一展示了如何使用Qwen2与LlamaIndex实现RAG应用，实验二则展示了Qwen2与LangChain结合实现Agent应用。文章强调了在本地设备上快速部署和运行开源模型的便捷性，提供了详细的代码示例和步骤说明，帮助读者快速上手并实现相应功能。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/0Cv7adCioN9ZT8OaL6ifTg" target="_blank" rel="noopener noreferrer">7月9日生效!OpenAI将封杀不支持地区API，违规者将面临封号!</a></p><ul><li>本文介绍了OpenAI将于7月9日开始封锁不支持地区的API访问，违规者将面临封号。文章指出，OpenAI检测用户使用其API的地区，并警告不支持位置的用户即将封禁“非法”流量。这一举措将导致部分开发者需要更换工具，一些“套壳”应用也会因此暴露。</li><li>此外，文章提到OpenAI在新版本的ChatGPT iOS应用中增加了高级语音模式选项，并开始alpha版本的灰度测试。该语音模式具备实时响应自然对话、感知用户情绪和视频聊天等功能，Plus用户将很快获得GPT-4o的完整版功能。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/BgMNITn5e1RGUOHQLKv7yg" target="_blank" rel="noopener noreferrer">语言≠思维，大模型学不了推理:一篇Nature让AI社区炸锅了</a></p><ul><li>这篇由麻省理工学院等机构发表在《自然》杂志上的文章指出，人类大脑生成和解析语言的神经网络并不负责形式化推理，语言主要是用于交流的工具，而不是思考的工具。文章通过神经科学和相关学科的最新证据，挑战了语言对于复杂思维的必要性。</li><li>文章引发了科技领域的广泛讨论，特别是在AI社区。研究表明，即使没有语言能力，人类仍然能够进行复杂的思维和推理。文章讨论了语言网络的特性及其在思维和认知中的作用，强调了语言和推理的平行发展而非依赖关系。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/dDaYBhewnc9-GslzS7vv1A" target="_blank" rel="noopener noreferrer">Skywork AI | 提出新框架:Q*，旨在解决大模型多步推理(Multi-step)错误问题</a></p><ul><li>本文作者提出了一个名为Q<!-- -->*<!-- -->的新框架，旨在解决大模型在多步推理中出现的错误、幻觉和不一致陈述等问题。Q<!-- -->*<!-- -->通过学习一个Q值模型作为启发式函数，引导LLMs选择最合适的下一步行动，无需对每个任务进行微调，从而降低计算资源开销并避免灾难性遗忘。</li><li>Q<!-- -->*<!-- -->框架在数学推理和代码生成等任务上的表现显著提升，通过深思熟虑的规划，有效帮助模型规避推理过程中的错误和逻辑不一致性。实验结果表明，Q<!-- -->*<!-- -->在多个数据集上均取得了优异的结果。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/On_fAwP-Gjpl6QD_zXzCnQ" target="_blank" rel="noopener noreferrer">Modelscope-Agent 增强RAG能力:(一)多策略召回、多模态召回</a></p><ul><li>本文介绍了Modelscope-Agent通过引入llama-index来增强其在多策略和多模态召回场景中的应用能力。作者详细描述了如何通过多策略召回器混用和支持多种模态文件（如文本、图片、音频、视频）的读取和处理，提升了知识库的RAG（检索-生成）能力。</li><li>文章还展示了具体的实现方法和代码示例，说明了如何配置和使用这些新功能。通过这些增强措施，Modelscope-Agent能够在不同场景中提供更高的准确率和性能效果，满足复杂多样的应用需求。</li></ul></li><li><p>🌟 <a href="https://mp.weixin.qq.com/s/_fwMZnycmFWHFIxR76FJTg" target="_blank" rel="noopener noreferrer">TGI 基准测试</a></p><ul><li>本文作者Derek Thomas介绍了TGI基准测试工具，该工具能帮助用户超越简单的吞吐量指标，对TGI进行全面的性能剖析。文章详细讲解了如何利用该工具进行服务性能优化，以便根据实际需求进行调优并作出最佳决策。</li><li>文章还展示了如何在Hugging Face空间上使用TGI基准测试工具，通过具体示例和图表说明了延迟与吞吐量的关系，帮助用户理解和优化LLM推理服务的性能。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/MJaWdar-rnYC8YnYyJsBnw" target="_blank" rel="noopener noreferrer">成果｜Seq1F1B：节省50%显存的长文本模型流水线并行训练技术</a></p><ul><li>本文作者介绍了他们与北京邮电大学团队共同开发的Seq1F1B训练技术，这是一种新的长文本模型流水线并行训练方法。Seq1F1B通过将流水线调度单元按序列切分，并提出针对序列维度的1F1B流水线并行策略和高效的序列切分方法，显著降低了流水线对显存的需求，同时减少了因空闲气泡导致的性能损失。</li><li>实验结果表明，Seq1F1B相比传统流水线方法可减少50%的显存占用，最高能支持30B GPT-2模型的64k长文本训练（不启用重计算显存优化），并在大多数情况下实现更高的训练吞吐。该技术解决了1F1B流水线在长文本训练中面临的显存瓶颈，为大语言模型的高效训练提供了新的解决方案。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/hd2FzO2p15ERbHe0w87J8Q" target="_blank" rel="noopener noreferrer">Vector | Graph:蚂蚁首个开源Graph RAG框架设计解读</a></p><ul><li>本文作者介绍了蚂蚁集团开发的通用开源RAG框架，该框架旨在兼容多样化的基础研究建设和工程化应用需求。文章详细阐述了从传统RAG到Graph RAG的技术演进，并提出了一个统一的架构设计，可以同时支持向量索引和图索引等多种索引形式。</li><li>作者还介绍了蚂蚁的Graph RAG开源技术方案，包括DB-GPT、OpenSPG和TuGraph等核心组件，并探讨了未来的优化方向，如改进内容索引和检索生成阶段，以及RAG向Agent架构的演化趋势。文章强调了Graph RAG作为新兴AI工程领域的潜力，并邀请开发者参与共建。</li></ul></li><li><p>🌟 <a href="https://mp.weixin.qq.com/s/b_-O0FoTYtANJbQvks9ghw" target="_blank" rel="noopener noreferrer">[LLM推理优化][万字]TensorRT-LLM部署调优-指北</a></p><ul><li>本文作者详细介绍了TensorRT-LLM部署过程中的性能调优技巧。文章涵盖了多个关键方面，包括Batch size相关设置、影响首Token时延的配置、custom_all_reduce的使用、Decode时延的优化、fp8/int8 KV Cache的设置、In-Flight Batching的相关配置以及bls模式的设置等。</li><li>作者还提供了如何开启debug模式的指导，并总结了TensorRT-LLM性能分析的方法。这篇文章为TensorRT-LLM的实际应用提供了全面的指导，帮助读者理解和优化LLM推理服务的性能。作者承诺长期更新文章内容，以反映最新的实践经验和遇到的问题。</li></ul></li><li><p><a href="https://mp.weixin.qq.com/s/EOn1pKn7fo4unJm3H1xnQQ" target="_blank" rel="noopener noreferrer">超越Devin!华为等| 解决接近30%的GitHub issues!最强CodeR来啦!</a></p><ul><li>这篇由华为、中科院、新加坡管理大学和北京大学的研究人员撰写的文章介绍了一个名为CodeR的新框架，用于自动解决GitHub issues。CodeR采用多智能体（Multi-Agent）和预定义的任务图（Task Graph）方法，在SWE-bench-lite数据集上实现了28.33%的issue解决率，创造了新的记录。</li><li>CodeR框架包含五个代理角色：经理、复现者、故障定位器、编辑器和验证者，每个角色都有特定的动作空间。关键创新在于使用结构化任务图来表示解决issue的计划，这种方法避免了大语言模型在指令遵循和长上下文处理中的问题。此外，CodeR还利用LLM生成的测试用例和现有代码库中的测试来改进故障定位和代码检索。</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><div class="theme-admonition theme-admonition-tip alert alert--success admonition_kCt_"><div class="admonitionHeading_oZsk"><span class="admonitionIcon_tnIl"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>技术资讯</div><div class="admonitionContent_m8BQ"><ul><li><a href="https://twitter.com/golangch/status/1806352351017529544" target="_blank" rel="noopener noreferrer">A simple slog.Handler designed to recursively merge and de-duplicate log attributes, ensuring clean, concise, and informative log entries</a></li><li><a href="https://twitter.com/golangch/status/1806703850998333532" target="_blank" rel="noopener noreferrer">A cloud-native vector database, storage for next-generation AI applications</a></li><li><a href="https://twitter.com/golangch/status/1806244656998404448" target="_blank" rel="noopener noreferrer">A Go library that offers functional programming using generics</a></li><li><a href="https://twitter.com/golangch/status/1806967292846080218" target="_blank" rel="noopener noreferrer">A Go Cookie Library &quot;Cookies, but with structs, for happiness.&quot;</a></li><li><a href="https://twitter.com/golangch/status/1806193172076273852" target="_blank" rel="noopener noreferrer">An interesting new Video Tutorial Series about &quot;Build an e-commerce backend in Go&quot;</a></li><li><a href="https://twitter.com/golangch/status/1805943665388314905" target="_blank" rel="noopener noreferrer">Structuring Go Code for CLI Applications: Commonly Used Program Layouts for Robust Applications</a></li><li><a href="https://twitter.com/golangch/status/1805905133294784513" target="_blank" rel="noopener noreferrer">A great article about &quot;How Golang Compiler Works&quot;</a></li><li><a href="https://twitter.com/golangch/status/1805808975541141839" target="_blank" rel="noopener noreferrer">A monitoring software that makes it super-easy to monitor availability and performance of various components of your system</a></li><li><a href="https://twitter.com/golangch/status/1805802912947314713" target="_blank" rel="noopener noreferrer">A fully production-ready solution designed to implement best practices for building performant and secure backend REST API services</a></li><li><a href="https://twitter.com/golangch/status/1805481161533124789" target="_blank" rel="noopener noreferrer">A Go-based CLI generates runbooks with AI or from commands you provide</a></li><li><a href="https://twitter.com/golangch/status/1805471204465148221" target="_blank" rel="noopener noreferrer">An open-source UI-first Identity and Access Management (IAM) / Single-Sign-On (SSO) platform with web UI</a></li><li><a href="https://twitter.com/golangch/status/1805440695554994683" target="_blank" rel="noopener noreferrer">An interesting article &quot;No sleep until we build the ideal pub/sub library in Go&quot;</a></li><li><a href="https://twitter.com/golangch/status/1805227429880906187" target="_blank" rel="noopener noreferrer">A Go web and RPC framework with lots of built-in engineering practices</a></li><li><a href="https://twitter.com/golangch/status/1805144296812613711" target="_blank" rel="noopener noreferrer">CPU vs I/O Bound Benchmarking in Go</a></li><li><a href="https://twitter.com/golangch/status/1804489580135014535" target="_blank" rel="noopener noreferrer">A great article about &quot;How to Implement Two-Factor Authentication (2FA) with TOTP in Golang&quot;</a></li><li><a href="https://twitter.com/golangch/status/1804879167567057139" target="_blank" rel="noopener noreferrer">EntGo vs GORM vs SQLx : Benchmarking Golang ORMs</a></li></ul></div></div><p><a href="https://juejin.cn/post/7384303275376230411" target="_blank" rel="noopener noreferrer">（九）深入解析 Go 语言 GMP 模型：并发编程的核心机制</a></p><p><a href="https://juejin.cn/post/7382470660775624758" target="_blank" rel="noopener noreferrer">（八）Go-Zero 数据库实战：配置、建模与业务逻辑一体化</a></p><p><a href="https://mp.weixin.qq.com/s/yodhtxhjmiIymRHUNIQelw" target="_blank" rel="noopener noreferrer">Golang empty struct 的底层原理和其使用</a></p><p><a href="https://mp.weixin.qq.com/s/tb10VnpdiZCLYhXZDb--kQ" target="_blank" rel="noopener noreferrer">国内多个库被 rsc 钉上 Go 耻辱柱</a></p><p><a href="https://mp.weixin.qq.com/s/Ok7QCpo8yhaCFu95Qz0m_Q" target="_blank" rel="noopener noreferrer">Go 如何基于 MVS 解决依赖关系问题</a></p><p><a href="https://mp.weixin.qq.com/s/MTTizYTY5vctqhiUia_DsA" target="_blank" rel="noopener noreferrer">Ducker：Rust编写的管理Docker容器的终端应用程</a></p><p><a href="https://mp.weixin.qq.com/s/yJunfxNPp0qfFBcdyzOeGA" target="_blank" rel="noopener noreferrer">从使用到原理看Kubernetes网络</a></p><p><a href="https://mp.weixin.qq.com/s/Xs2BCbYKhb0IVe4yra6l-A" target="_blank" rel="noopener noreferrer">用Go语言从零开始开发一个Prometheus Exporter</a></p><p><a href="https://mp.weixin.qq.com/s/tVuV597whmQ03CHeRFA5RQ" target="_blank" rel="noopener noreferrer">Go与神经网络：手写数字识别</a></p><p><a href="https://mp.weixin.qq.com/s/B7WBb-9XDRDOZFZ-DF0xeQ" target="_blank" rel="noopener noreferrer">链路追踪详解（五）：链路传播 Header 详解</a></p><p><a href="https://mp.weixin.qq.com/s/D_AsV9QpOZ_5v8f1eKoxjQ" target="_blank" rel="noopener noreferrer">Go 模块使用 GitLab subgroups 的问题</a></p><p><a href="https://mp.weixin.qq.com/s/ZjLlwhYoLSDTKtD5kecVYA" target="_blank" rel="noopener noreferrer">Go 1.23 rc1 已发布，包括极具争议的迭代器...</a></p><p><a href="https://mp.weixin.qq.com/s/I8PQep7BkB3l7Vz8A6UonQ" target="_blank" rel="noopener noreferrer">GORM V2 几个最实用的功能和升级注意事项</a></p><p><a href="https://mp.weixin.qq.com/s/bz3RmkoUCrNiGubvhQXimw" target="_blank" rel="noopener noreferrer">Rust 编写专为容器而设计的操作系统 Bottlerocket ，已 8.3k+ star！</a></p><p><a href="https://mp.weixin.qq.com/s/lfM6o5LKExDS3CAIMus5Ag" target="_blank" rel="noopener noreferrer">【译】Rust中的Arc与Mutex</a></p><p><a href="https://mp.weixin.qq.com/s/YJfMC-opOP9e-KzcaNydEw" target="_blank" rel="noopener noreferrer">【译】Rust中的Vec类型</a></p><p><a href="https://mp.weixin.qq.com/s/AlrgIoxCGGoizQkVqoExsw" target="_blank" rel="noopener noreferrer">【译】为什么Rust中的BTreeMap没有with_capacity()方法</a></p><p><a href="https://mp.weixin.qq.com/s/kAT7x9UXuU7XVKMLYQk_OQ" target="_blank" rel="noopener noreferrer">一文搞懂如何排查 Kubernetes 部署问题</a></p><p><a href="https://mp.weixin.qq.com/s/8MyiP0fcU5rAJ1cy8aAY0A" target="_blank" rel="noopener noreferrer">Go必知必会：并发编程的核心channel</a></p><p><a href="https://mp.weixin.qq.com/s/E2-d4AWP5YuUQcPKpUXr9Q" target="_blank" rel="noopener noreferrer">Go 1.22 提供的更加强大的 Tracing 能力</a></p><p><a href="https://mp.weixin.qq.com/s/-L4uS9Hc7hnnTxfSd0F0iw" target="_blank" rel="noopener noreferrer">使用 Gin 快速开发高性能的 Web 应用</a></p><p><a href="https://mp.weixin.qq.com/s/zfqf1H8D156wVvb6mN1pvw" target="_blank" rel="noopener noreferrer">错误检查 errors.Is() 会拖慢5倍执行速度</a></p><p><a href="https://mp.weixin.qq.com/s/8wDr82Nevb4ZZWkewlBACA" target="_blank" rel="noopener noreferrer">Golang项目代码组织架构实践</a></p><p><a href="https://mp.weixin.qq.com/s/JTcUUrn78DPqNp3BcgLrVg" target="_blank" rel="noopener noreferrer">C++ vs Rust vs Go 性能比较</a></p><p><a href="https://mp.weixin.qq.com/s/0wSOnDVW6qwP0wYbjeYqLA" target="_blank" rel="noopener noreferrer">Go 在结构体中定义下划线（_）字段原来还有这个特殊用途</a></p><p><a href="https://mp.weixin.qq.com/s/ibDaxoTn6Vd5x2d1nq08IQ" target="_blank" rel="noopener noreferrer">Go 高性能本地缓存库 bigcache 是怎么实现的</a></p><p><a href="https://mp.weixin.qq.com/s/vN8hNQ1bDKcrq4AlmaIZYA" target="_blank" rel="noopener noreferrer">Go 1.23中的自定义迭代器与iter包</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/7WnJrDtZKYfgMIrFALbJ6Q" target="_blank" rel="noopener noreferrer">构建属于自己的云游戏服务器</a></p><p><a href="https://mp.weixin.qq.com/s/OQcaNRWHB1CBojkObeCLbw" target="_blank" rel="noopener noreferrer">真好，Navicat Premium 也放出了免费版，终于可以光明正大的用了</a></p><p><a href="https://mp.weixin.qq.com/s/2PVw7d46MBrVaj9ePa81_g" target="_blank" rel="noopener noreferrer">漫谈分布式开篇：从全景视野详解单体到分布式架构的蜕变之旅！</a></p><p><a href="https://mp.weixin.qq.com/s/ZOAyUVKgAx7NM8YU3FhmEg" target="_blank" rel="noopener noreferrer">百亿级存储架构： ElasticSearch+HBase 海量存储架构与实现</a></p><p><a href="https://mp.weixin.qq.com/s/OX9rGl2ZhhmMfh2Oxv89CQ" target="_blank" rel="noopener noreferrer">1.4万字+20张图探秘Redis高效的网络模型</a></p><p>🌟 <a href="https://mp.weixin.qq.com/s/99IFnZFrEwUAkQuh7Nc7tg" target="_blank" rel="noopener noreferrer">如何写一个后端的技术方案</a></p><p><a href="https://mp.weixin.qq.com/s/wcc8T1msUfR35KJGWgL1_w" target="_blank" rel="noopener noreferrer">走向管理岗，一定要学会“吵架”</a></p><p><a href="https://mp.weixin.qq.com/s/qk78XmbzdovtmjQrcfHxlQ" target="_blank" rel="noopener noreferrer">使用PolarDB和ECS搭建门户网站详解</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/zebQx_Zm4TNshDMS6kl5Eg" target="_blank" rel="noopener noreferrer">b 站 banner 的鼠标跟随动画效果</a></p><p><a href="https://mp.weixin.qq.com/s/mbmu1Z6tj9ScZ8EsY-TMxw" target="_blank" rel="noopener noreferrer">Mako Tree Shaking 简介</a></p><p><a href="https://mp.weixin.qq.com/s/Vk-bzuHb8d7M3bap8mn7Nw" target="_blank" rel="noopener noreferrer">强烈推荐一款好用到爆的可视化拖拽库</a></p><p><a href="https://mp.weixin.qq.com/s/YHGbEpTBXFaze4Ftzgli9Q" target="_blank" rel="noopener noreferrer">服务端渲染时，如何序列化传输 Promise</a></p><p><a href="https://mp.weixin.qq.com/s/fYoc7LvNOWcaKSPHczEMTQ" target="_blank" rel="noopener noreferrer">9.6K Star！在浏览器/Node环境中可跑近 1000 个 AI 模型的开源项目来了！</a></p><p><a href="https://mp.weixin.qq.com/s/aYK6RFyPrTtc6WWEY4Offg" target="_blank" rel="noopener noreferrer">前端如何体系化性能优化</a></p><p><a href="https://mp.weixin.qq.com/s/LVRtWXZ1Lva_75jD0YmeFA" target="_blank" rel="noopener noreferrer">理解 Node.js：利用JavaScript 进行服务端编程的利器</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/6月23日内容汇总">6月23日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-06-23T00:00:00.000Z" itemprop="datePublished">June 23, 2024</time> · <!-- -->30 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/image-1-aa85d112efac3e3b2d3548745e38e42b.png" width="1200" height="675" class="img_astN"></p><p>封面图：&quot;Heartfelt Doodlings&quot; — The Web Event for Genshin Impact&#x27;s new character: Sigewinne is now available.</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://www.anthropic.com/news/claude-3-5-sonnet" target="_blank" rel="noopener noreferrer">《Claude 3.5 Sonnet》</a>。这篇由Anthropic团队撰写的文章介绍了最新发布的Claude 3.5 Sonnet模型。Claude 3.5 Sonnet在速度和智能方面设立了新的行业标准，能够高效处理复杂任务，如上下文敏感的客户支持和多步骤工作流程。该模型通过内部编码评估展示了强大的编码能力，且在视觉任务中表现卓越。此外，文章还介绍了新功能Artifacts，提供了一个动态工作空间，使用户可以实时查看、编辑AI生成的内容。Anthropic还强调了其在安全性和隐私保护方面的承诺。Claude 3.5 Sonnet现已在多个平台上上线，包括Claude.ai、iOS应用、Anthropic API、Amazon Bedrock和Google Cloud的Vertex AI。</p><p><a href="https://mp.weixin.qq.com/s/-jj552KKJLZ-Y4WnwzJuRg" target="_blank" rel="noopener noreferrer">《NUS、清华提出STAR:一句话生成高质量4D Avatar，代码已开源》</a>。本文作者Chai Zenghao介绍了由新加坡国立大学和清华大学团队提出的“STAR”算法。该算法利用骨骼感知技术从文本生成高质量4D Avatar，显著提高了虚拟人物的外观和动作真实度。STAR解决了T2I模型生成中的多面问题、域间隙和动画穿模等挑战，并通过结合T2I和T2V扩散模型与混合SDS方法优化Avatar的几何、纹理和动作。该技术展示了在虚拟人生成领域的显著进步，提升了生成效果及一致性。代码现已开源。</p><p><a href="https://mp.weixin.qq.com/s/F-wOCZgpc3YksqsHjvY2nw" target="_blank" rel="noopener noreferrer">《从LLM中完全消除矩阵乘法，效果出奇得好，10亿参数跑在FPGA上接近大脑功耗》</a>。本文作者王菁介绍了加州大学圣克鲁兹分校等机构研究者提出的MatMul-free语言模型，通过在密集层中使用加法和自注意力类函数中使用元素级乘积，完全消除了矩阵乘法的需求。实验表明，该模型在十亿参数尺度下保持了强大的性能，并且在优化内核和FPGA自定义硬件方案下，显著减少了内存和功耗消耗。此外，研究者在扩展模型规模时发现其性能与最先进的Transformer逐渐接近，为实现大规模语言模型的高效和低成本提供了新思路。项目代码已开源。</p><p><a href="https://mp.weixin.qq.com/s/hPU3XfKLBs7H9WBiFC2AjQ" target="_blank" rel="noopener noreferrer">《使用Coze(扣子)定制一个Android领域的专家》</a>。本文作者王菁介绍了如何使用字节跳动的扣子平台创建一个Android领域的智能专家。文章详细讲解了从设置基础信息、定义人设、添加联网搜索和绘图插件、建立知识库、设置个性化音色到通过工作流添加定制任务的全过程。通过这些步骤，用户可以创建一个能够回答Android相关问题的智能专家，并将其发布在豆包App上供终端用户使用。同时，作者分享了添加和测试插件、工作流的实际操作和经验，为实现高效的智能助手提供了有价值的指导。</p><p><a href="https://mp.weixin.qq.com/s/rxELLnxVNgBfHmfY6SnEnA" target="_blank" rel="noopener noreferrer">《一篇大模型Agent工具使用全面研究综述》</a>。本文详细介绍了使用大型语言模型（LLMs）进行工具学习的研究进展。作者王菁分析了工具学习的优势，包括增强知识获取、专业技能、自动化与效率、以及交互能力。同时，文章从任务规划、工具选择、工具调用和响应生成四个关键阶段对工具学习进行了系统性审查。通过引入新的工具学习范式和方法，使得LLMs能够更好地处理复杂问题，提高模型的可解释性和用户信任。该研究为新来者提供了宝贵的系统性指导和全面的理论基础。</p><p><a href="https://mp.weixin.qq.com/s/ynSchFDQCBto258PwTGhJg" target="_blank" rel="noopener noreferrer">《无需人类或GPT-4打标签!南大&amp;旷视研究院无监督范式大幅降低视觉大模型对齐成本》</a>。本文作者王菁介绍了南大与旷视研究院推出的一种无监督范式，用于解决视觉大模型的偏好对齐问题。研究团队通过构造偏好样本对，提出了Self-Supervised Visual Preference Alignment（SeVa）范式，在无需GPT-4或人类打标签的情况下，显著提高了视觉语言模型（VLM）的指令遵循能力和用户感受效果。SeVa基于LLaVa-1.5-7B/13B模型，并通过实验在多个benchmark上证明其优越性。研究结果表明，无监督方法可以有效降低成本并提高模型性能，为视觉大模型的发展提供了新方向。项目代码和论文已开源。</p><p><a href="https://mp.weixin.qq.com/s/lHcqkUSqMuBTFsFE3CzB5Q" target="_blank" rel="noopener noreferrer">《墙裂推荐!Karpathy大模型培训课LLM101n上线了，非常基础》</a>。本文作者王菁详细介绍了由Andrej Karpathy推出的大语言模型培训课程《LLM101n》。该课程旨在从基础到高级，教授如何从零开始构建一个类似于ChatGPT的大型语言模型。课程内容涵盖从语言建模、机器学习基础、多模态、强化学习到模型部署等多个方面。通过Python、C和CUDA的实际操作，学员将深入理解AI、LLM和深度学习的核心原理。课程的大纲包括语言模型的基础概念、优化方法、设备和精度管理、数据处理与推理、微调与部署等核心主题。Karpathy的这一课程以实践为导向，为希望理解并构建大语言模型的学习者提供了详尽而实用的指导。</p><p><a href="https://mp.weixin.qq.com/s/GcLVLRADYB6LFZBMGEUFlg" target="_blank" rel="noopener noreferrer">《斯坦福 |提出多阶段LLM编程指令示例优化器:MIPRO，复杂任务准确率提升13%!》</a>。本文作者王菁详细介绍了斯坦福大学提出的多阶段语言模型（LLM）编程指令示例优化器MIPRO。MIPRO旨在通过优化每个阶段的指令提示，最大化下游任务指标，克服现有单阶段优化方法的局限。研究通过将复杂问题分解为多阶段任务，并引入贝叶斯优化技术，成功提升了如Llama3-8B等模型在多个项目上的性能，最高提升达13%。MIPRO通过其灵活性和高效率，为复杂任务的语言模型优化提供了创新性的解决方案。</p><p><a href="https://mp.weixin.qq.com/s/R6ZsMZwiHNGcfVowUwPvaQ" target="_blank" rel="noopener noreferrer">《RePrompt:提示词自动化优化策略》</a>。本文作者王菁详细介绍了RePrompt，这是一种为大型语言模型代理设计的自动提示优化策略。RePrompt通过分析与语言模型（LLM）代理的交互历史，对提示中的指令进行逐步优化，类似于“梯度下降”。其核心思想是通过优化提示，使得LLM在特定领域内更好地规划，并提升不同推理任务的性能。RePrompt不需对提示词进行精心编写，通过交互式动作生成和逐步优化，显著提高LLM在代码生成、旅行规划和机器人控制等应用中的表现。研究表明，使用RePrompt，LLM的推理任务准确率显著提升，展示了自动提示工程在实际应用中的潜力。</p><p><a href="https://mp.weixin.qq.com/s/m925xVwSLW0I7RTT1Mgxdg" target="_blank" rel="noopener noreferrer">《多模态大模型VLMs一年多的进展与思考》</a>。本文作者王菁探讨了视觉-语言模型（VLMs）在过去一年中的研究进展与应用。文章回顾了从ChatGPT到支持多模态输入的GPT-4的发布，VLMs技术的飞速发展，并探讨了代表性工作如LLaVA的实现和优化、对高分辨率和训练数据的改进、以及模型结构和图像生成技术的发展。此外，文章还探讨了视觉对LLM智能提升的潜力，提出VLMs尽管尚未与Diffusion方法一样广泛应用，但在增强机器感知能力、提高学习效率和纠正认知偏差方面展示了巨大潜力。文章为理解VLMs的未来趋势与应用提供了综合视角。</p><p><a href="https://mp.weixin.qq.com/s/eU3T7Y2xefTDRfO94VIV1A" target="_blank" rel="noopener noreferrer">《怎样让 PPO 训练更稳定？早期人类征服 RLHF 的驯化经验》</a>。本文作者王菁介绍了如何稳定且有效地训练增强学习中的顶流算法PPO，并分享了在RLHF（人类反馈强化学习）中的成功经验。文章详细探讨了Reward Model的训练方法，指出了仅拉开得分差会导致钻牛角尖的问题，并提出在Loss中加入对好样本的LM loss以保持模型的语言能力。此外，文章分析了PPO训练中的常见问题如模式崩溃，并提出了通过监控KL、Response Length、Perplexity等指标来及时发现问题的方法。作者还分享了Score Normalization &amp; Clipping技巧，以及Policy Loss设计中的关键步骤，包括重要性采样和KL-惩罚。最后，文章提出了最优策略集合（PPO-max）的一套推荐策略，如reward normalize、token KL penalty等，为PPO训练提供了实践指导。</p><p><a href="https://mp.weixin.qq.com/s/gnWRDgNAFFs1a1D4RX4-1g" target="_blank" rel="noopener noreferrer">《Runway新模型Gen-3 Alpha效果炸裂，创始人要做出比 Sora 更好的文生视频模型的承诺兑现，目前接受付费使用申请》</a>。本文作者王菁介绍了Runway发布的新视频生成基础模型Gen-3 Alpha。作为Runway在AI视频生成领域持续投入和技术进步的标志，Gen-3 Alpha不仅是对先前模型的改进，更是通过用户反馈和技术研究后的全新进化。新模型引入了先进的语义分割技术和优化的渲染算法，显著提升了视频生成的自然度和逼真度。在用户体验和性能方面，Gen-3 Alpha也有了明显的提升，并得到了高度稳定性的保证。Runway的这一创新不仅兑现了其创始人比Sora更好的模型承诺，还通过在线教程和社区活动，推广了AI视频生成技术。</p><p><a href="https://mp.weixin.qq.com/s/MceI21zmgVqBnIpjohIwpg" target="_blank" rel="noopener noreferrer">《Multi-Head RAG:多头注意力的激活层作为嵌入进行文档检索》</a>。本文作者SACHIN KUMAR介绍了一种新的文档检索方案Multi-Head RAG (MRAG)，该方案利用Transformer的多头注意力层作为嵌入，而不是传统的解码器层激活，从而提高文档检索的效果。MRAG通过在嵌入过程中处理多个注意头的激活，捕获文本的多面性，优化了检索准确性和相关性。文章详细描述了MRAG的数据准备、嵌入构建、查询执行等步骤，并通过多项实验和实际用例（比如法律文件合成和工业事故分析），展示了MRAG相较于标准RAG在检索成功率和性能方面的显著提升。MRAG不仅提升了检索效果，还保持了与标准RAG相同的嵌入空间，不增加存储需求。论文还提供了相关代码链接，为研究者和工程师提供了实现参考。</p><p><a href="https://mp.weixin.qq.com/s/Xeu9XQhvz3wubK6d7Sd7qQ" target="_blank" rel="noopener noreferrer">《SOFTS: 时间序列预测的最新模型以及Python使用示例》</a>。本文作者王菁介绍了2024年4月提出的全新时间序列预测模型SOFTS（Series-cOre Fused Time Series）。SOFTS通过引入STar聚合调度（STAD）模块，集中学习不同时间序列之间的交互关系，在多变量预测中表现尤为出色。文章详细讲解了SOFTS的架构，包括序列归一化、嵌入和STAD模块的操作原理，并通过实验证明了其在单变量和多变量任务中的优秀性能。此外，文章还提供了具体的Python代码示例，演示如何使用SOFTS模型进行预测，为研究者和工程师提供了实践指导。</p><p><a href="https://mp.weixin.qq.com/s/z5KgulufX0IEP6G6lkD_nQ" target="_blank" rel="noopener noreferrer">《魔搭社区GGUF模型怎么玩!看这篇就够了》</a> 。本文作者魔搭社区介绍了Qwen2系列的大模型家族发布的GGUF格式模型及其使用方法。文章详细讲解了通过包括llama.cpp、Ollama、LM Studio等工具进行模型下载、解析和应用的流程。内容覆盖了从CLI命令行工具、Python SDK到页面下载的方式，并对不同模型推理工具进行了比较，提供了逐步安装和使用指南。文章为初学者提供了易于上手的操作方法，让用户即便在仅配备CPU的笔记本上，也能够体验并应用顶尖的AI技术。通过详细的图文和代码示例，帮助开发者顺利部署并运行GGUF大模型。</p><p><a href="https://mp.weixin.qq.com/s/eyLnBTskZhlKcwghzqHmhQ" target="_blank" rel="noopener noreferrer">《将强化学习重新引入 RLHF》</a>。本文作者Shengyi Costa Huang和Arash Ahmadian介绍了RLOO（REINFORCE Leave One-Out）训练器，一种替代PPO的新型在线RLHF训练算法。RLOO通过减少GPU内存占用和加速收敛时间，使得在线强化学习变得更加易用和高效。与PPO相比，RLOO的vRAM使用量减少50-70%，运行速度提高2-3倍，并在响应胜率上优于DPO等离线方法，尤其是在大规模模型上。文章详细描述了RLOO的工作原理，包括奖励基线的计算、训练过程中的每步操作，并提供了实验证明RLOO的有效性和实现代码。通过RLOO，可以更高效地进行在线RLHF训练，提升模型的响应质量。</p><p><a href="https://mp.weixin.qq.com/s/Nh7l_ly791thmsXG7hm5Cw" target="_blank" rel="noopener noreferrer">《过去一年有关大模型应用构建的干货经验之战略篇》</a>。本文作者Eugene Yan与Bryan Bischof等人分享了他们在大模型应用构建中的经验。文章从战术、运营和战略三方面剖析了大模型的开发与落地。战略篇强调深思熟虑的规划和优先级排序，提出了“在产品市场契合度(PMF)之前不使用GPU”等观点，探讨了自建与购买模型的决策依据、如何围绕模型建系统以迭代精品，以及低成本认知趋势对未来应用的影响。通过实战经验总结提供了一条从原型到可靠产品的现实路径。</p><p><a href="https://mp.weixin.qq.com/s/XM9GfNPe-0Meb6MLMxhJPw" target="_blank" rel="noopener noreferrer">《过去一年有关大模型应用构建的干货经验之运营篇》</a>。本文由Eugene Yan和Bryan Bischof等人撰写，重点分享了大模型（LLM）应用在数据、模型、产品和人员等方面的运营经验。文章涵盖了LLM在生产过程中如何审查输入输出、解决开发-生产数据偏差，保持模型版本化，以及跨模型提示迁移的难点。还探讨了如何设计、人机交互的用户体验，优先排序需求，以及培养团队实验文化。通过实际案例展示了LLM在不同模型和版本间的表现、评估方法及优化策略，提供了综合的运营指南。</p><p><a href="https://mp.weixin.qq.com/s/1_kfUm7A4dbJ6owOO_mHfQ" target="_blank" rel="noopener noreferrer">《过去一年有关大模型应用构建的干货经验之战术篇》</a>。本文由Eugene Yan、Bryan Bischof等人撰写，详细介绍了在大模型应用构建中的战术经验。文章涵盖了提升质量和可靠性的提示技巧、构建检索增强生成（RAG）、应用流程工程、评估和监控的最佳实践和常见陷阱。具体内容包括n-shot提示、chain-of-thought提示技术、结构化输入输出、信息检索策略、缓存的重要性以及微调的时机。通过实际案例，文章探讨了如何优化上下文、组合工作流以及评估生成的输出质量，提供了极具实用性的战术建议。</p><p><a href="https://mp.weixin.qq.com/s/DUYp2EaMuUS8JOV2cnk8cA" target="_blank" rel="noopener noreferrer">《OpenAI前CTO Ilya推荐的30篇文章，认真读完将理解当下90%的AI技术(2)》</a>。本文同样由Ilya推荐，继续介绍剩余的AI关键论文，包括《Deep Residual Learning for Image Recognition》中的深度残差学习、《MULTI-SCALE CONTEXT AGGREGATION BY DILATED CONVOLUTIONS》的膨胀卷积、多尺度上下文聚合、《Neural Message Passing for Quantum Chemistry》在量子化学中的神经消息传递等。这些论文深入探讨了深度神经网络、语义分割、机器翻译等领域的前沿技术，展示了AI在不同应用方面的突破性进展。阅读这些论文有助于全面了解当前的AI技术和研究方向。</p><p><a href="https://mp.weixin.qq.com/s/R1QeWD7maFjA4Avc0EUcyQ" target="_blank" rel="noopener noreferrer">《OpenAI前CTO Ilya推荐的30篇文章，认真读完将理解当下90%的AI技术(1)》</a>。本文涵盖了Ilya与业内专家推荐的关键AI论文，包括Transformer开山之作《Attention Is All You Need》、Scott Aaronson探讨物理系统复杂性的《The First Law of Complexodynamics》、Andrej Karpathy强调RNN强大能力的《The Unreasonable Effectiveness of Recurrent Neural Networks》以及Geoffrey Hinton等人提出的深度学习革命性论文《ImageNet Classification with Deep Convolutional Neural Networks》。这些论文涵盖了从Transformer、RNN、LSTM到GPipe等多个重要领域，为深入理解当前AI技术提供了宝贵的资源。</p><p><a href="https://mp.weixin.qq.com/s/v4TVgqffLEygE24RClrz7A" target="_blank" rel="noopener noreferrer">《长文梳理!近年来GPT系列模型的发展历史:从GPT-1到GPT-4o(前世、今生)》</a>。文章作者详细回顾了从GPT-1到GPT-4o的演进历程。文章指出，大语言模型的快速发展始于GPT-1，经过GPT-2的大规模扩展与无监督预训练的尝试，到GPT-3引入的“上下文学习”技术，再到InstructGPT针对人类偏好对齐的改进。GPT-4进一步提升了模型性能，并支持图文双模态输入。最新的GPT-4o更是实现了多模态输入与输出的结合，展现了对文本、音频和图像的强化理解和生成能力。这些技术迭代展示了GPT模型在自然语言处理领域的持续革新和突破。</p><p><a href="https://mp.weixin.qq.com/s/f1eAp2WsefgitkRDaIXt2Q" target="_blank" rel="noopener noreferrer">《多头RAG:利用多头注意力提升复杂查询的检索准确性》</a>。本文介绍了一种名为“多头检索增强生成”（MRAG）的新方法，旨在解决大型语言模型（LLM）在处理多文档检索时的挑战。作者详细阐述了MRAG如何利用Transformer的多头注意力层激活作为键来检索不同方面的文档，提高复杂查询的检索准确性。通过实验评估和实际应用案例，MRAG在准确性和相关度上均表现出色，与传统RAG方法相比，相关性提升了20%。这篇文章证明了多头注意力机制在增强检索系统性能方面的潜力，并为未来研究提供了有效的参考和方法论。</p><p><a href="https://mp.weixin.qq.com/s/86vqhDddAXhAvFYpcFacbg" target="_blank" rel="noopener noreferrer">《今日arXiv最热大模型论文:清华大学:一个简单缩放让大模型利用长上下文能力提升15.2%》</a>。本文详细介绍了清华大学提出的通过扩展位置隐藏状态来减轻位置偏差的方法，显著提高了大模型在长上下文处理中的准确性。这种方法包括识别位置隐藏状态并按因子缩放，以减少因果掩码引起的注意力权重偏差，从而提升模型性能。在NaturalQuestions、KV检索和LongBench基准上，方法分别提高了9.3%、15.2%和4.7%的性能。通过详细实验与消融研究，证明了该方法在各种任务上的有效性与适应性，特别在长上下文任务中的显著改进，展示了大模型在处理长文档时性能显著改善的可能性。</p><p><a href="https://mp.weixin.qq.com/s/HMwk3yn-ftugyrHzbBpnOg" target="_blank" rel="noopener noreferrer">《欢迎 Stable Diffusion 3 加入 🧨 Diffusers》</a>。这篇文章介绍了Stable Diffusion家族的最新模型Stable Diffusion 3（SD3），现已登陆Hugging Face Hub，并可在🧨 Diffusers中使用。作者详细描述了SD3的主要特性、模型架构以及如何在Diffusers中进行使用。SD3模型具有20亿参数，包括三个不同的文本编码器（CLIP L/14、OpenCLIP bigG/14和T5-v1.1-XXL），并使用新提出的多模态Diffusion Transformer（MMDiT）模型和16通道的AutoEncoder模型。在内存优化方面，SD3引入了模型卸载和量化方法的多种手段，并详细展示了如何通过代码进行内存优化和性能提升。此外，还提供了使用DreamBooth和LoRA进行微调的代码示例，对SD3进行了详细的性能测量。文章为想要快速尝试和部署SD3模型的用户提供了全面的指导。</p><p><a href="https://mp.weixin.qq.com/s/3e4KaXNL0O9sdEPmIlrFfw" target="_blank" rel="noopener noreferrer">《Nemotron-4 340B 技术报告:全面解读当前最强大语言模型的诞生过程》</a>。本文介绍了NVIDIA发布的Nemotron-4 340B系列模型，该系列包括基础版、指导版和奖励版，专为在单台搭载8个GPU的DGX H100上以FP8精度部署而设计。作者详细描述了模型的训练过程、架构细节及其在各类任务上的卓越表现。报告还强调了98%以上的对齐数据均为合成生成，展示了合成数据生成对模型性能的显著提升。通过多轮对齐和训练迭代，该模型在多个测试数据集上超越了GPT-4，成为当前最强大开源语言模型。详细资料和代码也已开源，供研究和商业应用自由使用。</p><p><a href="https://mp.weixin.qq.com/s/pbPyxEjI48OrViBkDAXKjA" target="_blank" rel="noopener noreferrer">《样本设计工程 (SDE) :如何设计更好的大模型微调样本》</a>。本文作者郭必扬介绍了样本设计工程（Sample Design Engineering, SDE）的概念，系统探讨了大模型在下游任务微调样本设计方面的多种选择。实验表明，经过精心设计的微调样本能够显著提升大模型的任务表现。文章还特别提出了一种在多个复杂任务上均表现优异的样本设计方案，进一步探讨了SDE与提示工程（PE）的异同。通过大量实验验证，作者展示了如何通过细致样本设计，以较少的数据实现更好的模型微调效果。详尽的实验数据充分证明了SDE的实用性和潜在价值。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://juejin.cn/post/7380222254195834892" target="_blank" rel="noopener noreferrer">使用 Golang 实现高 IO 性能超边缘缓存服务器</a></p><p><a href="https://mp.weixin.qq.com/s/lBp1qRdgzCe0etr9rRTi_A" target="_blank" rel="noopener noreferrer">揭秘Go Telemetry</a></p><p><a href="https://mp.weixin.qq.com/s/RWFowB1T7TZ63-GwYPXNUg" target="_blank" rel="noopener noreferrer">Go 1.23 RC1 已经 released</a></p><p><a href="https://mp.weixin.qq.com/s/GG3QbKQz3wYKFPdmJjWtuA" target="_blank" rel="noopener noreferrer">10 个提高生产力的 Go 小技巧</a></p><p><a href="https://mp.weixin.qq.com/s/_4bSpc18clX2Z6gR4pbwqg" target="_blank" rel="noopener noreferrer">聊一聊资深的 Go 开发者如何顺利转型到 Rust 开发</a></p><p><a href="https://mp.weixin.qq.com/s/_OB0TNt0K9EjVvpLo1rvJQ" target="_blank" rel="noopener noreferrer">Go必知必会：探索内存操作的艺术--指针</a></p><p><a href="https://mp.weixin.qq.com/s/U22CsNSkOosDmXDHgg1R2g" target="_blank" rel="noopener noreferrer">深度解析服务发布策略之滚动发布</a></p><p><a href="https://mp.weixin.qq.com/s/qpLimb2y9z12JixyQs0WzA" target="_blank" rel="noopener noreferrer">万字长文：在 Go 中如何优雅的使用 wire 依赖注入工具提高开发效率？下篇</a></p><p><a href="https://mp.weixin.qq.com/s/jGOSjgHeqh5HaQd5icBvpA" target="_blank" rel="noopener noreferrer">在 Go 中如何让结构体不可比较</a></p><p><a href="https://mp.weixin.qq.com/s/0mphuzSCmcLgd90I6ddr3w" target="_blank" rel="noopener noreferrer">为什么 Go 不学 Rust 用 ? 做错误处理</a></p><p><a href="https://mp.weixin.qq.com/s/50RqAQmflA3kVuekfR8cDA" target="_blank" rel="noopener noreferrer">Golang 极简的开发和快速部署</a></p><p><a href="https://mp.weixin.qq.com/s/ETA-tWI_DW1kS4earL_iqg" target="_blank" rel="noopener noreferrer">程序绑核和CPU亲和性</a></p><p><a href="https://mp.weixin.qq.com/s/-3Zt8ZyMZAHFPTKHDvggVQ" target="_blank" rel="noopener noreferrer">Go 实现可复用的通用内存缓存</a></p><p><a href="https://mp.weixin.qq.com/s/WrG0KccMJSwUJAeCr-CFkQ" target="_blank" rel="noopener noreferrer">一文搞定 Golang 反射 (Reflect)</a></p><p><a href="https://mp.weixin.qq.com/s/Fygdos_msEaYMGIa226i5A" target="_blank" rel="noopener noreferrer">Go必知必会：map详解</a></p><p><a href="https://mp.weixin.qq.com/s/aAgDibroCEk0UQAI2NtZxg" target="_blank" rel="noopener noreferrer">duckdb: 一个超火的数据库，背后公司只有18人</a></p><p><a href="https://mp.weixin.qq.com/s/eBfegl6fCtzQpmQkM9eTNA" target="_blank" rel="noopener noreferrer">Go 再讨论 catch error 模型，官方回应现状</a></p><p><a href="https://mp.weixin.qq.com/s/UG-6UuqDiLX15dEZrGGrRA" target="_blank" rel="noopener noreferrer">Gopher的Rust第一课：Rust的依赖管理</a></p><p><a href="https://mp.weixin.qq.com/s/U5Ii6_lhkNzItQCHZIARrg" target="_blank" rel="noopener noreferrer">atomic128</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/dEgTmNioqjx5IyDTX4KE4g" target="_blank" rel="noopener noreferrer">万字解析 mysql innodb 事务实现原理</a></p><p><a href="https://mp.weixin.qq.com/s/RDvph7lcTGgLiJYC3MsPyQ" target="_blank" rel="noopener noreferrer">接口性能优化的11个小技巧</a></p><p><a href="https://mp.weixin.qq.com/s/RUQXIyN95hvi2wM3CyPI9w" target="_blank" rel="noopener noreferrer">elasticSearch 是什么？工作原理是怎么样的</a></p><p><a href="https://mp.weixin.qq.com/s/xX4fvl4vjjfEI6ccra_DzQ" target="_blank" rel="noopener noreferrer">手把手带你从自建 MySQL 迁移到云数据库，一步就能脱胎换骨</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/qOGU5SdKgdhi6Mfi6wKNaA" target="_blank" rel="noopener noreferrer">全网独家-万字长文入门前端全球化</a></p><p><a href="https://mp.weixin.qq.com/s/oTGR73vxBUvsM45UkpB-Fw" target="_blank" rel="noopener noreferrer">前端可观测性系统建设</a></p><p><a href="https://juejin.cn/post/7380650414414807074" target="_blank" rel="noopener noreferrer">React19 为我们带来了什么</a></p><p><a href="https://mp.weixin.qq.com/s/ogAc-0aUyph4CscrwQMSyA" target="_blank" rel="noopener noreferrer">Tailwind轻松实现夜间模式，能跟随系统又能手动控制！</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/6月16日内容汇总">6月16日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-06-16T00:00:00.000Z" itemprop="datePublished">June 16, 2024</time> · <!-- -->19 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/maxresdefault-ffb8f11e1c31c2d1464780924ffb5d89.jpg" width="1280" height="720" class="img_astN"></p><p>封面图：Safe by construction - Roberto Clapis</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/tW6lQPugUeUR1ye3LUgtzw" target="_blank" rel="noopener noreferrer">《LLaMA Factory 实战——单卡 3 小时训练专属大模型 Agent》</a>。本文作者介绍了如何使用LLaMA Factory的Agent Tuning功能，在单张GPU上仅用3小时训练出一个定制的LLM Agent。通过任务分解、工具调用、多智能体协作等，LLM Agent可以突破传统语言模型的局限，从外部工具获取实时知识，减少生成幻觉现象。文章详细讲解了训练过程，包括环境准备、数据集选择、模型微调和部署步骤。微调后的Yi-6B模型展示了出色的工具使用能力，显著提升了任务解决能力，并可部署为本地API服务。</p><p><a href="https://mp.weixin.qq.com/s/TOXkGpfhBx6Xv-5LZS5IaA" target="_blank" rel="noopener noreferrer">《关键点检测——HRNet源码解析篇》</a>。本文作者小苏详细解析了HRNet（High-Resolution Network）在关键点检测任务中的实现细节。文章通过源码解析，分多个部分深入讲解了HRNet的构建，包括数据集的预处理、数据增强、模型架构、训练流程和预测步骤。文中重点介绍了关键点数据集构建方法，在线数据增强技术（如HalfBody、仿射变换、水平翻转及热力图生成）以及仿射变换和高斯核的具体实现。同时，文章也对网络的训练策略和预测方法进行了详尽的说明，帮助读者更好地理解和应用HRNet进行关键点检测。</p><p><a href="https://mp.weixin.qq.com/s/09awsKgaF9T1AMFzLzSIGA" target="_blank" rel="noopener noreferrer">《ToolBench指标提升8.25%!魔搭社区让Qwen2 成为你的智能体好帮手》</a>。本文介绍了Qwen2模型经过魔搭社区的优化后，在ToolBench所有评测指标上平均提升了8.25个百分点，证明了在垂直场景中针对LLM的特定调优有较大提升。文章详尽介绍了数据集准备、训练、评测和部署的全链路能力。通过使用MSAgent-Pro数据集及引入loss_scale技术，进一步提升了训练效果。文中还演示了如何基于模型生态进行评测，以及使用ModelScope-Agent框架进行部署和应用。该文章为开发者提供了实际操作指南，帮助其在特定场景下实现智能体的高效部署。</p><p><a href="https://mp.weixin.qq.com/s/7LKfamTnCyFih6_grf9m3A" target="_blank" rel="noopener noreferrer">《万字综述大模型高效推理:无问芯穹与清华、上交最新联合研究全面解析大模型推理优化》</a>。这篇由周紫轩撰写的文章介绍了大语言模型（LLM）高效推理的最新研究进展。通过分析Transformer 架构、KV缓存技术等，文章系统总结了影响LLM推理效率的瓶颈，并对数据层、模型层和系统层的优化技术进行了全面综述。文章还探讨了自动化推理技术、模型压缩和全新替代架构的设计与应用，重点分析了提示词压缩、并行输出、注意力机制优化等技术。未来研究方向包括长文本处理、边缘部署和智能体协同优化，以期为高效推理领域提供新的思路和改进途径。</p><p><a href="https://mp.weixin.qq.com/s/g9r2MsPri67ylWVPE2zejQ" target="_blank" rel="noopener noreferrer">《ACL 2024 | 构建超关系知识图谱(KG)，增强大模型多跳/Multi-hop QA问答能力!》</a>。本文作者详细介绍了如何通过构建一个上下文感知的超关系知识图谱（KG）来增强大模型在多跳问答（Multi-hop QA）中的表现。该方法称为HOLMES，通过从查询中识别实体并生成增强的知识图谱，然后精简为最相关的信息作为模型输入，有效减少了无关信息的干扰。实验表明，与传统方法相比，HOLMES在Token消耗上节约了67%，并在多个测试集上取得了一致性提升，显著提高了复杂问题的回答性能。</p><p><a href="https://mp.weixin.qq.com/s/WyVqI1drIpmPmkg1r4WmNQ" target="_blank" rel="noopener noreferrer">《LLM推理后端性能大比拼，来自BentoML团队的深度评估!》</a>。这篇文章翻译自BentoML工程团队，全面评估了多个大型语言模型（LLM）推理后端的性能，包括vLLM、LMDeploy、MLC-LLM、TensorRT-LLM和Hugging Face TGI。文章对比了各后端在首token延时（TTFT）和token生成率两个关键指标上的表现，尤其是在不同并发用户负载下的性能。LMDeploy在多个用户负载下都展示了最低的TTFT和最高的token生成速率，适合高吞吐量应用。此外，还探讨了开发者体验，包括文档质量、模型编译和部署难度，提供了对选择合适推理后端的建议。</p><p>[<a href="https://mp.weixin.qq.com/s/BI8EdDyTEk8meL_FhX-ftw" target="_blank" rel="noopener noreferrer">《Karpathy最新四小时视频教程:从零复现GPT-2，通宵运行即搞定》</a>。本文介绍了AI专家Andrej Karpathy的一段长达四小时的视频教程，该视频详细讲解了如何从零开始复现GPT-2模型（1.24亿参数）。教程内容包括网络构建、优化训练、超参数设置和模型评估等多个关键步骤。Karpathy在视频中展示了如何通过wiki和GPT-3论文优化配置，实现快速训练并最终生成高质量的模型。教程分四大部分，涵盖了从基本实现到高级优化的全过程，最后还提供了相关的GitHub存储库“build-nanogpt”，以方便大家参考和学习。</p><p><a href="https://mp.weixin.qq.com/s/gdT0q5HJ9Fw5QrbBihI1vA" target="_blank" rel="noopener noreferrer">《视觉语言模型导论:这篇论文能成为你进军VLM的第一步》</a>。本文翻译自Meta和蒙特利尔大学等多所研究机构的论文，全面介绍了视觉语言模型（VLM）的发展和现状。文章详细说明了不同VLM的训练方法，包括对比训练、掩码策略、生成模型及预训练骨干网络等。同时，文章还介绍了VLM的训练指南、评估方法以及提升定基和对齐能力的技巧。对于刚入门VLM的学生或AI领域从业者，这篇导论是一份非常实用的参考资料。</p><p><a href="https://mp.weixin.qq.com/s/-UAKKKxA7I_qkNm5ck5R0Q" target="_blank" rel="noopener noreferrer">《详解LLM参数高效微调:从Adpter、PrefixTuning到LoRA》</a>。这篇文章详细介绍了多种大型语言模型（LLM）参数高效微调的方法，包括Adapter Tuning、Prompt Tuning、Prefix Tuning和LoRA。文章首先概述了Transformer的结构和指令微调的背景，接着总结了多种参数高效微调（PEFT）方法，如仅微调偏置项的BitFit、使用低秩矩阵分解的LoRA等。重点介绍了LoRA方法，其通过对增量参数矩阵进行低秩近似，大幅减少了微调过程中需要训练的参数数量，为LLM的微调提供了一种高效的解决方案。文章最后也描述了这些微调方法在实际中的适用范围和性能。</p><p><a href="https://mp.weixin.qq.com/s/T5-z6J6nDNdTETmEQHtlug" target="_blank" rel="noopener noreferrer">《干货|解锁产品迭代新速度:A/B测试在AI大模型时代的应用》</a>。这篇文章介绍了火山引擎数智平台VeDI旗下DataTester如何在AI大模型时代应用A/B测试，帮助企业在业务增长、用户转化、产品迭代等环节科学决策。通过A/B测试，企业能够快速上线、快速体验和回滚产品，在真实用户环境中验证产品效果。文章还讲述了如何利用A/B测试优化高效调优模型参数，提升产品质量和用户体验。这种数据驱动的精细化运营方法使得产品在激烈竞争中保持领先，提高产品竞争力。</p><p><a href="https://mp.weixin.qq.com/s/-FTbJYMbCyiQXyTZ6BHjaA" target="_blank" rel="noopener noreferrer">《港大&amp;腾讯 | 提出SELF-TUNING学习框架，让LLM自学获取新知识，表现出色!》</a>。本文介绍了由香港大学和腾讯共同提出的SELF-TUNING学习框架，这个框架旨在通过自学方式让大型语言模型（LLM）获取最新的知识。SELF-TUNING包括记忆、理解和自我反思三个关键方面，通过自我教学策略提高模型的知识获取和记忆能力。文中详细说明了框架的三个学习阶段及其如何使用Wiki-Newpages-2023-QA数据集测试和评估模型性能，结果显示框架在知识记忆、提取和推理方面效果显著，可避免灾难性遗忘并有效内化新知识。</p><p><a href="https://mp.weixin.qq.com/s/Jj5dclm7qqzp6pR4YM3lsw" target="_blank" rel="noopener noreferrer">《Multi-Agent实践第8期:轻松拖拽搭建多智能体应用》</a>。这篇文章介绍了如何使用AgentScope Workstation，一个基于拖拽式构建多智能体应用的零代码开发平台。用户无需编程经验，只需从工具栏选择并拖拽组件，就能自由组合出创意独特的多智能体应用。文章详细描述了操作步骤，包括选择大模型和智能体、设置配置以及运行应用等。此外，还介绍了AgentScope的高级功能，使用户能够创建复杂工作流并实现包括代码运行、文件读写和网络搜索在内的多种任务。文章鼓励读者探索更多可能，支持AgentScope社区的发展。</p><p><a href="https://mp.weixin.qq.com/s/Iqr7UMVk9vW6tMuRK6AIOg" target="_blank" rel="noopener noreferrer">《用 KV 缓存量化解锁长文本生成》</a>。这篇文章由Raushan Turganbay介绍了Hugging Face的新功能——KV缓存量化。本文详细解释了键值缓存（KV Cache）和量化的工作原理，以及它们如何在大语言模型（LLM）生成长文本时提高速度和内存效率。通过量化KV缓存，模型能在几乎不损失生成质量的前提下显著减少内存占用，从而支持更长文本的生成。研究表明，这一方法在多种基准测试数据集上的效果良好。文中还提供了KV缓存量化在具体操作步骤和代码示例，展示了如何实现这一优化。</p><p><a href="https://juejin.cn/post/7320082701212844044" target="_blank" rel="noopener noreferrer">《图解 Transformer [译]》</a>。这篇文章由The Random Transformer编写并在掘金上翻译和发布，重点介绍了Transformer模型。Transformer利用自注意力机制显著提升了模型训练速度，适合并行处理，并在某些任务上超过传统的神经机器翻译模型。文章深入解释了Transformer的工作原理，包括编码器和解码器组件、自注意机制、多头注意力机制以及位置编码等重要概念。通过图解和简单的描述，使读者能够更轻松地理解复杂的技术细节。</p><p><a href="https://mp.weixin.qq.com/s/zT4CwkZJkExuvivgG_h_EQ" target="_blank" rel="noopener noreferrer">《LlamaFactory 一键式LLM训练、微调工具介绍与实践》</a>。本文介绍了LlamaFactory工具，一个封装完善的LLM微调工具。作者详细描述了LlamaFactory的架构和主要特性，强调其通过Trainer类实现训练流程，支持各种模型和多种训练方法，包括全参数微调、LoRA微调和QLoRA微调等。LlamaFactory结合先进算法如GaLore和Unsloth，大幅降低了显存占用。文章还探讨了数据准备和使用自定义数据集的步骤，并分享了工具的安装依赖和WEB-UI训练界面。LlamaFactory凭借集成化设计，提供便捷且高效的LLM微调解决方案，适合快速上手和复杂训练任务，但需用户详细了解配置参数以优化使用。</p><p><a href="https://mp.weixin.qq.com/s/gI7qXG7qzIFsfgFjD82yDA" target="_blank" rel="noopener noreferrer">《分享几个有趣的大模型(LLMs)应用场景，涉及金融分析、物联网、招聘、战术分析等》</a>。本文作者盘点了一些大模型（LLMs）在不同领域的应用案例。具体包括：利用MockLLM进行在线招聘面试，通过模拟面试过程提升人职匹配质量；ResearchAgent系统生成论文idea，优化科研思路；TacicAI在足球战术分析中的应用，高效提升角球战术效果；代码精细化，通过迭代改进源代码；CibyGPT处理物联网时空数据；finRobot进行高级金融分析；FactAgent用于假新闻检测和信息核查；以及基于信息检索系统的QA问答。这些案例展示了大模型在不同场景中的创新应用和潜在影响。</p><p><a href="https://mp.weixin.qq.com/s/sCD2DKx9-rroCoTh1bSvBQ" target="_blank" rel="noopener noreferrer">《苹果智能炸裂登场:直接GPT-4o加持，全家桶都上生成式AI，Siri脱胎换骨》</a>。这篇文章介绍了苹果在WWDC 2024发布的一系列生成式AI功能，由Apple Intelligence系统驱动，集成了GPT-4o和本地大模型加云端的混合策略。Siri更新与大模型结合，增强自然语言理解。Apple Intelligence系统应用广泛，覆盖语言和图像生成，以及系统级整合功能，如文档生成和图像处理。苹果还首次引入了iPhone通话录音和iPad计算器功能。这标志着苹果在AI技术领域迈出的重要一步。</p><p><a href="https://mp.weixin.qq.com/s/kpdkS1BeOwmnUiOcXxvfwA" target="_blank" rel="noopener noreferrer">《效果远超LoRA和QLoRA!PiSSA微调LLaMA-3》</a>。本文作者孟繁续详细介绍了如何使用PiSSA微调LLaMA-3模型。PiSSA通过不同的初始化方式，仍保持与LoRA和QLoRA相同的结构，但显著减少量化误差，提升了模型收敛速度和最终效果，并且适用于4bit量化场景。文中提供了具体的代码示例和步骤指南，展示了PiSSA的快速收敛和高效性能。作者还强调未来将在Huggingface平台上逐步共享更多模型和配置，方便用户使用和定制。PiSSA微调LLaMA-3使训练更高效，效果更优。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://dev.to/alvaronaschez/creating-a-chesscomlichess-clone-using-go-and-vue-1om" target="_blank" rel="noopener noreferrer">Creating a chess.com/lichess clone using Go and Vue</a></p><p><a href="https://mp.weixin.qq.com/s/e5as8u4aklbm9Aukw66KwA" target="_blank" rel="noopener noreferrer">Secure Randomness in Go 1.22</a></p><p><a href="https://mp.weixin.qq.com/s/RRigOLC_bQjOLh47gEVd-A" target="_blank" rel="noopener noreferrer">使用一键脚本搭建自己的镜像加速仓库</a></p><p><a href="https://mp.weixin.qq.com/s/EW1OUZSgtGSff5R8eg9fhg" target="_blank" rel="noopener noreferrer">Rust项目中使用 Lettre 进行发送邮件</a></p><p><a href="https://mp.weixin.qq.com/s/QqgwkNQ-qRo4Aa3HPZ9uhw" target="_blank" rel="noopener noreferrer">使用 Gin 快速开发高性能的 Web 应用</a></p><p><a href="https://mp.weixin.qq.com/s/cSs_4xP6aIztSoZIfvVnsw" target="_blank" rel="noopener noreferrer">在 Go 中如何优雅的使用 wire 依赖注入工具提高开发效率？上篇</a></p><p><a href="https://mp.weixin.qq.com/s/UAdVpZ_UvfdGdDMWmGRp2w" target="_blank" rel="noopener noreferrer">探索Rust在AI领域的应用</a></p><p><a href="https://mp.weixin.qq.com/s/aJ2ywxRvEIzKU9gUlG0NOw" target="_blank" rel="noopener noreferrer">Gopher的Rust第一课：Rust代码组织</a></p><p><a href="https://mp.weixin.qq.com/s/G1gXrl9C4knrXN93a-M4vw" target="_blank" rel="noopener noreferrer">Go必知必会：数组和切片详解</a></p><p><a href="https://mp.weixin.qq.com/s/wUn2TyI66GbzfMLCYHB6yg" target="_blank" rel="noopener noreferrer">分享最近学到的 5 个 Golang 小技巧</a></p><p><a href="https://mp.weixin.qq.com/s/eHoZI-VUDCxJq6wc3zNZSA" target="_blank" rel="noopener noreferrer">Docker镜像加速器被毙了？试下这种免费的方式吧！</a></p><p><a href="https://mp.weixin.qq.com/s/LxFntxCigGlUa1bcipKhZg" target="_blank" rel="noopener noreferrer">Go 面试中的隐藏陷阱：SliceHeader 问题解析</a></p><p><a href="https://mp.weixin.qq.com/s/mCZ9Fn3twf6dLzqyXxRpGA" target="_blank" rel="noopener noreferrer">Golang sql 标准库源码解析</a></p><p><a href="https://mp.weixin.qq.com/s/YY6Y-rpYASL6s6OMJCm20g" target="_blank" rel="noopener noreferrer">Go-Zero实战之docker开发环境部署（六）</a></p><p><a href="https://mp.weixin.qq.com/s/IM4yRYjZmQ2AGWhv87h2gA" target="_blank" rel="noopener noreferrer">使用 Nginx Ingress 实现金丝雀发布</a></p><p><a href="https://mp.weixin.qq.com/s/XEZADreCOhWCizJeUInl1A" target="_blank" rel="noopener noreferrer">Go即时通信：Goim 源码</a></p><p><a href="https://mp.weixin.qq.com/s/85CIMowIm9oon3m9Lzr8wg" target="_blank" rel="noopener noreferrer">Go 朝着错误的方向发展</a></p><p><a href="https://mp.weixin.qq.com/s/qrobTHebMnxsaQUuljxAMw" target="_blank" rel="noopener noreferrer">大厂开始选择使用 Rust 做微服务应用开发了</a></p><p><a href="https://mp.weixin.qq.com/s/WdLEIXnwmxpU25D7Yknpmg" target="_blank" rel="noopener noreferrer">Go 夜读第 155 期：带你从零到一实现 TCC 分布式事务框架</a></p><p><a href="https://mp.weixin.qq.com/s/pnMkTwons7Tsg19HBhCsTg" target="_blank" rel="noopener noreferrer">Go与神经网络：线性回归</a></p><p><a href="https://mp.weixin.qq.com/s/v9_9PGqsmqnQjT7f9soO6A" target="_blank" rel="noopener noreferrer">Rob Pike的编程哲学</a></p><p><a href="https://mp.weixin.qq.com/s/3MFTD5_FG80fSyHSeZhMuw" target="_blank" rel="noopener noreferrer">快速吃透 Golang Channels 使用技巧</a></p><p><a href="https://mp.weixin.qq.com/s/o3-yPO-OfdVlXvEtVPIzRw" target="_blank" rel="noopener noreferrer">Go 中空结构体的用法，我帮你总结全了！</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/aXaYZQdhbnWV6q3oiTs6Zw" target="_blank" rel="noopener noreferrer">网关系统就该这么设计（万能通用），稳的一批！</a></p><p><a href="https://mp.weixin.qq.com/s/kZGJR3e9BbsTRJUCD8FMMQ" target="_blank" rel="noopener noreferrer">领导撒事不干，凭什么工资比我高</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/cFzOOqknRyvwGxMLw5DNLw" target="_blank" rel="noopener noreferrer">VSCode无限画布模式（可能会惊艳到你的一个小功能）</a></p><p><a href="https://juejin.cn/post/7375858343179255862" target="_blank" rel="noopener noreferrer">Next.js v15 要来了，有哪些更新？附升级指南</a></p><p><a href="https://mp.weixin.qq.com/s/bdjBt0GcoS1jwqqBE3Lvkw" target="_blank" rel="noopener noreferrer">Next.js 项目接入 AI 的利器 —— Vercel AI SDK</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/6月9日内容汇总">6月9日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-06-09T00:00:00.000Z" itemprop="datePublished">June 9, 2024</time> · <!-- -->14 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/image-812b7464c8a84a0f4a2cdce8a8e2b97b.png" width="900" height="520" class="img_astN"></p><p>封面图：Go 1.22.4 is Released!</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/Jgf9akHdgxEokrlMPmGgQQ" target="_blank" rel="noopener noreferrer">《开源百B大语言模型哪家强?》</a>。本文作者爱因总结了截至2024年5月开源社区的百B大模型，包括Mixtral、Llama 3、Qwen1.5-110B 和 DeepSeek-V2。每个模型都有其特点，例如Mixtral 8x22B 采用稀疏的专家混合（SMoE）结构，性能强劲且成本效益高；Llama 3 400B 在多模态和多语言能力上有显著提升；Qwen1.5-110B 支持长达32K token的上下文长度，并在多语言理解方面表现优秀；而DeepSeek-V2 通过多头潜在注意力（MLA）和DeepSeekMoE的创新架构，实现了更高的性能和效率。文章详细对比了这些模型的架构、训练数据和性能表现，为读者提供了深入的参考。</p><p><a href="https://mp.weixin.qq.com/s/s5vChAY6B2s_ZVK-ALYP2w" target="_blank" rel="noopener noreferrer">《你好，Qwen2!》</a>。本文介绍了全新的Qwen2系列模型，这是通义千问团队对Qwen1.5的重大升级，包括从0.5B到72B的五个尺寸的预训练和微调模型。Qwen2不仅增加了27种语言的高质量数据，还在多项基准测试中表现出色，特别是在自然语言理解、代码、数学和多语言能力方面。Qwen2模型还支持最长128K tokens的上下文长度。文章详细阐述了Qwen2的架构、训练数据和优化方法，以及微调、推理和部署的详细过程。此外，Qwen2采用了更加开放的Apache 2.0许可（除72B模型外），以推动其在全球各地的应用。</p><p><a href="https://mp.weixin.qq.com/s/EXFIMUaSJfG_WhRCBzgmKA" target="_blank" rel="noopener noreferrer">《Mobile-Agent-v2: GPT4v + 多Agent提高40%准确率》</a>。本文介绍了由一支团队开发的Mobile-Agent-v2，这是一个通过多代理协作优化移动设备操作的助手系统，包含规划、决策和反思三个代理。与单一代理架构相比，Mobile-Agent-v2在复杂的移动设备任务中提高了30%以上的任务完成效率，并在一些高级操作中达到了55%的成功率。通过整合视觉感知和记忆模块，该系统大大改善了对屏幕内容的识别和任务执行的精度。反思代理的引入帮助纠正错误操作，进一步提升了系统的可靠性和灵活性。相关代码已在GitHub开源。</p><p><a href="https://mp.weixin.qq.com/s/luZGMG1RRUT4X_ckt8hsCQ" target="_blank" rel="noopener noreferrer">《Karpathy点赞，这份报告教你如何用 LLaMa 3创建高质量网络数据集》</a>。本文作者总结了一份名为FineWeb-Edu的工作，该工作受到AI大牛Andrej Karpathy的推荐。FineWeb-Edu通过使用LLaMa 3 70B评判，将原始的15万亿个FineWeb token过滤为1.3万亿个高质量教育内容token。FineWeb数据集来自96个CommonCrawl快照，经过多步数据过滤和重复数据删除，形成一个高达15万亿token的预训练数据集。FineWeb-Edu进一步利用LLaMa 3进行精细化的教育内容筛选，在教育基准测试中表现优越。文章深入探讨了大规模数据过滤、教育内容筛选器的设计和评估方法，非常适合研究如何创建用于大语言模型预训练的高质量网络数据集。</p><p><a href="https://mp.weixin.qq.com/s/duayAuvVfSoMlpRJQbDjrA" target="_blank" rel="noopener noreferrer">《RLHF替代方案:在SFT以外，我们还能拿SFT数据做什么?》</a>。本文提出了一种名为Alignment from Demonstrations (AfD)的RLHF替代方案。通过Inverse RL trajectory matching方法，文章探讨了何时应该使用SFT数据，何时应该进行Reward Modeling，并提出了利用SFT数据进行Reward Modeling的策略。具体内容涵盖MDP的定义、RLHF的局限、逆向强化学习的优缺点，并提供了相关的实验验证结果，展示了AfD方案在多种任务中的有效性。研究中使用的原模型和强化模型效果接近RLHF，具有更高的成本效益。</p><p><a href="https://mp.weixin.qq.com/s/w_MFh_-W5wpV2FwMCP5Yfg" target="_blank" rel="noopener noreferrer">《大模型对齐到底是与谁的价值对齐?KAIST-AI | 提出大模型多价值对齐方法!》</a>。本文介绍了KAIST-AI团队提出的一种大模型多价值对齐方法。传统的模型对齐方法假设与公众整体价值对齐是最佳选择，但人类价值观多样，需个性化对齐来满足用户多样化的需求。为此，作者创建了一个包含192k种价值观组合和65k条用户指令的偏好数据集，并训练了名为JANUS7B的大模型。实验结果表明用户可通过系统消息表明其价值偏好，使模型生成符合个体价值观的内容，提高了大模型在适应不同用户偏好方面的灵活性和有效性。</p><p><a href="https://mp.weixin.qq.com/s/7tPKmp-Z_unsjl7n7lV89Q" target="_blank" rel="noopener noreferrer">《深入理解AWQ量化技术》</a>。本文由Coder.AN撰写，介绍了AWQ（Activation-aware Weight Quantization）量化技术，这是一种基于激活值分布挑选显著权重进行量化的方法。AWQ量化不依赖反向传播或重建，可以保持大型语言模型在多领域的泛化能力。AWQ技术已被集成至多个推理框架，并被许多大厂采用，获得Mlsys 2024最佳论文提名。文章详细解释了AWQ的核心观点及其具体实现步骤，包括显著权重的识别和缩放算法的使用，有助于大幅降低模型内存占用并提高推理速度。</p><p><a href="https://mp.weixin.qq.com/s/o6shuvsz8UFJxbsknKf0tQ" target="_blank" rel="noopener noreferrer">《单卡训练 LLaMA-3-70B?PiSSA 参数微调方法实践》</a>。本文作者孟繁续博士介绍了来自北京大学人工智能研究院的一种名为PiSSA的参数微调方法。PiSSA通过对预训练模型的权重进行奇异值分解，初始化了一个适配器，能够在不完全训练模型的情况下达到近似效果。PiSSA与LoRA架构相似，但具有更快的收敛速度和更小的量化误差，允许在单卡GPU上完成大模型的微调训练。PiSSA已被合并到huggingface/peft项目中，并展示了在LLaMA-3等多种大模型上的优异表现。</p><p><a href="https://mp.weixin.qq.com/s/Y-3ZMvn_gZK1u5I6_woq_g" target="_blank" rel="noopener noreferrer">《借着triton inference server聊一下各种batching方法》</a>。本文作者介绍了在实际模型部署中如何使用多种batching方法优化模型性能。通过讨论单batch、静态batch、动态batch、连续batch、ragged batching以及自定义batching策略，文章详细说明了每种方法的适用场景和优势。例如，静态batch适合固定的输入shape，而连续batch则在高吞吐量场景中表现优异。文中提及的triton inference server和TensorRT-LLM等技术，展示了如何通过批处理策略提升模型服务的整体性能。</p><p><a href="https://mp.weixin.qq.com/s/OfA333WDUkNIprfMBJ9FjQ" target="_blank" rel="noopener noreferrer">《多模态LLM!谷歌 | 提出创新架构Zipper:分开训练再「压缩」》</a>。本文作者介绍了Google DeepMind提出的新型多模态架构Zipper。Zipper由多个单模态预训练解码器组成，通过交叉注意力将这些解码器压缩在一起，利用有限的跨模态数据微调，实现多模态生成能力。该方法利用无监督单模态数据进行强大的单模态预训练，然后通过融合这些预训练解码器来生成多模态内容。实验表明，Zipper模型在语音到文本和文本到语音任务上表现出色，并且相比传统方法更高效地利用了对齐数据。</p><p><a href="https://mp.weixin.qq.com/s/4kwCqxu6e2uFZ53UGbtDuw" target="_blank" rel="noopener noreferrer">《2024 人工智能最前沿:分享几个大模型(LLMs)的热门研究方向》</a>。本文作者介绍了当前人工智能领域中几个热门的大模型（LLMs）研究方向，包括检索增强生成（RAG）、大模型Agent、Mamba、MoE和LoRA等。每个方向都有其独特的应用场景和技术创新，例如RAG结合信息检索和文本生成以提高内容的准确性和鲁棒性，大模型Agent通过多任务学习和常识推理来增强AI的适应性，并且LoRA通过参数高效微调技术在减少资源消耗的同时维持模型性能。文章详细介绍了这些方向的研究重点和面临的挑战，旨在帮助寻找研究方向的学者了解前沿动态。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/XjEra9vuOBj1Y3b-jM3Oxw" target="_blank" rel="noopener noreferrer">Rust Tips #81 ~ #90</a></p><p><a href="https://mp.weixin.qq.com/s/02P6kZogyzOYm6QkKweDAg" target="_blank" rel="noopener noreferrer">Rust Tips #61 ~ #80</a></p><p><a href="https://mp.weixin.qq.com/s/i2qEvESgy2YueL1kjUCUzA" target="_blank" rel="noopener noreferrer">[<!-- -->Golang 1.23 前瞻<!-- -->]<!-- --> unique package 介绍</a></p><p><a href="https://mp.weixin.qq.com/s/UsoheOJsnkUkIpwK-PdmhA" target="_blank" rel="noopener noreferrer">Golang GC 基础: 三色标记清除和 STW</a></p><p><a href="https://mp.weixin.qq.com/s/92jjgtbPJ0W6pcgudfkq2A" target="_blank" rel="noopener noreferrer">Rust tips #41 ~ #60</a></p><p><a href="https://mp.weixin.qq.com/s/7bma0aoB2ZLX5F_LmvG19w" target="_blank" rel="noopener noreferrer">全球最大开源项目之一——Kubernetes诞生十周年</a></p><p><a href="https://mp.weixin.qq.com/s/buOZUGUF6bKoN3J3dOcZ4A" target="_blank" rel="noopener noreferrer">Rust Tips #21 ~ #40</a></p><p><a href="https://mp.weixin.qq.com/s/kDxIJEy9kfvvRXEZCzVI7Q" target="_blank" rel="noopener noreferrer">聊一聊使用Rust进行Web开发的细节</a></p><p><a href="https://mp.weixin.qq.com/s/RM6AzkFPBMUxWPe2Z3Ot3w" target="_blank" rel="noopener noreferrer">Rust 中使用 Serde 和 Serde_json 库实现 JSON 操作</a></p><p><a href="https://mp.weixin.qq.com/s/sJazQAYon7dgYRYIaLhj5g" target="_blank" rel="noopener noreferrer">使用 Rust Actix 快速开发高性能的Web应用</a></p><p><a href="https://mp.weixin.qq.com/s/sJUpIAxBMxbxXFmZu673ZA" target="_blank" rel="noopener noreferrer">Rust Actix-Web 高性能HTTP服务器的实现与配置</a></p><p><a href="https://mp.weixin.qq.com/s/4MwfLHqxFXkSxT6ytWr_lw" target="_blank" rel="noopener noreferrer">在 Rust Actix-Web 项目中实现 SSE 实时推送功能</a></p><p><a href="https://mp.weixin.qq.com/s/FqkbhsN93hDgsUvDrhKniA" target="_blank" rel="noopener noreferrer">Rust Actix-web 错误处理的最佳实践</a></p><p><a href="https://mp.weixin.qq.com/s/si0VzcyZRIp9cX-22ukLUA" target="_blank" rel="noopener noreferrer">快速上手Rust Actix-Web中的单元测试和集成测试</a></p><p><a href="https://mp.weixin.qq.com/s/sFCkv1f6qtfsHEbc-wD5pg" target="_blank" rel="noopener noreferrer">Rust 开发到底用 RustRover 与还是 VS Code Rust 插件</a></p><p><a href="https://mp.weixin.qq.com/s/FiO0c0CDJ4LR2GsRdh8CxQ" target="_blank" rel="noopener noreferrer">深入理解Rust的线程安全机制</a></p><p><a href="https://mp.weixin.qq.com/s/3z9lbJXKsKmYOUNZLFnCtw" target="_blank" rel="noopener noreferrer">跟着 Google 团队快速入门 Rust 编程</a></p><p><a href="https://mp.weixin.qq.com/s/3Xo6meiZa_AitddFpgUSZw" target="_blank" rel="noopener noreferrer">Gopher的Rust第一课：Rust代码组织</a></p><p><a href="https://mp.weixin.qq.com/s/ai54GIM-e3hWNj1MMUbntA" target="_blank" rel="noopener noreferrer">Go 项目文件命名规范是什么</a></p><p><a href="https://mp.weixin.qq.com/s/8r_8k6mN54obPSs1lUkz6Q" target="_blank" rel="noopener noreferrer">Rust Tips #1 ~#20</a></p><p><a href="https://mp.weixin.qq.com/s/tzUzoyAaNq-59PbwBlvqdg" target="_blank" rel="noopener noreferrer">如何优雅地处理 Goroutines 中的错误</a></p><p><a href="https://mp.weixin.qq.com/s/4VwlsxZ17kcZjOgPl-Ahtw" target="_blank" rel="noopener noreferrer">Go 1.22.4 is Released!</a></p><p><a href="https://mp.weixin.qq.com/s/Y7Cl_vKTN4CUcemmE5a17A" target="_blank" rel="noopener noreferrer">Go 语言 mongox 库：简化操作、安全、高效、可扩展、BSON 构建</a></p><p><a href="https://mp.weixin.qq.com/s/4pO7yMSiwXhTTU7IM1TusQ" target="_blank" rel="noopener noreferrer">Golang：使用bcrypt实现密码加密和和校验</a></p><p><a href="https://mp.weixin.qq.com/s/7dD18BazBSRdkaGXNF-toA" target="_blank" rel="noopener noreferrer">Go 夜读第 154 期：木鸟带你建立理解分布式系统的框架</a></p><p><a href="https://mp.weixin.qq.com/s/ShzYKGkOAqJFE1qRQXjSxw" target="_blank" rel="noopener noreferrer">K8s集群稳定性提升手段</a></p><p><a href="https://mp.weixin.qq.com/s/O5M5RFq2pgEutYncFYsFNA" target="_blank" rel="noopener noreferrer">Crossplane 实战：构建统一的云原生控制平面</a></p><p><a href="https://mp.weixin.qq.com/s/h8qaz1LF7HdwRy6ottW8cg" target="_blank" rel="noopener noreferrer">如何用 golang 从 OpenAI, Ollama 和 Claude 获取可靠的结构化输出</a></p><p><a href="https://mp.weixin.qq.com/s/gMro9EomjDnflLKldzZuag" target="_blank" rel="noopener noreferrer">Go 还缺少什么，能更完美</a></p><p><a href="https://mp.weixin.qq.com/s/3E2UvCIx9_XpLbmBmu-yUg" target="_blank" rel="noopener noreferrer">命令分发模式</a></p><p><a href="https://mp.weixin.qq.com/s/raFDnbkWU4G8Mvng1yo_8g" target="_blank" rel="noopener noreferrer">Enhancing Kubernetes API with k8s.io/apiserver - 自定义APIServer篇</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/HIsTtf7QC_n82fV6JuYv7g" target="_blank" rel="noopener noreferrer">“鸭子数据库”DuckDB正式发布1.0稳定版：C++引擎代码超30万行、百万级月下载量</a></p><p><a href="https://mp.weixin.qq.com/s/7TxBtoz4wMCjYjFe3qfKxg" target="_blank" rel="noopener noreferrer">干货 | 携程数据基础平台2.0建设，多机房架构下的演进</a></p><p><a href="https://mp.weixin.qq.com/s/yQLKQE5EB7fDBPAXzLPpEw" target="_blank" rel="noopener noreferrer">封装优雅的缓存组件库（Redis 缓存与内存缓存）</a></p><p><a href="https://mp.weixin.qq.com/s/UYS5ALDC0nOdookJGijkrg" target="_blank" rel="noopener noreferrer">MySQL 深潜 - Semijoin 丛林小道全览</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/YxPxpds9OJl0CWXTCYfxWg" target="_blank" rel="noopener noreferrer">61儿童节，我给儿子做了两款coze小应用，让他见识一下程序员爸爸的厉害</a></p><p><a href="https://mp.weixin.qq.com/s/0oZaNQguFHHL3OiXoiGbvA" target="_blank" rel="noopener noreferrer">忆童年：用 Coze 搭一只「AI 电子宠物」</a></p><p><a href="https://mp.weixin.qq.com/s/b7VpQ5LNKYYKf40Rq5youg" target="_blank" rel="noopener noreferrer">聊下 Mako 的 Benchmark</a></p><p><a href="https://mp.weixin.qq.com/s/8T9pfdKQ5A9N5e87Y92h5g" target="_blank" rel="noopener noreferrer">MDH Weekly 127 – 《六一快乐》</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/6月2日内容汇总">6月2日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-06-02T00:00:00.000Z" itemprop="datePublished">June 2, 2024</time> · <!-- -->12 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/maxresdefault-ffb8f11e1c31c2d1464780924ffb5d89.jpg" width="1280" height="720" class="img_astN"></p><p>封面图：Safe by construction - Roberto Clapis</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://arxiv.org/pdf/2405.19893" target="_blank" rel="noopener noreferrer">《Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered Thoughts》</a>。本文由Chunjing Gan等撰写，讨论了大型语言模型（LLMs）在知识密集型任务中遇到的知识更新不及时和幻觉问题，传统的基于相似性的检索增强生成（RAG）方法在这些任务中的局限性。作者提出了一种名为MetRAG的多层次思维增强RAG框架，该框架超越了现有的相似性导向模型，结合了效用导向思维和紧凑性导向思维，通过LLM进行任务自适应总结，并最终实现知识增强生成。实验结果显示，MetRAG在知识密集型任务中具备优越表现。</p><p><a href="https://arxiv.org/pdf/2405.00208" target="_blank" rel="noopener noreferrer">《A Primer on the Inner Workings of Transformer-based Language Models》</a>。本文由Javier Ferrando、Gabriele Sarti、Arianna Bisazza和Marta R. Costa-jussà撰写，主要介绍了解释基于Transformer的语言模型内部工作原理的当前技术。文章深入探讨了生成式解码器结构，综述了这些模型中已知的内部机制及其实现方法。通过总结多年研究的成果，文章为读者提供了关于这些技术的简明技术介绍，并揭示了流行方法与当前研究方向之间的联系，是理解和研究先进语言模型的宝贵资源。</p><p><a href="https://mp.weixin.qq.com/s/JxB6JU6MxO3709mkg7penw" target="_blank" rel="noopener noreferrer">《解决Transformer根本缺陷，CoPE论文爆火:所有大模型都能获得巨大改进》</a>。本文由Meta的FAIR团队撰写，介绍了新提出的上下文位置编码方法（CoPE），旨在解决传统Transformer在处理计数和复制任务中的缺陷。CoPE结合了内容和上下文的因素来编码位置，使模型更加灵活、高效地理解输入数据结构和语义内容。实验结果显示，CoPE在处理分布外数据以及需要高泛化能力的任务上表现出色，为大型语言模型在自然语言处理领域提供了更强的能力。这篇论文已成为AI领域的热门话题，具有重要的意义。</p><p><a href="https://mp.weixin.qq.com/s/O6a5LdjH-2LGR5tep3uUeg" target="_blank" rel="noopener noreferrer">《爆火ChatTTS突破开源语音天花板，3天斩获9k的Star量》</a>。本文介绍了ChatTTS项目的火爆现象。ChatTTS是一种新的文本转语音技术，能够生成自然流畅的语音合成，支持中英文混合语音和多样细粒度的控制，例如笑声、停顿等。该项目在GitHub上发布仅三天就获得了超过9,000个Star，展示了其巨大的关注度和影响力。尽管开源的只是底层模型，但ChatTTS已显现其在语音韵律控制和细节处理上的优势。未来的发展和完善或将进一步提升其在文本到语音转换领域的应用价值。</p><p><a href="https://mp.weixin.qq.com/s/iC5w0Ox-xk5KLnyEgb1Qew" target="_blank" rel="noopener noreferrer">《利用大模型构造数据集，并微调大模型》</a>。本文由稀土掘金技术社区首发，详细介绍了如何利用大语言模型（LLM）构造定制化的数据集，并使用其微调大模型。文章分为四部分：前言、构造数据集、微调模型和推理。首先，介绍了利用LLM生成自定义问答对数据集的方法，包括设计Prompt和处理文本数据的步骤。接着，讨论了如何使用LoRA（低秩适配器）技术在消费级硬件上微调模型，详细说明了数据加载、模型配置及训练参数设置的全过程。最后，提供了推理代码，展示了如何在微调后的模型上进行问答生成。这篇文章为AI开发者提供了实用的工具和方法，有助于高效地实现模型的个性化定制。</p><p><a href="https://mp.weixin.qq.com/s/xUJXxP6DQGqb6xrmTKKlgQ" target="_blank" rel="noopener noreferrer">《Meta| 提出上下文位置编码:CoPE，解决当前模型「普遍存在的问题」，含GPT-4o!》</a>。本文作者Meta团队提出了一种新的位置编码方法——上下文位置编码（CoPE），旨在解决传统Transformer模型中使用Token计数作为位置编码的局限性。CoPE通过结合上下文信息来定位，能够提高大模型在处理语言数据时的泛化能力和性能。实验表明，CoPE在处理计数、选择性复制等任务，以及在维基百科文本的语言建模上表现出色，显示了其在提升模型效果上的潜力。这项研究为进一步改进自然语言处理模型提供了新方向。</p><p><a href="https://mp.weixin.qq.com/s/sPeA9Vfip0Hv_8xDpb8zVw" target="_blank" rel="noopener noreferrer">《综述：大语言模型在信息抽取上的应用》</a>。本文综述了大语言模型(LLMs)在信息抽取(IE)领域的应用，特别是生成型大模型在命名实体识别(NER)、关系抽取(RE)和事件抽取(EE)方面的表现。LLMs展现出强大的跨领域泛化能力，通过生成范式为信息抽取任务提供了创新的解决方案。作者详细分类了相关工作并分析了前沿技术，指出LLMs结合IE的新趋势。文章还探讨了监督式微调、少样本学习、零样本学习和数据增强等不同学习范式，并展示了在不同数据集上的性能比较。这篇综述为研究人员提供了技术洞见和未来研究方向的参考。</p><p><a href="https://mp.weixin.qq.com/s/Tp9W0RR_rfeuv24ma67k0w" target="_blank" rel="noopener noreferrer">《AutoCoder:性能超越GPT-4o的模型，居然只有33B，还是开源!》</a>。本文介绍了由Meta团队推出的AutoCoder模型，这款只有33B参数的大模型在HumanEval基准测试中以90.9%的Pass@1成绩超越了GPT-4 Turbo。AutoCoder的灵活性得益于AIEV-Instruct技术，该技术通过智能体交互模拟和执行验证提升代码数据的质量。AutoCoder不仅在多种编程语言如Java、C++、Rust中表现优异，还支持安装外部包，进一步提升了解决复杂任务的能力。文章详细描述了AutoCoder的训练方法、数据集构建以及性能对比，并提供了模型的开源代码和实验示范。</p><p><a href="https://mp.weixin.qq.com/s/aJP-MgZ_8ZJeu3zxEuSGAA" target="_blank" rel="noopener noreferrer">《开源金融领域AI Agent平台:FinRobot，利用多源LLMs进行高级金融分析、市场预测》</a>。本文介绍了由Meta提出的开源AI Agent平台——FinRobot，该平台利用多源大语言模型(LLMs)，为金融领域提供高级分析和市场预测。FinRobot通过多层架构结合了金融思维链提示、市场预测Agent、文档分析Agent和交易策略Agent，以实现复杂的财务分析和决策支持。其创新的多源集成策略和实时数据处理能力确保了对全球市场的精准适应。文章详细描述了FinRobot的技术架构、应用场景及其在提升金融分析准确性和透明度方面的优势。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://juejin.cn/post/7343915092100431906" target="_blank" rel="noopener noreferrer">【一分钟快学】掌握Go语言并发编程：深入理解与精巧运用 sync.Map</a></p><p><a href="https://juejin.cn/post/7343814405442502694" target="_blank" rel="noopener noreferrer">挑战自我极限，用最简方式介绍从零开始构建 Kubernetes Operator</a></p><p><a href="https://juejin.cn/post/7351584333613727798" target="_blank" rel="noopener noreferrer">【一分钟快学】掌握Go语言：深入解析Context包与精妙的取消机制</a></p><p><a href="https://juejin.cn/post/7344916114204196901" target="_blank" rel="noopener noreferrer">【一分钟快学】并发编程的艺术：解锁如何在 Go 语言中的批量并发</a></p><p><a href="https://mp.weixin.qq.com/s/kT_yBR4l1kToawVzey7syA" target="_blank" rel="noopener noreferrer">[<!-- -->Golang 1.23 前瞻<!-- -->]<!-- -->使用 Go 实现可组合的函数迭代器</a></p><p><a href="https://mp.weixin.qq.com/s/raFDnbkWU4G8Mvng1yo_8g" target="_blank" rel="noopener noreferrer">Enhancing Kubernetes API with k8s.io/apiserver - 自定义APIServer篇</a></p><p><a href="https://mp.weixin.qq.com/s/nSUQgY9Rx47ZywhJQyh4Ew" target="_blank" rel="noopener noreferrer">[<!-- -->Golang 1.23 前瞻<!-- -->]<!-- -->对 //go:linkname 的修改及其对开发人员的影响</a></p><p><a href="https://mp.weixin.qq.com/s/3aw5sMsMW8MA_pJxlhMFbQ" target="_blank" rel="noopener noreferrer">使用 gpt-4o 分析火焰图</a></p><p><a href="https://mp.weixin.qq.com/s/0JS7XWcpRauj14xWGWopFw" target="_blank" rel="noopener noreferrer">Go 如何优雅实现业务并发</a></p><p><a href="https://mp.weixin.qq.com/s/c7UuQetStkA7Tw2DLfMjvA" target="_blank" rel="noopener noreferrer">Go 1.23新特性前瞻</a></p><p><a href="https://mp.weixin.qq.com/s/Wf49LyLs-avTLb5k4DHD0w" target="_blank" rel="noopener noreferrer">Enhancing Kubernetes API with k8s.io/apiserver - 网关篇</a></p><p><a href="https://mp.weixin.qq.com/s/4B82xP0uMLoK8Q_ETcQfFg" target="_blank" rel="noopener noreferrer">Flame Graph AI: Grafana新推出智能火焰图分析AI专家</a></p><p><a href="https://mp.weixin.qq.com/s/C0b-VqlKtrwApVHtVGy6yA" target="_blank" rel="noopener noreferrer">Go 通过 ETCD 实现应用选主</a></p><p><a href="https://mp.weixin.qq.com/s/S5YqeiFb4T9q-9DRpBtlRw" target="_blank" rel="noopener noreferrer">Go 命令模式实战</a></p><p><a href="https://mp.weixin.qq.com/s/OHb8ODD8x43pCBZVTfmA1Q" target="_blank" rel="noopener noreferrer">看了Kuberentes源码后，得到的 Golang 工程化实践</a></p><p><a href="https://mp.weixin.qq.com/s/cPLozuxxGOZbwsGUxFdoFw" target="_blank" rel="noopener noreferrer">Go 实现双buffer id生成器</a></p><p><a href="https://mp.weixin.qq.com/s/maaE3R7S-pfPgEHk3-BlyA" target="_blank" rel="noopener noreferrer">Go夜读第 153 期：chDB: In-Process ClickHouse引擎</a></p><p><a href="https://mp.weixin.qq.com/s/Y6XBCh6dhKvnbN03B5QB0Q" target="_blank" rel="noopener noreferrer">Gopher的Rust第一课：第一个Rust程序</a></p><p><a href="https://mp.weixin.qq.com/s/mRLIGYqq_R9G4G-FGdvWlg" target="_blank" rel="noopener noreferrer">还在为 Go 中繁琐 if-else 逻辑的烦恼? 那就用 vowlink 来解决</a></p><p><a href="https://mp.weixin.qq.com/s/_IpkHrU0w4ATtMat68Rknw" target="_blank" rel="noopener noreferrer">把Redis当作队列来用，真的合适吗</a></p><p><a href="https://mp.weixin.qq.com/s/mtyaQLiaf8Lhye18QSBwIg" target="_blank" rel="noopener noreferrer">容器网络原理</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/aYwBOnC2Q3DRLtngiMzSTA" target="_blank" rel="noopener noreferrer">SpringBoot+Redis+定时任务模拟手机短信验证</a></p><p><a href="https://mp.weixin.qq.com/s/Kt-m7nvWdtLAUV-lMnu95A" target="_blank" rel="noopener noreferrer">专栏：通过node-exporter源码掌握机器监控指标</a></p><p><a href="https://mp.weixin.qq.com/s/EQeRqt9kP33V0AYRPhk0_A" target="_blank" rel="noopener noreferrer">SpringBoot+Spring WebFlux响应式开发，实现打字效果</a></p><p><a href="https://mp.weixin.qq.com/s/XoyXeVZs66udzhxakXVTjw" target="_blank" rel="noopener noreferrer">向上管理：给我惊喜，而不是问题！</a></p><p><a href="https://mp.weixin.qq.com/s/8i3D-ppX5lYxpLO34L2eVw" target="_blank" rel="noopener noreferrer">这些年背过的面试题——领域模型落地篇</a></p><p><a href="https://mp.weixin.qq.com/s/RkGnDwjvLiBVFUXsu89U5g" target="_blank" rel="noopener noreferrer">SRE 排障利器，接口请求超时试试 httpstat</a></p><p><a href="https://mp.weixin.qq.com/s/06eND-fUGQ7Y6gwJxmvwQQ" target="_blank" rel="noopener noreferrer">不来看一看HTML请求后端性能优化的实战总结吗</a></p><p><a href="https://mp.weixin.qq.com/s/4APCJVcxyiKj5Xe4ns2PVw" target="_blank" rel="noopener noreferrer">管理者的进阶之路：正确的评价</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/AF-G4ZcfKO6stiZil5lS0A" target="_blank" rel="noopener noreferrer">一网打尽 Rust 语法</a></p><p><a href="https://mp.weixin.qq.com/s/_bcZOmLVgH9Ea4Iu0tcorw" target="_blank" rel="noopener noreferrer">Vite 热更新(HMR)原理了解一下</a></p><p><a href="https://mp.weixin.qq.com/s/X6ZMokNSAsBpqdiE17BFrA" target="_blank" rel="noopener noreferrer">老师又来活了，用coze快速搭建一个读书机器人</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/5月26日内容汇总">5月26日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-05-26T00:00:00.000Z" itemprop="datePublished">May 26, 2024</time> · <!-- -->11 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/maxresdefault-ffb8f11e1c31c2d1464780924ffb5d89.jpg" width="1280" height="720" class="img_astN"></p><p>封面图：Safe by construction - Roberto Clapis</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/8UG_NKD4F7xW6QeU76x4sA" target="_blank" rel="noopener noreferrer">《训练你自己的多模态大模型》</a>。作者介绍了如何根据官方教程训练LLaVA v1.5多模态模型。文章首先说明训练包括特征对齐阶段和视觉指令微调阶段。特征对齐阶段训练MLP连接器，使用LAION-CC-SBU数据集的558K子集；视觉指令微调阶段则通过GPT-4生成的150K条数据及515K条VQA数据进行训练。作者详细描述了数据准备和下载过程，并提供了各阶段训练脚本以及所需资源。文章为研究者和开发者提供了完整的操作指南，帮助实现多模态模型的自主训练。</p><p><a href="https://mp.weixin.qq.com/s/f-_GOiwbXOvsE-UzSh0lSg" target="_blank" rel="noopener noreferrer">《Anthropic | 数百万个特征，带你深入理解大模型的「思维」!》</a>。本文作者介绍了Anthropic在理解大模型内部运作机制方面的最新进展。团队通过在Claude Sonnet模型中提取数百万个特征，揭示了GPT等AI模型的内部表征。这些特征涉及人物、地点、科学概念和情感等，展示了模型的复杂思维过程。研究还发现了特定欺诈和偏见特征，提出了可能的安全性改进方法。这项工作为AI可解释性和安全性研究提供了重要见解和前景。</p><p><a href="https://mp.weixin.qq.com/s/pfSc3Rr8BBo0Lwa2Kb_rzw" target="_blank" rel="noopener noreferrer">《麻省理工(MIT) | 提出跨层Attention，减少Transformer大模型键值(KV)缓存，加快LLM推理!》</a>。本文作者介绍了一种新的Attention设计方法——跨层注意力（Cross-Layer Attention, CLA），用于减少Transformer大模型的键值（KV）缓存。CLA通过在不同层之间共享KV头，显著削减KV缓存大小，与现有方法相比在保证准确性的同时将KV缓存大小缩小了2倍。作者详细分析了CLA与多头注意力（MHA）、多查询注意力（MQA）和分组查询注意力（GQA）的对比，展示了实验结果和在关键指标上的影响，证明了CLA在降低内存占用和解码延迟方面的有效性。文章为优化大模型推理性能提供了新思路。</p><p><a href="https://mp.weixin.qq.com/s/4RH6C-M7zzd_6-34lhMwfQ" target="_blank" rel="noopener noreferrer">《用 Coze(扣子) 打造 &quot;最强&quot; 浏览器书签助手(上)》</a>。作者细讲解了如何利用Coze平台构建一个功能强大的浏览器书签助手。文章首先介绍了Coze新功能的速览，包括多Agents模式、记忆-变量、记忆-长期记忆等。接着，作者逐步展示了文件上传、书签提取、数据清洗、简单分类、生成书签文件以及AI书签检索的具体操作步骤，并结合实际代码示例进行说明。整篇文章为开发者提供了一个完整的实现路径，帮助实现书签管理自动化。</p><p><a href="https://mp.weixin.qq.com/s/PADxs5gW5AQU8dAsHXJhQw" target="_blank" rel="noopener noreferrer">《手把手拆解:从零实现Llama3大模型(Python)》</a>。本文参考Meta发布的开源LLama3系列模型，由开发者Nishant Aklecha详细介绍如何从零开始实现Llama3模型，包括跨多个头的注意力矩阵乘法、位置编码和每个层的细节解析。教程包括特征对齐（使用Andrej Karpathy的分词器实现）和神经网络训练、注意力机制实现、嵌入归一化步骤，并提供了训练脚本和所需资源下载链接。作者逐步拆解了从模型加载到生成Token的过程，为开发者们提供了具体实现路径和参考。项目在GitHub上开源并获得了大量关注，有助于提高对大模型的理解和应用。</p><p><a href="https://mp.weixin.qq.com/s/95CUl1bGN-fSvmAbH0O-DA" target="_blank" rel="noopener noreferrer">《大模型精度(FP16，FP32，BF16)详解与实践》</a>。本文作者王明对三种浮点数精度类型——FP16、FP32和BF16进行了详细介绍，解释了其表示方法及计算过程。文章通过对比这三种精度在机器学习模型训练中的表现，分析各自的优劣，FP16具备较高计算效率，FP32精度更高，BF16在兼顾精度和计算效率方面表现出色。文中还提供了具体的实践代码，帮助读者更好地理解不同精度浮点数的实际应用。</p><p><a href="https://mp.weixin.qq.com/s/T5efQNYfd0807mBcO9lgEg" target="_blank" rel="noopener noreferrer">《模型调优(RLHF/DPO/ORPO)终极指南》</a>。本文由张伟撰写，详细解读了三种模型调优方法：RLHF（基于人类反馈的强化学习），DPO（直接偏好优化）和ORPO（优势比偏好优化）。文章全面剖析了各方法的优缺点及其在训练效率和计算性能上的差异，RLHF复杂且资源密集，DPO通过解析映射提高效率，而ORPO则通过调整损失函数直接优化偏好，减少计算负担，适合资源有限的情况。</p><p><a href="https://mp.weixin.qq.com/s/3C4OuqPLUp7_psReAMhIOQ" target="_blank" rel="noopener noreferrer">《今日arXiv最热大模型论文: Agent也疯狂! FoA方法对智能体做树结构搜索，超越ToT》</a>。这篇文章介绍了由最新论文提出的“Fleet of Agents”（FoA）框架，通过将遗传粒子过滤概念应用于动态树搜索，有效解决了传统树搜索算法在不确定环境中的局限性。FoA通过独立agents的多步探索和重采样优化，实现了对24点游戏和小型填字游戏的显著性能提升和成本降低，较Tree of Thoughts (ToT)更具优势。</p><p><a href="https://mp.weixin.qq.com/s/srdS8qltf8r9pAEgqKPoVg" target="_blank" rel="noopener noreferrer">《GPT模型的前世今生》</a>。李媛媛撰写的这篇文章详细介绍了GPT模型的概念、架构及进化历程。文章逐步讲解了GPT-1至GPT-4各版本的改进优化，并讨论了其在自然语言处理中的应用，尤其是多模态处理能力的提升。此外，文章探讨了GPT模型的核心技术，包括Transformer架构、自注意力机制和残差连接等，以及未来可能发布的GPT-5的特性展望。总结了GPT系列在人工智能领域的重大影响及其应用前景。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://juejin.cn/post/7371239685701730342" target="_blank" rel="noopener noreferrer">Rust 大项目结构如何组织？参考官方标准，给你最清晰的回答</a></p><p><a href="https://juejin.cn/post/7281601361985241088" target="_blank" rel="noopener noreferrer">基于go语言gin框架的web项目骨架</a></p><p><a href="https://juejin.cn/post/7334103408196927529" target="_blank" rel="noopener noreferrer">Rust中打印语句为什么使用宏实现</a></p><p><a href="https://mp.weixin.qq.com/s/bAQg0pZXrG9gEcmT7JGZ9Q" target="_blank" rel="noopener noreferrer">从源码搞懂 kube-scheduler Pod绑定Node全流程</a></p><p><a href="https://mp.weixin.qq.com/s/BrkVDKXGYstQrCyeYG__Rw" target="_blank" rel="noopener noreferrer">Go Goroutine 究竟可以开多少</a></p><p><a href="https://mp.weixin.qq.com/s/NhfrDsk-54Se8ts6JMIWSw" target="_blank" rel="noopener noreferrer">Rust 练手项目—实现 MVCC 多版本并发控制</a></p><p><a href="https://mp.weixin.qq.com/s/AhD4t9DT_ecdG1MVJJMtwg" target="_blank" rel="noopener noreferrer">使用Rust捕获和解析网络包</a></p><p><a href="https://mp.weixin.qq.com/s/S23_NsOuGsDCfTJL_wniKw" target="_blank" rel="noopener noreferrer">xgo: 一款新鲜出炉的 Go 代码测试利器</a></p><p><a href="https://mp.weixin.qq.com/s/PBJAS-vbuYZfQuRrn3Roxw" target="_blank" rel="noopener noreferrer">Go 语言中 database/sql 是如何设计的</a></p><p><a href="https://mp.weixin.qq.com/s/SkVwege0EcLAegQFUw-81g" target="_blank" rel="noopener noreferrer">如何使用 database/sql 来操作数据库</a></p><p><a href="https://mp.weixin.qq.com/s/ZrYYMsuqrzWubh0zpIp17g" target="_blank" rel="noopener noreferrer">万字长文：Go 语言流行 ORM 框架 GORM 使用详解</a></p><p><a href="https://mp.weixin.qq.com/s/bztqsCEXGaiNiaEjz2lWoA" target="_blank" rel="noopener noreferrer">Skywalking通关指南</a></p><p><a href="https://mp.weixin.qq.com/s/Cy01y5Xs04OdyzeBOHnaRQ" target="_blank" rel="noopener noreferrer">弹性容器实例：基于 Argo Workflows 和 Serverless Kubernetes 搭建精细化用云工作流</a></p><p><a href="https://mp.weixin.qq.com/s/05IQZjcUKXM1i51p98oI0A" target="_blank" rel="noopener noreferrer">这30道K8S面试题你能答出来几个</a></p><p><a href="https://mp.weixin.qq.com/s/lE50bcosCyi-5P98QMwRVw" target="_blank" rel="noopener noreferrer">使用Go语言实现 pping</a></p><p><a href="https://mp.weixin.qq.com/s/2t1ABjI-2IL8DMaVinikGw" target="_blank" rel="noopener noreferrer">一文搞懂Kubernetes Service 网络</a></p><p><a href="https://www.bilibili.com/video/BV14U411o7ZU" target="_blank" rel="noopener noreferrer">Go 夜读第 152 期：从汇编角度理解 Go 语言</a></p><p><a href="https://mp.weixin.qq.com/s/dxBnBLbUKC9GTyi6NPDdTQ" target="_blank" rel="noopener noreferrer">Go团队：Go是什么</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/JchVvLMz2a0eQnzJs1oK-g" target="_blank" rel="noopener noreferrer">什么是MySQL锁？有哪些锁类型</a></p><p><a href="https://mp.weixin.qq.com/s/_DIWInIddfcsdggDCGOCyA" target="_blank" rel="noopener noreferrer">Jenkins Pipeline用户权限管理新技巧：打造安全高效的流水线！</a></p><p><a href="https://mp.weixin.qq.com/s/Wp6ErsgUKOYOjry7eRczEQ" target="_blank" rel="noopener noreferrer">这些年背过的面试题——架构设计篇</a></p><p><a href="https://mp.weixin.qq.com/s/oje7PLWHz_7bKWn8M72LUw" target="_blank" rel="noopener noreferrer">RocketMQ 是什么？它的架构是怎么样的？和 Kafka 又有什么区别</a></p><p><a href="https://mp.weixin.qq.com/s/Eluy6hc3jUHdZfdjEEJWpA" target="_blank" rel="noopener noreferrer">揭开管理的秘密：耗时半年精心打磨，一线管理者不可不读的终极指南！</a></p><p><a href="https://mp.weixin.qq.com/s/hC3TFKLFFEfC7Ietobkypw" target="_blank" rel="noopener noreferrer">10 亿级短 URL 生成方案，拿去可以直接重写短 URL 系统了</a></p><p><a href="https://mp.weixin.qq.com/s/xGYM0pXAHfaLMpTxBJvLBg" target="_blank" rel="noopener noreferrer">字节面试：百亿级存储，怎么设计？只是分库分表</a></p><p><a href="https://mp.weixin.qq.com/s/1puGCULSwfJdLD7onhrDtw" target="_blank" rel="noopener noreferrer">一个淘宝服务端工程师的年度总结</a></p><p><a href="https://mp.weixin.qq.com/s/gnjTj1Kw53iF_4Gr5RUxLQ" target="_blank" rel="noopener noreferrer">【视觉笔记】｜领导力21法则</a></p><p><a href="https://mp.weixin.qq.com/s/CFJWv0NLL97jhHvvveS5KQ" target="_blank" rel="noopener noreferrer">【消息队列】 一文搞懂 Kafka</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/7H6J9aH3pRHXD4nxEUwJaQ" target="_blank" rel="noopener noreferrer">node.js+AIGC：对输入的评论进行情感分析</a></p><p><a href="https://mp.weixin.qq.com/s/4MZhKf_p4JIHOmRqAf3AuQ" target="_blank" rel="noopener noreferrer">我使用coze做了一个云顶之弈助手，帮助我上分</a></p><p><a href="https://mp.weixin.qq.com/s/uP-n-AknzWSOZ95LGOdVfQ" target="_blank" rel="noopener noreferrer">autolog.js：一个小而美的toast插件</a></p><p><a href="https://mp.weixin.qq.com/s/o-h3JU7NRvgKGowaPpyK_A" target="_blank" rel="noopener noreferrer">VSCode深度配置 - settings.json</a></p><p><a href="https://mp.weixin.qq.com/s/VKtrNihMFGgo6RhlVgURXg" target="_blank" rel="noopener noreferrer">苦等三年，React Compiler 终于能用了</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/5月19日内容汇总">5月19日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-05-19T00:00:00.000Z" itemprop="datePublished">May 19, 2024</time> · <!-- -->4 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/maxresdefault-ffb8f11e1c31c2d1464780924ffb5d89.jpg" width="1280" height="720" class="img_astN"></p><p>封面图：Safe by construction - Roberto Clapis</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/MZHYqwfFR0aA-hOdTSuyzQ" target="_blank" rel="noopener noreferrer">GPT-4o团队引发OpenAI组织创新热议！应届生领衔Sora，本科生带队GPT-1，经验职级都是浮云</a></p><p><a href="https://mp.weixin.qq.com/s/G5NXAr9-BOjUAY4nrfKROA" target="_blank" rel="noopener noreferrer">生成式AI原理技术详解（二）——高级神经网络</a></p><p><a href="https://mp.weixin.qq.com/s/Gi9Vme6khmy3UMhWnDjMrg" target="_blank" rel="noopener noreferrer">他们卷大模型，小模型交给我：千元实现多终端设备的视觉分类</a></p><p><a href="https://mp.weixin.qq.com/s/BV6afLLJNwtQeRd_9ZRWYw" target="_blank" rel="noopener noreferrer">达到1k stars后🥂，我对大模型开源教程的反思！</a></p><p><a href="https://mp.weixin.qq.com/s/VNWnf4tB7D0DF1GcP2mHGg" target="_blank" rel="noopener noreferrer">以 LLM 为基础的 Multi-Agent 系统解析</a></p><p><a href="https://mp.weixin.qq.com/s/YlYGXEFRIrVbs2yyT5lZZg" target="_blank" rel="noopener noreferrer">GPT-4o炸裂玩法大赏！选股效率爆炸、创造新物种、暴打广告设计、金牌作业辅导...</a></p><p><a href="https://mp.weixin.qq.com/s/cAeLgg46Wq81rhgsJp0l4Q" target="_blank" rel="noopener noreferrer">GPT-4o深夜炸场！AI实时视频通话丝滑如人类，Plus功能免费可用，奥特曼：《她》来了</a></p><p><a href="https://mp.weixin.qq.com/s/PfWnlhXh3n3VDfZaMI-ifQ" target="_blank" rel="noopener noreferrer">OpenAI颠覆世界：GPT-4o完全免费，实时语音视频交互震撼全场，直接进入科幻时代</a></p><p><a href="https://mp.weixin.qq.com/s/NPcCHlLjBZeUiAhQOHX5qA" target="_blank" rel="noopener noreferrer">快速提升性能，如何更好地使用GPU（下）</a></p><p><a href="https://mp.weixin.qq.com/s/h8z4eXsemPMeL2oI_8VnvQ" target="_blank" rel="noopener noreferrer">一文看懂RAG的各种套路 | 综述：当RAG遇到大语言模型</a></p><p><a href="https://mp.weixin.qq.com/s/3wD-0dCgXB646r720o8JAg" target="_blank" rel="noopener noreferrer">零一万物Yi-1.5系列模型发布并开源！ 34B/9B/6B 多尺寸，魔搭社区推理微调最佳实践教程来啦！</a></p><p><a href="https://mp.weixin.qq.com/s/ew7z9zgYHEngTwtYohPUkg" target="_blank" rel="noopener noreferrer">从头预训练一只超迷你 LLaMA 3——复现 Tiny Stories</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/d4n_8MpDi6azlIditkRmkQ" target="_blank" rel="noopener noreferrer">看了Kubernetes源码后，我更喜欢写Golang的单元测试了</a></p><p><a href="https://mp.weixin.qq.com/s/CsrEA7Mkw4B7m8Hhgb-wfQ" target="_blank" rel="noopener noreferrer">Go实战 | 《微服务实战gin+grpc：项目管理/协同系统》</a></p><p><a href="https://mp.weixin.qq.com/s/gUignWHIUy--8Ap0VC_5Iw" target="_blank" rel="noopener noreferrer">如果有 AI 加持，go 的这个问题会避免吗</a></p><p><a href="https://mp.weixin.qq.com/s/8nOFjKJ9lnZDQh3zc-N0AA" target="_blank" rel="noopener noreferrer">Golang 中的 Base64 编解码</a></p><p><a href="https://mp.weixin.qq.com/s/WRCvHETs_eWZcNek0GMrPA" target="_blank" rel="noopener noreferrer">让研发规范管得住 - 我们为什么在流水线之上又做了研发流程</a></p><p><a href="https://mp.weixin.qq.com/s/V32txuNHraazDlD1F9w9Jg" target="_blank" rel="noopener noreferrer">Go module 目录为什么带 ! 感叹号？</a></p><p><a href="https://mp.weixin.qq.com/s/oUpHl74zkMha_Syw9-uZBw" target="_blank" rel="noopener noreferrer">使用 OpenTelemetry 实现 Golang 服务的可观测系统</a></p><p><a href="https://mp.weixin.qq.com/s/2Wq4Kb2fw1RLhUIAfByWaA" target="_blank" rel="noopener noreferrer">Go-Zero定义API实战：探索API语法规范与最佳实践（五）</a></p><p><a href="https://mp.weixin.qq.com/s/XpnPzbCQ7gdwWzvT9lAj9g" target="_blank" rel="noopener noreferrer">KubeBlocks - 云原生数据库基础设施（值得拥有）</a></p><p><a href="https://mp.weixin.qq.com/s/sOjUSvIM5IO-n0wL5KuIrQ" target="_blank" rel="noopener noreferrer">pping: 被动式ping，计算网络时延</a></p><p><a href="https://mp.weixin.qq.com/s/z0aJ2-1fbaxpOjqAySQmMQ" target="_blank" rel="noopener noreferrer">Go 夜读第 151 期：xgo: 基于编译期代码重写实现 Mock 和 Trace</a></p><p><a href="https://mp.weixin.qq.com/s/2NxC4oO_4KpsMAf9dpayFg" target="_blank" rel="noopener noreferrer">基于Pingora实现k8s的网关，代码实战（一）</a></p><p><a href="https://mp.weixin.qq.com/s/7LgEB79u6orPmW-44KSBpg" target="_blank" rel="noopener noreferrer">Go 事件驱动编程：实现一个简单的事件总线</a></p><p><a href="https://mp.weixin.qq.com/s/LlXnachkw8H9I_SAYA23gg" target="_blank" rel="noopener noreferrer">Kubernetes 最佳实践之解决容器内时区不一致问题</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/S-oAZ4qaN8qLbLBndpiK-w" target="_blank" rel="noopener noreferrer">Spring Boot+Groovy 魔法轻松实现动态编程！</a></p><p><a href="https://mp.weixin.qq.com/s/zVvRfhJVOzhgalNADq7GFw" target="_blank" rel="noopener noreferrer">Kafka 消息堆积四连击：一些优化技巧</a></p><p><a href="https://mp.weixin.qq.com/s/ZALPGbsvYpKv66POZ4V6dw" target="_blank" rel="noopener noreferrer">这些年背过的面试题——个人项目篇</a></p><p><a href="https://mp.weixin.qq.com/s/OT6LuwX1XyQ0n8P_FMzS-g" target="_blank" rel="noopener noreferrer">DDD面试题：什么是领域驱动设计？什么是贫血模型？什么是充血模型？（大厂面烂了）</a></p><p><a href="https://mp.weixin.qq.com/s/AkxNqWFUoLEpJ5BDXIyxSw" target="_blank" rel="noopener noreferrer">高并发架构的三板斧，你也可以成为架构师</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/ll6KS9fW9O_PZYmRHwuDnA" target="_blank" rel="noopener noreferrer">作为前端开发，感受下 nginx 带来的魅力！</a></p><p><a href="https://mp.weixin.qq.com/s/waFMJHdqlaYbZtBEJvafMQ" target="_blank" rel="noopener noreferrer">卡顿减少 95% — 记一次React性能优化实践（性能篇）</a></p><p><a href="https://juejin.cn/book/7347579913702293567" target="_blank" rel="noopener noreferrer">从前端到 AI：LangChain.js 入门和实战</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/frontend-weekly/2024/page/2"><div class="pagination-nav__label">Older Entries</div></a></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Blog</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/frontend-weekly/2024">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/garfield-dev-team/Garfield-cli" target="_blank" rel="noopener noreferrer" class="footer__link-item">Garfield-cli 前端工程化<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/Jiacheng787/Garfield-utils" target="_blank" rel="noopener noreferrer" class="footer__link-item">NPM 工程化规范<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/Jiacheng787/React-zero-to-one" target="_blank" rel="noopener noreferrer" class="footer__link-item">React 从零到一工程化指北<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/Jiacheng787/go-by-example" target="_blank" rel="noopener noreferrer" class="footer__link-item">Golang 学习<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/Jiacheng787/Bytedance-interview" target="_blank" rel="noopener noreferrer" class="footer__link-item">面试内容汇总<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Garfield Dev Team. Built with Docusaurus. Deploys on GitHub Pages.</div></div></div></footer></div>
<script src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/js/runtime~main.14a8a14b.js"></script>
<script src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/js/main.90d1b645.js"></script>
</body>
</html>