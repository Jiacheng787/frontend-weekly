<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-list-page plugin-blog plugin-id-2024">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.3.1">
<title data-rh="true">Blog | Frontend Weekly</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/frontend-weekly/2024"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="Blog | Frontend Weekly"><meta data-rh="true" name="description" content="Blog"><meta data-rh="true" property="og:description" content="Blog"><meta data-rh="true" name="docusaurus_tag" content="blog_posts_list"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_posts_list"><link data-rh="true" rel="icon" href="/frontend-weekly/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/frontend-weekly/2024"><link data-rh="true" rel="alternate" href="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/frontend-weekly/2024" hreflang="en"><link data-rh="true" rel="alternate" href="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/frontend-weekly/2024" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/frontend-weekly/2024/rss.xml" title="Frontend Weekly RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/frontend-weekly/2024/atom.xml" title="Frontend Weekly Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/frontend-weekly/2023/rss.xml" title="Frontend Weekly RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/frontend-weekly/2023/atom.xml" title="Frontend Weekly Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/frontend-weekly/2022/rss.xml" title="Frontend Weekly RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/frontend-weekly/2022/atom.xml" title="Frontend Weekly Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/frontend-weekly/2021/rss.xml" title="Frontend Weekly RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/frontend-weekly/2021/atom.xml" title="Frontend Weekly Atom Feed"><link rel="stylesheet" href="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/css/styles.52862517.css">
<link rel="preload" href="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/js/runtime~main.f604be39.js" as="script">
<link rel="preload" href="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/js/main.3f218b19.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_Rzz1" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/frontend-weekly/"><div class="navbar__logo"><img src="/frontend-weekly/img/logo.svg" alt="My Site Logo" class="themedImage_DeRy themedImage--light_hbln"><img src="/frontend-weekly/img/logo.svg" alt="My Site Logo" class="themedImage_DeRy themedImage--dark_qgR1"></div><b class="navbar__title text--truncate">Frontend Weekly</b></a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a aria-current="page" class="navbar__link active" aria-haspopup="true" aria-expanded="false" role="button" href="/frontend-weekly/2024">Blog of 2024</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/frontend-weekly/2024">2024</a></li><li><a class="dropdown__link" href="/frontend-weekly/2023">2023</a></li><li><a class="dropdown__link" href="/frontend-weekly/2022">2022</a></li><li><a class="dropdown__link" href="/frontend-weekly/2021">2021</a></li></ul></div><a href="https://github.com/garfield-dev-team/frontend-weekly/tree/main/static/img/IMG_0058.JPG" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">⭐️ 前端交流群<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://github.com/garfield-dev-team/frontend-weekly" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_HPIb colorModeToggle_KItF"><button class="clean-btn toggleButton_yRlM toggleButtonDisabled_oHIz" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_Vljy"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_lcNQ"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_mmj0"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_NWrx"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_J5VD thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_ZkTY margin-bottom--md">All posts in 2024</div><ul class="sidebarItemList_Jaez clean-list"><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/welcome">置顶内容</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/3月31日内容汇总">3月31日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/3月24日内容汇总">3月24日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/3月17日内容汇总">3月17日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/3月10日内容汇总">3月10日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/3月3日内容汇总">3月3日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/2月25日内容汇总">2月25日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/2月18日内容汇总">2月18日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/2月11日内容汇总">2月11日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/2月4日内容汇总">2月4日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/1月28日内容汇总">1月28日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/1月21日内容汇总">1月21日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/1月14日内容汇总">1月14日内容汇总</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/frontend-weekly/2024/1月7日内容汇总">1月7日内容汇总</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/welcome">置顶内容</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-12-12T00:00:00.000Z" itemprop="datePublished">December 12, 2024</time> · <!-- -->145 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>⭐️ 每周更新优质技术文章，欢迎点赞关注！</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_HAaO padding--none margin-left--sm"><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/type-script">TypeScript</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/前端框架">前端框架</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/webpack">Webpack</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/源码系列">源码系列</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/业务成长">业务成长</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/性能优化">性能优化</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/组件库实战">组件库实战</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/网络相关">网络相关</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/机器学习">机器学习</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/java">Java</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/frontend-weekly/2024/tags/golang">Golang</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about 置顶内容" href="/frontend-weekly/2024/welcome"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/3月31日内容汇总">3月31日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-03-31T00:00:00.000Z" itemprop="datePublished">March 31, 2024</time> · <!-- -->26 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/maxresdefault-ffb8f11e1c31c2d1464780924ffb5d89.jpg" width="1280" height="720" class="img_astN"></p><p>封面图：Safe by construction - Roberto Clapis</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/ZY8zwaGdR6dq1OL_XQ2iTQ" target="_blank" rel="noopener noreferrer">《面向业务开发的 Coze 使用指南》</a>。文章作者详细介绍了 Coze，一个一站式 AI Bot 开发平台，强调了它的易用性与功能强大，适合各类问答 Bot 的开发和部署至社交平台。通过举例说明如何使用 Coze 迅速搭建 AI 智能体和 RAG 问答系统，展示其插件库丰富性和沟通插件的效果。文章还讨论了 Coze 长期记忆的实用性，通过对话创建数据库并进行 CRUD 操作，以及如何实现长期记忆。最后，作者分析了 Coze 与其他 AI 开发工具的差异和适用场景，为读者提供了一个 Coze 实现原理和使用方式的深入指南。</p><p><a href="https://mp.weixin.qq.com/s/FTd9L6HzpV-5AoT20V8YyQ" target="_blank" rel="noopener noreferrer">《Qwen1.5-MoE模型:2.7B的激活参数量达到7B模型的性能》</a>。文章介绍了阿里巴巴开源的 Qwen1.5-MoE模型，它在总参数量14.3B的基础上，每次激活8个专家，激活参数量仅为2.7B，并且与7B模型性能相当。突破性的是实现了约75%的训练成本降低和1.74倍推理速度提升。作者描述了模型的结构改进，例如细粒度专家细分、模型初始化优化，以及共享路由机制。此外，文章还评估了模型在不同领域如MMLU、GSM8K、HumanEval和多语言领域的任务表现，并与7B模型进行对比。通过这些测试表明，即使在较低的激活参数量下，Qwen1.5-MoE-A2.7B模型也获得了卓越的性能，有效降低了训练与推理成本。</p><p><a href="https://mp.weixin.qq.com/s/Y_Xbpaat3ClZ6LIUkUzg9A" target="_blank" rel="noopener noreferrer">《港大 | 提出高效大模型微调方法:LISA，性能碾压LoRA，甚至可超全参数微调!》</a>。这篇文章讨论了港大研究者提出的新型大模型微调方法：LISA。该方法通过分层重要性采样（Layerwise Importance Sampled Adam）优化少数关键层，进而以更少的GPU内存消耗实现了性能超越低秩适应（LoRA）的微调，并有潜力超越全参数微调。LISA 方法在微调大规模语言模型上显著降低了资源消耗，在多种下游任务表现突出，优于传统微调，解决资源限制下的大模型训练挑战，对提升大模型训练的可行性和效率具有重大意义。</p><p><a href="https://mp.weixin.qq.com/s/NEf1TwwKd69_l_qsZsMlhw" target="_blank" rel="noopener noreferrer">《LLM训练要不要过采样/训多个epoch?》</a>。本文作者探讨了在数据资源紧缺的情况下，循环使用数据（即过采样或多次epoch训练）对大型语言模型（LLM）训练的影响。通过实验发现，重复使用数据会导致模型性能下降和过拟合风险。文章讨论了几个主要问题：重复训练（repeat）导致得分降低、即便少量重复也存在过度拟合的风险、以及LLM在不同个体的数据下受重复影响的程度不同。分析显示，重复会让模型在生成响应时更依赖早期输出而非指令与输入。文章最后提及，数据量和质量对缓解过拟合的影响，以及如何通过适当策略（例如使用dropout）对抗过拟合现象。</p><p><a href="https://mp.weixin.qq.com/s/3KkgskOpqL7fJ5w9fpQm7g" target="_blank" rel="noopener noreferrer">《视频生成新玩家:Sora 原理探索与效果对比》</a>。文章由支付宝算法工程师杰凡撰写，介绍了 OpenAI 提出的视频生成模型 Sora 和其它主要视频生成玩家的比较。Sora 能够根据文本提示词，生成长达一分钟且质量极高的视频，而其他模型生成的视频时间要短得多。文章探究了 Sora 视频生成的原理，包括其视觉编码器/解码器结构、扩散模型等，并讨论了 Sora 生成的视频如何实现三维一致性、长序列连贯性以及与世界的互动。文章总结了 Sora 的技术特性并略提其局限性，指出 AIGC 竞赛不仅在模型结构上，还在大规模高质量训练数据、工程优化、训练技巧和经验上展开竞争。</p><p><a href="https://mp.weixin.qq.com/s/6AM39RXaahpwniZ0wL-Yfg" target="_blank" rel="noopener noreferrer">《聊聊 MOE + LoRA 微调新方式》</a>。这篇文章讨论了 MOE（Mixture-of-Experts）与 LoRA（Low-Rank Adaptation）相结合的新型微调方式。该方法利用 LoRA 技术只微调参数的一部分，并保持大语言模型（LLMs）的预训练参数不变。文章中详细介绍了 LLaVA-MoLE 模式，在此模式下，通过在 Transformer 层内为 MLP 层创建专门用于 LoRA 的专家组，使用 MoE 概念并根据路由函数自适应选择不同领域的输入令牌。实验显示，这种微调方法解决了多任务数据冲突问题，在保持计算成本相似的同时，提高了微调的效果和性能。</p><p><a href="https://mp.weixin.qq.com/s/R56Ob5dZjMh1alhMin8DZw" target="_blank" rel="noopener noreferrer">《32K上下文，Mistral 7B v0.2 基模型突然开源了》</a>。本文介绍了 Mistral AI 最新开源的 Mistral 7B v0.2 Base Model。这个模型的更新包括扩展上下文限制至 32K、调整Rope Theta参数至1e6，以及去除了滑动窗口技术。这些改进使得 Mistral 7B 成为同规模模型中性能最好的之一，并为开发者提供了按需微调模型的可能。此外，文章还提到 Mistral AI 的未来目标是与 OpenAI 比肩，并已与微软 Azure 创建战略合作。最新的 Mistral Large 模型则直接针对 GPT-4 竞争，展现了 Mistral AI 从开源模式到优化商业模式的战略转变。</p><p><a href="https://mp.weixin.qq.com/s/XS1_NAZ65P-1aLqwWm2hbg" target="_blank" rel="noopener noreferrer">《原创 | 一文读懂K均值(K-Means)聚类算法》</a>。本文详细介绍了K-Means聚类算法，一个广泛使用的无监督学习算法，它适用于聚集数据并发现数据内在的分布结构。文章解释了K-Means算法的基本原理，其中簇的数量K是预先确定的，且簇的中心或质心是通过算法迭代计算得出。算法过程包括随机选择初始质心、分配数据点到最近的质心、重新计算质心，并重复这个过程直到质心稳定。作者提供了一个手工计算的例子来说明K-Means如何工作，并详述了如何通过总簇内平方和的最小化来评估聚类效果。此外，文中对算法的时间复杂度、初始化问题以及优缺点都进行了讨论。</p><p><a href="https://mp.weixin.qq.com/s/8wHkjPlEIfzjHCU6SS5fPA" target="_blank" rel="noopener noreferrer">《大语言模型时代的聚类怎么做?哪种embedding算法和聚类算法最有效?》</a>。本文研究在大语言模型(LLM)时代文本聚类的有效方法，对比各种文本嵌入方法及聚类算法。研究显示，LLM嵌入在抓取结构化语言特征上表现突出，特别是BERT在轻量级嵌入中卓越。使用多种验证指标（如F1分数、调整兰德指数等），结果推荐在正规文本聚类中配合k-means算法使用OpenAI嵌入方法。实验发现，在优化聚类质量时，应平衡嵌入维度、摘要技术等因素，避免一味追求维度增大。BERT由于较低维度和上下文理解力，在开源模型中效果最佳；而在LLM嵌入之间，Falcon-7b因混合语料库训练在多数数据集上超越LLaMA-2-7b。</p><p><a href="https://mp.weixin.qq.com/s/W3zbcdrOo4M07Os16UD9Ow" target="_blank" rel="noopener noreferrer">《从长期记忆的角度谈Agent》</a>。本文探讨了在构建自主智能体（Autonomous Agents）和智能体模拟器（Agent Simulations）时，长期记忆这一核心能力的重要性和实现。作者说明了大语言模型（LLM）在长期记忆上的局限性，并讨论了如何通过外部存储来辅助LLM的记忆。同时，介绍了几个流行的自主智能体项目，如Langchain、Visual-ChatGPT与HuggingGPT，并详细解析了如何结合短期和长期记忆管理，以及通过文档检索来增强LLM在处理增强记忆任务时的性能。此外，文中还讨论了如何使用向量搜索改进传统搜索，以及基于LLM的高阶逻辑链技术的潜力。</p><p><a href="https://mp.weixin.qq.com/s/GFUG3IVRpe-TbDM0DimshA" target="_blank" rel="noopener noreferrer">《从啥也不会到GPT-3和InstructGPT》</a>。作者详细记录了从基本的机器学习原理起步，逐步学习NLP和大型语言模型（LLM）的心得。强调了深度递归学习方法，即遇到不懂的概念就立刻搜索学习的重要性。文章详细列出了学习大模型的顺序，包括预处理、分词、模型优化等，一直至对GPT-3和InstructGPT的理解。每一部分都有推荐文献和关键点说明，使读者可以按顺序阅读文档逐步理解。涉及多种模型的细节，像Transformer、BERT、T5和GPT系列，并且讨论了各种模型的原理和应用。</p><p><a href="https://mp.weixin.qq.com/s/WHgnP2aJM37Q5jjNVyu_iA" target="_blank" rel="noopener noreferrer">《ChainLM: CoTGenius 框架，专门用于自动生成高品质的 CoT 提示》</a>。文章介绍了CoTGenius框架，它是设计来自动生成高品质Chain-of-Thought (CoT)提示的系统。通过三种策略（复杂化、多样化、具体化）和筛选机制（进化成功评判、正确性验证），它能生成更有挑战性和具体性的CoT问题。此外，文中提出“步级辩论法”，多个角色对推理步骤逐一讨论以确保正确性，增强了模型在复杂推理任务上的表现。相关数据集和代码也公开分享以进一步的社区研究和应用。</p><p><a href="https://mp.weixin.qq.com/s/5-W0Dt676qNhKZkLaNEcwQ" target="_blank" rel="noopener noreferrer">《Token预测的未来:大型语言模型的预训练后操作》</a>。文章详细探讨了大型语言模型在预测单个Token功能之外的能力，如理解上下文、创造连贯文本和解决问题。强调了从基础预训练到指令微调和对齐的多层训练方法的重要性。开篇介绍了语言模型的基础组件和Transformers的token预测。之后，分析了OpenAI的InstructGPT如何创新非任务特定微调，提高模型对细腻指令的响应力。最后说明了精心设计的交互提示的重要性，以及如何使这些高度复杂的模型与人类指令和价值观更好地对齐。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/nnxQjzPRnRUApbIMuhTU8g" target="_blank" rel="noopener noreferrer">《分布式系统模式 - 低水位标记(Low-Water Mark)》</a>。文章介绍了分布式系统中低水位标记(Low-Water Mark)机制，重点是如何管理日志文件的大小和保留时间以优化存储。探讨了两种低水位标记策略：基于快照的低水位标记和基于时间戳的低水位标记。文中以ZooKeeper和etcd为例，描述了周期性快照帮助确定可丢弃日志的边界，而Kafka则使用时间戳决定日志保留期。文章还深入讨论了etcd中快照和写前日志(WAL)如何结合使用以确保状态一致性，并对Kafka日志清理的基于时间和大小的策略进行了阐释。</p><p><a href="https://mp.weixin.qq.com/s/dPWImK8knB36ZUnueMdoEA" target="_blank" rel="noopener noreferrer">《Go 1.22引入的包级变量初始化次序问题》</a>。文章详述了Go 1.22版本对包级变量初始化顺序的改变。由于Go 1.22未在官方Release Note中提及变化，作者发现变量初始化顺序与文档描述相悖。经过详细分析和测试，作者推测Go 1.22将常量误视为未初始化变量，导致初始化次序变动。此问题被提交至Go官方GitHub(issue #66575)，并获确认，修复计划已纳入Go 1.23版本。文章还讨论了Go语言规范与实际编译器行为的一致性问题。</p><p><a href="https://mp.weixin.qq.com/s/MlS0rp5wM02z2WfDb7IgZw" target="_blank" rel="noopener noreferrer">《分布式系统模式 - 分段日志(Segmented Log)》</a>。文章着重讲述了日志分割技术对于处理大体量日志的重要性，并介绍了如何通过日志分割来映射日志偏移量，优化读写性能。文中详细举例了Kafka、etcd和MySQL的实际应用案例，说明分割日志和维护索引如何帮助它们高效地处理日志数据。特别指出Kafka如何通过分段和索引机制处理日志分段，详述了etcd中的分段日志管理，以及MySQL二进制日志的组成和查询方式，体现了分段日志模式在现代分布式系统中的实践价值。</p><p><a href="https://mp.weixin.qq.com/s/zq5V6zkVrAx-j8obm6YcIA" target="_blank" rel="noopener noreferrer">《Go singleflight 源码剖析》</a>。本文深入分析了 Go 语言中singleflight包的源码，讲解其如何通过Group和call结构体来防止缓存击穿，保障相同资源的请求在同一时刻只执行一次。详细解释了其中的核心机制，包括请求的合并和结果的共享等。文章还探讨了如何通过Do、DoChan和Forget方法来处理请求，确保函数调用的唯一性及结果的正确分发。通过对Result和panicError结构体的剖析，作者清晰展示了singleflight提供的错误处理和结果传递功能。</p><p><a href="https://mp.weixin.qq.com/s/3qTPyg17i7n1IiJuIYBOrA" target="_blank" rel="noopener noreferrer">《分布式系统模式 - Write-Ahead Log》</a>。本文探讨了Write-Ahead Log (WAL)在分布式系统中的关键作用，尤其在保证数据一致性和服务持续性方面的应用。作者解释了WAL用于节点间复制数据、容错和状态机复制技术，以保障数据不因服务器故障而丢失。同时，文章讨论了刷新操作的性能考量，日志数据的校验和纠错机制，以及利用幂等操作处理可能的重复记录。特别指出etcd项目如何运用WAL进行数据持久化，证实了WAL技术的实际效益和在集群同步中的作用，进而强调了复制日志在提高系统复原力和可靠性方面的价值。</p><p><a href="https://mp.weixin.qq.com/s/sCDRt8ziRk4PmFr9YyTyMA" target="_blank" rel="noopener noreferrer">《Go 创始人 Rob Pike:我们做对了什么?》</a>。文章由煎鱼撰写，回顾了Go语言创始人Rob Pike对Go的成功因素的思考。文章着重介绍了Go语言的设计理念，是为了提供一种更好的编写软件的方法，而不仅仅是一种新的编程语言。Rob Pike突出了Go的可爱吉祥物、强大的规范定义、出色的可移植性和兼容性、标准化的代码格式化工具Gofmt，以及强大的工具链等成功要素。文章还讨论了Go社区标准库的统一，以及多种编译器实现的可能性，这些因素共同促进了其现代编程环境的构建和业务发展。</p><p><a href="https://mp.weixin.qq.com/s/NKSKbIO2dV0-s5ix_DI2Ig" target="_blank" rel="noopener noreferrer">《最具研读价值的 Go 源码之一:context 包》</a>。这篇文章详细剖析了 Go 的 context 包源码，阐释了 Context 的回溯链和树形结构如何协同工作来实现级联取消操作。文章解读了 context 包如何在 Go 语言中为并发控制和超时控制等提供标准化做法，并展示了通过接口和几个关键结构体实现上下文管理。特别强调了 context 的四个主要方法：Deadline, Done, Err, Value 的实现以及使用场景，详细解说了使用 WithCancel, WithDeadline, WithTimeout, WithValue 方法创建和管理不同类型的 Context 对象，为理解并发请求管理提供了宝贵的视角。</p><p><a href="https://mp.weixin.qq.com/s/IckcTUDixrYocyM4liKP_w" target="_blank" rel="noopener noreferrer">《Go 负责人 rsc 翻车，决定追加 godebug 行》</a>。煎鱼撰写的文章讨论了 Go 核心团队负责人 Russ Cox 提出的新提案，即从 go.mod 中分离 GODEBUG 默认设置的变更。新提案应对了 Go 语言兼容性机制导致的一些问题，例如 GODEBUG 设置在依赖项更新时造成的冲突。提案引入了新的设置 <code>default=go1.X</code>，让基础设置和 <code>go 1.X</code> 行分离，从而允许在 go.mod 和 go.work 文件中设置模块级别的 GODEBUG。这变更确保了使用不同 Go 版本的同时可以保持不同版本的 GODEBUG 语义，提升了灵活性和兼容性。预计从 Go1.23 版本开始这一变更将正式生效。</p><p><a href="https://mp.weixin.qq.com/s/lg0uHTk0VjXC_RS5bMa8Hw" target="_blank" rel="noopener noreferrer">《抽象的艺术:Go 语言中的编程哲学》</a>。文章深入探讨了在 Go 语言编程中抽象的概念和实践。抽象被描述为不仅仅是隐藏细节的技术，更是提升代码质量和理解性的哲学。文章通过一个将比赛胜者计算器程序作为例子，展示了如何通过合理的函数组织提高代码的抽象层次。这使得逻辑更清晰、代码更易于理解，并且每个函数都有明确的目的。文章最终强调，良好的抽象是找到简洁与表现力之间的平衡，是编程艺术中的核心。</p><p><a href="https://mp.weixin.qq.com/s/D8vmIyQFhW8pC6okOSfjAA" target="_blank" rel="noopener noreferrer">《<!-- -->[<!-- -->]<!-- -->byte与string的两种转换方式和底层实现》</a>。小许在文章中深入探讨了 Go 语言中 <!-- -->[<!-- -->]<!-- -->byte 与 string 数据类型的转换方式及其底层实现机制。文章首先介绍了两种数据类型的基础知识，随后解析了两种常见的转换方式：一种是标准库方法，另一种是使用 unsafe 和 reflect 包的强转换方法。重点解释了强转换是如何通过指针操作避免内存分配来提升性能（零拷贝），并且指出这种方法虽然更高效，但需要小心处理可能的安全隐患。最后，提供了对 fasthttp 使用优化转换方式的分析，说明这种情况下的应用场景和益处。</p><p><a href="https://mp.weixin.qq.com/s/pTdymwNrhLCosw-ZCHcHeg" target="_blank" rel="noopener noreferrer">《图文讲透Golang标准库 net/http实现原理 -- 服务端》</a>。本篇文章详细介绍了Go语言标准库net/http在服务端的实现原理。通过代码示例和流程图解析，作者阐释如何在Go语言中启动HTTP服务并处理接收的请求。重点包括<code>http.HandleFunc</code>和<code>http.ListenAndServe</code>的使用，以及<code>Server</code>与<code>ServeMux</code>结构体的内部工作原理。文章详细解释了如何注册和匹配路由，以及如何通过Server的ServeHTTP方法处理客户端请求，达到理解Go语言http服务端核心处理流程和思路的目的。</p><p><a href="https://mp.weixin.qq.com/s/2k8hoOEny7rQJD5otz-H9A" target="_blank" rel="noopener noreferrer">《goroutine调度器揭秘 2》</a>。本文是对Go语言goroutine调度器的深入解析，内容继续之前文章的讨论，对Go的调度器在运行时的各个阶段进行了详细的剖析。作者参考了Go 1.21.1版本，讲解了schedule函数的工作机制，包括其如何永不返回地循环调用和所涉及的“栈切换”技术。文中还详述了调度器的核心函数findRunnable的实现逻辑，包括它是如何寻找可执行的goroutine的，以及多种场景下可能会调用schedule函数的过程。作者通过解释不同的调用函数和它们的使用场景，帮助读者理解Go调度器的工作原理。最后，文章承诺补充内容关于抢占式调度，并引导读者关注公众号以获取最新文章。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/JZE22Ndvo0tWC2P-MD0ROg" target="_blank" rel="noopener noreferrer">这些年背过的面试题——Netty篇</a></p><p><a href="https://mp.weixin.qq.com/s/v1P1vlqw-C2TxCpbNBDcmw" target="_blank" rel="noopener noreferrer">云原生最佳实践系列 4：基于 MSE 和 SAE 的微服务部署与压测</a></p><p><a href="https://mp.weixin.qq.com/s/VhpfORlmIlTMX5KFwXK0Dg" target="_blank" rel="noopener noreferrer">技术领导力之路 - 正反馈</a></p><p><a href="https://mp.weixin.qq.com/s/l4Y-L78DV_NokkggobWIdQ" target="_blank" rel="noopener noreferrer">深度 | 一条查询SQL的前世今生 —— ClickHouse 源码阅读</a></p><p><a href="https://mp.weixin.qq.com/s/XfTcUH02Ut-vPPWHiuprpA" target="_blank" rel="noopener noreferrer">看一遍就理解：IO模型详解</a></p><p><a href="https://mp.weixin.qq.com/s/O-auGP-1H3MO74kcTrC7Tw" target="_blank" rel="noopener noreferrer">工作多年，如何从 CRUD Boy 转型为分布式系统架构师？解锁分布式系统的艺术：从零开始理解分布式系统架构与设计原理！</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/2ejZrvHuvmoqf8_QMBqCTw" target="_blank" rel="noopener noreferrer">前端要学会自己写shell脚本，让你的项目看起来更优秀！</a></p><p><a href="https://mp.weixin.qq.com/s/SxZK5dKph-g-nbwAThOsZg" target="_blank" rel="noopener noreferrer">扩展你的前端知识库，毫无废话！【下】</a></p><p><a href="https://mp.weixin.qq.com/s/2bbbZ6jBWHmObHcL-lLNFQ" target="_blank" rel="noopener noreferrer">从流程上讲，如何用AI为前端开发提效</a></p><p><a href="https://mp.weixin.qq.com/s/i2MRvAicXCDZkHjO9gbgYQ" target="_blank" rel="noopener noreferrer">如何使用 Router 为你页面带来更快的加载速度</a></p><p><a href="https://juejin.cn/post/7320949203542409231" target="_blank" rel="noopener noreferrer">GPT自动投简历，一周斩获三offer，开源分享！</a></p><p><a href="https://mp.weixin.qq.com/s/DlvS7faM0H1a8NWzOBdWgw" target="_blank" rel="noopener noreferrer">一次给社区知名项目 Astro 的PR，如何点燃了我的开源之路</a></p><p><a href="https://mp.weixin.qq.com/s/y35QawST3An1olCgQy0z0g" target="_blank" rel="noopener noreferrer">MDH Weekly 124 - 《Code Like a Pro》</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/3月24日内容汇总">3月24日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-03-24T00:00:00.000Z" itemprop="datePublished">March 24, 2024</time> · <!-- -->46 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/image-cf4bb971d0691cfbaec4e4c72f360e95.png" width="900" height="520" class="img_astN"></p><p>封面图：Go 1.22 发布第一个安全补丁</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://docs.anthropic.com/claude/docs/prompt-engineering" target="_blank" rel="noopener noreferrer">《Prompt engineering》</a>。文章介绍了在使用Anthropic的Claude模型时，如何通过prompt engineering（提示设计）提升其性能。提示设计是一个经验科学，需要通过反复迭代和测试来优化提示的表现。文章建议定义清晰的任务和成功标准，并通过测试驱动的开发方法来优化提示。还包含了一些技术，比如清晰直白的指令、使用示例、赋予Claude特定角色、使用XML标记、分解复杂任务等，以提高输出质量和一致性。这些技巧帮助用户更好地利用Claude完成特定的用例。</p><p><a href="https://learning.snssdk.com/feoffline/toutiao_wallet_bundles/toutiao_learning_wap/online/article.html?item_id=7160681479788298504&amp;app_name=news_article" target="_blank" rel="noopener noreferrer">《Transformer前馈神经网络--Y=Wx+b公式却是人工智能领域的核心》</a>。这篇文章分析了Transformer模型中前馈神经网络的重要性，特别强调了其核心公式Y=Wx+b的重要作用。作者提到输入矩阵在经过multi-head attention机制和add&amp;norm操作后，由前馈神经网络经历两次线性变换和一次ReLU激活函数处理。这一过程确保无论输入数据如何变化，输出数据的维度都保持不变，从而保持数据的一致性并方便模型分析。</p><p><a href="https://v2ex.com/t/1000319" target="_blank" rel="noopener noreferrer">《Devv AI 是如何构建高效的 RAG 系统的》</a>。本篇文章探讨了Devv AI公司构建高效Retrieval Augmented Generation（RAG）系统的策略。RAG系统结合了语言模型、外部知识集合和特定场景所需知识，以提升搜索效能。作者提到，通过Go和Rust构建高并发架构、使用多种数据嵌入技术及优化召回机制来提高性能。文章指出，为了达到更高的效果，需要根据业务实际进行定制化优化，没有通用最佳实践，需要实际尝试和评估。</p><blockquote><p><a href="https://twitter.com/Tisoga/status/1731478506465636749?s=20" target="_blank" rel="noopener noreferrer">https://twitter.com/Tisoga/status/1731478506465636749?s=20</a></p></blockquote><p><a href="https://mp.weixin.qq.com/s/mt9W8Mf0LbZjbuRObyeWeQ" target="_blank" rel="noopener noreferrer">《OpenAI科学家Andrej Karpathy力荐，23年必读的大语言模型论文清单》</a>。文章由OpenAI的科学家Andrej Karpathy推荐，是对大语言模型(LLM)领域重要文章的整理。这份清单涵盖LLM的训练、运行、应用和未来发展方向，包括安全挑战。清单提及重要论文如《Attention Is All You Need》（提出了Transformer架构）、《Language Models are Unsupervised Multitask Learners》（关于GPT-2）、《Training Compute Optimal Language Models》等，并探讨了如何在现实世界中安全地集成并使用LLM。清单强调了追踪当前研究与保持思维前沿性的重要性。</p><p><a href="https://mp.weixin.qq.com/s/miNmrCt3brcPrrDXFe8rKA" target="_blank" rel="noopener noreferrer">《阿里出品!7B最强多模态文档理解大模型mPLUG-DocOwl 1.5》</a>。文章介绍了由阿里巴巴开发的mPLUG-DocOwl 1.5模型，这是一个7B参数级别的多模态大型语言模型（MLLM），专注于文档图片的结构化理解。模型通过统一的结构学习策略，在不同文档理解基准测试上取得了优异效果。文章提到了模型结构、训练策略、训练数据及其在多任务微调中的应用。mPLUG-DocOwl 1.5的性能在开源模型中处于领先地位，但与闭源模型相比在某些方面仍有差距。团队计划进一步优化并开源模型，促进社区的讨论与合作。</p><p><a href="https://mp.weixin.qq.com/s/mZbXfb99zOOjeL6DjrVfyA" target="_blank" rel="noopener noreferrer">《Good Data is All You Need，训练LLM数据是关键》</a>。本文探讨了在大型语言模型（LLM）训练中，数据的重要性、数据集的构成和数据质量。文章强调了高质量数据对模型性能的决定性影响，介绍了数据集应包含目标任务数据及相关迁移能力训练数据。文章详细讨论了在预训练、持续预训练和有监督微调阶段的数据混合策略，并指出避免“遗忘”问题的重要性。对于提升数据质量，建议提供丰富的任务信息和内逻辑，利于模型理解和泛化。最终，文章强调了结合数据多样性和解释性的必要性，以提升模型的学习效果和泛化能力。</p><p><a href="https://mp.weixin.qq.com/s/IdkFE-HuxGtDihlIc7BeDA" target="_blank" rel="noopener noreferrer">《融合RL与LLM思想，探寻世界模型以迈向AGI》</a>。本文深度分析了大型语言模型（LLM）与强化学习（RL）理论的结合，以及它们共同对人工通用智能（AGI）发展的影响。文章以AlphaGO、AlphaZero、AlphaDev这些模型为基础，讨论了深度学习和强化学习之间理论与实践的融合。重点探讨了Algorithm Distillation（AD）这一概念，这是将RL过程细粒度地嵌入到LLM中，使LLM能学习和压缩RL领域的深度洞察。此外，文章预测了AGI达到超人类智能（ASI）的潜在路径，并指出当前AI在LLM与RL层面上的缺失和未来发展的可能方向。</p><p><a href="https://mp.weixin.qq.com/s/zys9KvQWbbdRHkOyhzZqUw" target="_blank" rel="noopener noreferrer">《高性能 LLM 推理框架的设计与实现》</a>。文章从多个技术角度深入探讨了大型语言模型（LLM）的高性能推理框架设计。详细介绍了LLM推理的Prefill和Decoding两个阶段，以及测量推理性能的四个核心指标：吞吐量(Throughput)、首字延迟(First Token Latency)、延迟(Latency)和每秒请求数(QPS)。文章强调了Prefill阶段尽管计算量大但占比小，而Decoding阶段则数量庞大，是性能优化的关键。提出了多项优化策略，包括流水线前后处理、动态批处理和KV缓存量化等，有效提升系统的QPS和吞吐量。还讨论了包括FP8量化在内的多种硬件优化手段，旨在提供解决大模型高效推理的综合方案。</p><p><a href="https://mp.weixin.qq.com/s/-7Tz3g7cOV05rOyfA6XsvA" target="_blank" rel="noopener noreferrer">《超越 GPT-4V 和 Gemini Pro!HyperGAI 发布最新多模态大模型 HPT，已开源》</a>。HyperGAI团队推出的多模态大模型HPT，在多项基准测试中胜过GPT-4V和Gemini Pro。HPT包含HPT Air和HPT Pro两个版本，强调多模态理解并支持开源。HPT框架整合了视觉编码器和大语言模型，通过其创新组件H-former实现视觉与语言的紧密对齐。H-former处理视觉输入，生成可与语言模型联用的视觉嵌入。HPT在多模态数据集上的训练显示了其出色的理解、推理和创造力，尤其在MMMU及其它多模态测试中表现突出，同时展现了良好的泛化能力，这表明多模态大模型研究进展显著。</p><p><a href="https://mp.weixin.qq.com/s/77vlWgN6WkL3jL-6AJ0VAg" target="_blank" rel="noopener noreferrer">《大模型推理核心技术:Continuous Batching详解》</a>。文章深入探究了大模型推理中的Continuous Batching技术，从历史发展到现代架构进行了详尽的论述。阐释了在Transformer出现前后，Batching如何适应不同计算模型需求，特别是如何解决输入序列和批次大小变得可变的问题。分析了Continuous Batching的两种主要策略：ORCA框架的Iteration-level和Selective Batching，介绍了vLLM和FastGen等变种实现方法。通过对Continuous Batching在执行、资源管理、延迟均衡等方面的讨论，以及提及商汤LightLLM和TensorRT-LLM的应用案例，突出了该技术在推进AI服务效率的重要作用。</p><p><a href="https://mp.weixin.qq.com/s/vDPdgnKeYnLtHfN73ZJxRg" target="_blank" rel="noopener noreferrer">《第二篇:ChatGPT背后强大而神秘的力量:用最简单的语言讲解Transformer架构之Embedding》</a>。文章深入浅出地解释了Transformer架构中词嵌入（Embedding）的概念，包括其两种实现方法：稀疏表示法（如词袋模型和TF-IDF）和密集向量表示法（如Word2Vec和GloVe）。作者还介绍了如何使用欧氏距离、曼哈顿距离、点积和余弦距离计算词嵌入相似度的方法，并通过易懂的例子和代码实现。文章旨在让读者理解词嵌入对于语义理解的重要性，以及它在各种自然语言处理（NLP）任务中如何起到了核心的作用。</p><p><a href="https://mp.weixin.qq.com/s/_IrB7oWn-xckPi_QoAEu4g" target="_blank" rel="noopener noreferrer">《一文搞懂Transformer架构的三种注意力机制》</a>。本文是系列讲解Transformer架构的第四篇，重点讲解了核心组件注意力机制的三种形式。文章首先解释了注意力机制的概念，然后详细阐述了Transformer注意力层的工作原理，包括基础知识、理解Q、K、V矩阵，以及交叉、全局自注意力、因果注意力层的不同作用。此外，还介绍了位置编码，解释了其对位置信息的编码方式，以及如何通过正弦波函数来实现。文章最后描述了多头注意力机制，分析了其优势和如何通过将矩阵拆分为多个&quot;头&quot;来同时关注序列的不同特征。通过深入理解和比较这些注意力层与机制，文章帮助读者进一步认识Transformer模型的强大功能与效率。</p><p><a href="https://mp.weixin.qq.com/s/Jk-AK84sllBbkDDpvkv62w" target="_blank" rel="noopener noreferrer">《TensorRT-LLM初探(二)简析了结构，用的更明白》</a>。本文针对NVIDIA的TensorRT-LLM进行了深度解析，为使用者提供了一份快速入门指引。详细介绍了TensorRT-LLM的基本架构和组成，包含TensorRT库、FasterTransformer的设计以及其他组件，同时强调了大部分代码开源但包含一些闭源部分。还讨论了结合Triton Inference Server部署TensorRT-LLM的方式。文章解读了大模型推理过程中的动态batch（In-flight Batching）和Paged KV Cache技术，并提到了TensorRT-LLM对多卡支持的实现。最后，对于性能调优，还介绍了TensorRT-LLM独特的kernel性能优化以及量化策略。</p><p><a href="https://mp.weixin.qq.com/s/UFMxQB9sUC5I0y86nfzKjw" target="_blank" rel="noopener noreferrer">《谈谈我对 AIGC 趋势下软件工程重塑的理解》</a>。文章讨论了人工智能生成内容（AIGC）趋势对软件工程的影响，主要包括四个方面：AI作为软件开发不可或缺的部分、AI对软件研发的挑战和智能化机遇、企业实施软件研发智能化的策略与途径以及可落地的智能化软件研发工具。作者指出，在大模型时代，智能代码助手如Github Copilot显著提高了开发效率。AI的应用让开发者能专注于创新而非日常任务，而研发的智能化不仅改善了工作效率，还有助于处理软件本质的复杂性。文章还提到，利用AI工具如通义灵码可以增强个性化开发体验，并促进企业数字资产的增值。最终，作者建议采用分阶段方法实现软件研发智能化转型。</p><p><a href="https://mp.weixin.qq.com/s/eaKPOvww0mqjvtE2KS2YrA" target="_blank" rel="noopener noreferrer">《如何通过Vec2Text提升RAG的可解释性》</a>。这篇文章深入分析了Cornell University的研究团队发表的论文《Text Embeddings Reveal (Almost) As Much As Text》，介绍了一种名为Vec2Text的方法，它能从文本嵌入中恢复原始文本，有助于评估文本嵌入的隐私泄露风险。Vec2Text采用迭代修正的方式逐步重建文本，通过训练好的语言模型不断生成与目标嵌入更接近的文本。实验表明，Vec2Text在多个数据集和领域上能成功重建文本，显示出跨域文本恢复的有效性。同时，文章也探讨了Vec2Text的创新点、存在的不足，以及未来提高长文本恢复能力和减少嵌入模型查询次数的可能方向。</p><p><a href="https://mp.weixin.qq.com/s/eJMpoJCm0XcctRHrjfLhUQ" target="_blank" rel="noopener noreferrer">《Transformer扩散模型的先驱之作:DiT、PixArt、HDiT》</a>。文章综合介绍了三个重要的Transformer扩散模型结构：DiT、PixArt与HDiT，并对各自的特点和贡献进行了阐述。DiT以其可扩展性受到关注，通过遵循标准的Transformer架构进行设计，继承并改进了ViT的设计思想。PixArt由华为诺亚方舟实验室提出，是一个高效的文本到图像扩散模型，通过优化训练策略和数据集构造，显著降低了训练成本。HDiT则为Stability AI公司提出的沙漏形扩散Transformer，同样关注于图像生成。文章详细分析了这些模型的构造、优化和应用效果，展示了它们在图像生成领域的先进技术和潜力。</p><p><a href="https://mp.weixin.qq.com/s/F1FaJN1yUpDivuw0eoMcYA" target="_blank" rel="noopener noreferrer">《让 LLM 稳定输出 JSON》</a>。文章探讨了如何使大型语言模型（LLM）稳定输出 JSON 数据的方法，以及这些模型如何在高层次上工作。LLMs（如 ChatGPT 和 GPT-4）通常是自回归的，通过逐字预测来生成文本。文章介绍了原型系统 ReAct，这是一个通过Prompts来引导LLM产生特定格式输出的工具。通过训练，ReAct 可以解析工具名称和参数，以及调用工具和重复续写过程，直至获得最终答案。文章通过 COND_DATA_PROMPT 实践展示了如何生成用户问题的 JSON 结构，证明了在正确设定下，LLM 能可靠地输出所需的 JSON 格式，利用大模型的续写能力完成复杂的数据处理任务。</p><p><a href="https://mp.weixin.qq.com/s/vdr1WBCQVr9aS6bJYcdlRA" target="_blank" rel="noopener noreferrer">《没等来OpenAI，等来了Open-Sora全面开源》</a>。文章报道了Colossal-AI团队开源了一个类似OpenAI Sora视频生成模型的版本——Open-Sora 1.0，该模型包括完整的训练和数据处理过程。Open-Sora采用了Diffusion Transformer（DiT）架构，引入空间-时间注意力机制的STDiT模型。模型通过三个阶段：大规模图像预训练、大规模视频预训练和高质量视频数据微调，逐步提升生成质量。GitHub上提供的资源让AI爱好者可以轻松复现并生成视频内容，实现了在视频生成方面的成本节约与效率提升。团队承诺持续优化项目，实现更好的视频内容生成。</p><p><a href="https://mp.weixin.qq.com/s/mWQGmp7eCMRnDxcgqicKQw" target="_blank" rel="noopener noreferrer">《刚刚!马斯克开源 Grok:参数量近 Llama 四倍，成全球最大开源模型》</a>。本篇文章详述了马斯克通过其AI公司xAI开源了GroK-1，这是一个具有3140亿参数的混合专家系统模型，是迄今为止开源模型中最大的一个。它的参数量是Llama模型的四倍多，尽管如此，谷歌的switch transformer以1.6T参数保持公开记录。这次开源使用的是Apache-2.0许可，提供基本模型权重和网络架构，未针对特定应用进行微调。文章分析了开源背后的意图，其中包括与Meta保持一致、增加xAI在AIGC市场的吸引力，以及对于开源大型AI模</p><p><a href="https://mp.weixin.qq.com/s/xlSl1vDSBJnLBQto4_gltQ" target="_blank" rel="noopener noreferrer">《一文掌握大模型提示词技巧:从战略到战术》</a>。本文作者分享了在与大型语言模型合作时编写有效提示的战略和战术技巧。文章详述了如何制定清晰、具体和避免歧义的提示词原则、提供了详细示例，并讨论了用户输入完整性检查、结构化提示词及其优化等方面的技巧。作者强调了结构化的提示可以显著提高大模型的效能，使其输出更符合预期，还探讨了使用AI技术优化提示词的方法。</p><p><a href="https://mp.weixin.qq.com/s/LGCzkOvAfm68HpLmdJPu6g" target="_blank" rel="noopener noreferrer">《详解常见的几种LLM fine-tuning算法》</a>。本文详细解读了针对大型语言模型(Large Language Models, LLM)的几种微调(fine-tuning)算法，包括LoRA、QLoRA和AdaLoRA。文章讨论了各算法优化模型参数的方式，如LoRA通过低秩矩阵适应，QLoRA在此基础上增加量化优化和AdaLoRA通过奇异值分解的方式进行适配，以期在使用较少资源的情况下维持或提高模型性能。这些算法均旨在在保证效率和效果的同时，减少微调过程中的资源消耗。</p><p><a href="https://mp.weixin.qq.com/s/hvt5zwoazDx26KOaKuTs_w" target="_blank" rel="noopener noreferrer">《马斯克开源Grok-1:3140亿参数迄今最大，权重架构全开放，磁力下载》</a>。本文报道了马斯克旗下的大模型公司xAI宣布开源大模型Grok-1及其全部权重和架构，Grok-1为迄今参数量最大的开源语言模型，包括3140亿参数的混合专家模型。Grok-1从未进行过针对特定任务的微调，展现出在编程及推理任务上的优异能力。开源模型为研究人员与技术社区提供强大工具，助力创新，尽管也存在潜在的数据污染和资源需求挑战。文章还提及xAI公司的长期目标和研究方向，反映出对开放科学和技术发展的致力。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://juejin.cn/post/7298347391164743707" target="_blank" rel="noopener noreferrer">《Rust 中的 Clone-on-Write(Cow)类型:灵活的数据处理》</a>。这篇文章详细介绍了 Rust 语言中的 Clone-on-Write（即 Cow）类型，它是一种优化内存使用的策略，极大提高了数据处理的灵活性和效率。文章阐释了 Cow 类型的概念、优势和具体用法，举例展示了如何在读取大型数据结构或需要效率高的场合使用 Cow，特别是在读多写少的情况下以减少不必要的复制开销。文章还讨论了 Cow 类型在多线程编程中的应用，如何通过减少锁的使用来提高性能。作者提供了一系列的 Rust 代码示例，帮助读者理解和掌握 Cow 类型的正确使用方法，对于追求效率与内存安全的 Rust 开发者来说，是一份实用的参考资料。</p><p><a href="https://mp.weixin.qq.com/s/t6sJX1IeTNn1u-kSW5ju8A" target="_blank" rel="noopener noreferrer">《K8s 无备份，不运维!》</a>。本文详细介绍了Kubernetes集群的备份与恢复策略，强调备份作为投产前的必要步骤。文中介绍了两种备份方法：物理备份（etcd备份）和逻辑备份（velero备份）。物理备份执行简单，但只能整体恢复；逻辑备份提供内容选择性备份，允许细粒度控制。恢复流程中详细阐述了停止kube-apiserver，停止etcd，数据恢复，启动etcd及kube-apiserver的顺序步骤，保证了集群数据的稳定恢复。文章还提供了具体的备份恢复脚本和命令，并说明了它们在备份制定、执行和集群恢复中的应用。</p><p><a href="https://mp.weixin.qq.com/s/deInGh6vuhlVcmIXJyofpw" target="_blank" rel="noopener noreferrer">《Go singleflight:防缓存击穿利器》</a>。这篇由陈明勇撰写的文章讲解了如何使用Go语言的singleflight包来预防缓存击穿问题。文章阐述缓存击穿的定义，并介绍了mitigation策略，如使用永不过期的缓存键、互斥锁和提前更新策略。singleflight通过合并并发请求并共享单一结果来缓解这一问题，这样即使多个goroutine请求同一缓存键，数据获取的操作只会被执行一次。通过Group结构和Do方法，singleflight确保并发请求不会同时执行相同的数据获取，大幅降低数据库负载。文章还分享了使用例子和最佳实践，包括键设计和超时控制策略。</p><p><a href="https://mp.weixin.qq.com/s/PsGlXQWObV8b2WlTp47AMA" target="_blank" rel="noopener noreferrer">《Go 1.22 发布第一个安全补丁》</a>。本文作者杨文介绍了Go团队发布的最新补丁版本Go 1.22.1和Go 1.21.8，这对Go 1.22系列而言是首个安全补丁。该补丁解决了包括<code>html/template</code>, <code>net/http</code>, <code>net/http/cookiejar</code>, <code>net/mail</code>, <code>crypto/x509</code>在内的5个安全问题，例如修复了使用未知公钥算法时的panic错误，以及<code>net/http</code>包在处理HTTP重定向时错误转发敏感信息的问题。文中也引用了相关的GitHub issues链接，并强调了更新的紧急性和重要性。</p><p><a href="https://mp.weixin.qq.com/s/X27RCToY-jn-KNChL7OA5g" target="_blank" rel="noopener noreferrer">《运维人少，如何批量管理上百个微服务、上千条流水线?》</a>。文章讲述了在微服务和云原生技术背景下，如何通过云效应用交付平台AppStack高效地管理大量微服务和流水线。平台提供了应用模板功能，让使用相同技术栈的应用可以快速初始化。通过两种方式：一是直接使用或按需修改提供的示例模板；二是企业自定义模板配置。此外，通过应用模板修改实现应用配置的批量升级，简化了部署流程和权限管理，大幅提升了运维效率，实现了“解放双手”的管理方式。文章还描述了实现这一批量管理的具体操作步骤。</p><p><a href="https://mp.weixin.qq.com/s/vnU4-u4c1LawH2DWm0NBoA" target="_blank" rel="noopener noreferrer">《Go 团队近两年在做什么，AI 方面如何发力?》</a>。煎鱼在文章中分析了Go团队近两年的发展动态及其在AI领域的规划。Go团队在增加泛型、提高向后/前兼容性、增强软件供应链安全性、完善标准库、提升性能、改进Go IDE等方面取得了显著成果，同时，Go正计划对生成式AI进行深入研究。重点探索提高Go代码生成质量、对已有代码的现代化处理、以及在VSCode IDE中如何有效提示Go代码。文章强调了Go团队依据社区反馈和与业内大客户的联系来进行决策，并对未来AI协助工具的发展抱有积极的态度。</p><p><a href="https://mp.weixin.qq.com/s/mAUmnDxzwntwW4uA2i2q3g" target="_blank" rel="noopener noreferrer">《Goroutine调度器揭秘》</a>。文章深入解析了Go语言中Goroutine调度器的工作原理，详细介绍了Goroutine（G）、机器线程（M）和逻辑处理器（P）如何交互，形成了高效的M:N调度模型。描述了Goroutine的三种状态：等待、可运行、正在运行，并讲述了它们的生命周期管理。其中，调度器通过“工作窃取”机制使线程（M）在处理器（P）间动态分配Goroutine，从而实现了高效的并发执行。同时，Network Poller负责网络 I/O 的异步处理，避免了阻塞操作。文章强调了Go语言在简化并发程序设计上的优势，尤其是在Goroutine的轻量和调度策略方面。</p><p><a href="https://mp.weixin.qq.com/s/ND-2f3DKZ24iR0PAnY8uIA" target="_blank" rel="noopener noreferrer">《golang sync.Map之如何设计一个并发安全的读写分离结构?》</a>。文章解析了Go语言<code>sync.Map</code>的并发安全的读写分离设计结构。详述了<code>sync.Map</code>采用的读优先策略和&quot;懒惰&quot;同步机制，使用只读的<code>read map</code>和写入的<code>dirty map</code>通过原子操作和锁机制实现高效的读操作和写入的安全性。读操作优先从<code>read map</code>读取，降低锁的竞争；写操作更新<code>dirty map</code>，并根据读miss次数决定何时将<code>dirty</code>更新为<code>read</code>。<code>sync.Map</code>适用于读多写少场景，写多的场景下性能会下降，因为频繁同步和上锁操作会增加开销。</p><p><a href="https://mp.weixin.qq.com/s/zMgc9erIruK-CzooUtCg6g" target="_blank" rel="noopener noreferrer">《Kubernetes HPA 的三个误区与避坑指南》</a>。文章针对Kubernetes水平弹性扩容（HPA）存在的三个认知误区进行了深入分析，并提供了避免错误的指南。第一误区是HPA的扩容死区，第二是利用率计算方法误解，第三是弹性行为的滞后性。作者明确了HPA操作的工作原理、度量源、指标计算方法，和扩缩的行为策略，着重强调合理配置和理解HPA可以最大化其效率和效果。文章以用户在使用HPA时的常见问题为基础，提供实践中的有效“避坑”策略，有助于改善服务的弹性管理和资源利用。</p><p><a href="https://mp.weixin.qq.com/s/74glhCZ_GeiEvp_6hugbBw" target="_blank" rel="noopener noreferrer">《容器运行时-Containerd容器管理》</a>。本文详细讲解了Containerd容器管理的基础命令和操作过程，包括创建静态容器、查看容器、操作容器任务以及容器的启动和删除。特别指出，静态容器需要通过<code>ctr tasks</code>启动成为动态容器，以及如何查看容器进程和资源使用情况。文中还解释了使用<code>exec</code>进入容器进行操作的步骤，并展示了如何利用<code>ctr task</code>命令来管理容器的生命周期，如启动、暂停、恢复和删除容器进程，为Containerd容器运行时的用户提供了实用的管理指南和技巧。</p><p><a href="https://mp.weixin.qq.com/s/BWdhmZSmWGqSEZuRJSUjmQ" target="_blank" rel="noopener noreferrer">《更强大的Go执行跟踪能力》</a>。文章探讨了Go中<code>runtime/trace</code>包的功能强化，详细介绍了跟踪工具的最新进展。其中包括对执行跟踪开销的降低，现在大多数应用的CPU开销已减至1-2%，以及执行跟踪的扩展性提升。介绍了“飞行记录”技术，持续收集跟踪数据至关键事件发生，当发生错误时能够回溯。同时，分享了一个新的实验性跟踪读取器API，使得程序执行跟踪的分析更加容易和高效。这些进展旨在解决过去跟踪中遇到的问题，如高开销和可扩展性问题，提高Go程序的诊断能力。</p><p><a href="https://mp.weixin.qq.com/s/KhpoegAiclw3IyVf5CCUZw" target="_blank" rel="noopener noreferrer">《某些情况下，合理使用指针将大大提升程序的运行效率》</a>。本文由老貘撰写，探讨了通过合理使用指针来提升Go程序性能的策略。文章讨论了如何避免在循环中进行不必要的数组空指针检查，这是Go编译器v1.18的一个缺陷，通过代码示例展示如何将性能优化至最佳。进一步，文中还讨论了当数组指针是一个结构体字段时的特殊情况，提供了不同的方法和基准测试结果，指出了编译器优化的局限性，最后建议在可能的情况下使用切片来提高性能。文章深入浅出，为开发者提供了Go语言性能优化的有效技巧。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/Za6EMzkpUA-Z4qm3Qoh2Tw" target="_blank" rel="noopener noreferrer">《为什么不要在Spark中执行这个操作，详解DataFrame collect源码流程》</a>。本文作者Tim分析了Spark中DataFrame的<code>collect()</code>操作的弊端及其源码执行流程。文章指出，大量使用<code>collect()</code>可能导致程序慢速运行或挂掉，这与处理大数据量、内存不足、网络延迟、分区数过多和数据倾斜等问题有关。通过深入解析<code>collect()</code>的执行细节，从<code>withAction</code>函数到<code>DAGScheduler</code>的<code>runJob</code>方法再到<code>TaskScheduler</code>的任务调度，Tim详细阐述了该操作如何通过多个Spark组件协同工作完成作业的划分、调度和执行，进而指导开发者在合适的场景使用<code>collect()</code>操作以及可能的性能优化策略。</p><p><a href="https://mp.weixin.qq.com/s/3PPJI-m-m06nXgXfNwxzlA" target="_blank" rel="noopener noreferrer">《大厂Spark面试题，搞懂这些绝对稳稳的》</a>。文章由作者分享了一系列Spark面试题，并提供详细解答，帮助准备技术面试的人士深入理解Spark。内容涵盖了lineage理解、处理数据倾斜、Spark的DataFrame API、RDD的优缺点、不同缓存级别的使用时机、广播变量、内存管理、窄变换与宽变换的区别、数据序列化等核心概念，并深入讨论了如何解决大数据集处理、连接优化、数据倾斜问题、性能瓶颈诊断以及处理嵌套JSON数据等高级话题。对Spark RDD排序、内存管理、区别于Hive的Spark分区等高阶问题也进行了探讨，适合打算进入大厂或想要深化Spark知识的开发者阅读。</p><p><a href="https://mp.weixin.qq.com/s/uCt6Vwy8097rFBrCSxYmdQ" target="_blank" rel="noopener noreferrer">《腾讯文档收集表后台重构:改造一个巨石单体!》</a>。腾讯技术团队分享了他们对腾讯文档收集表服务进行后台重构的经验。原系统为C++风格的巨石单体服务，存在严重的业务逻辑耦合、接口分离不足、稳定性差和可观测性不足等问题。在重构过程中，团队通过业务模块化、架构松耦合设计、存储隔离、性能提升和增强可观测性等措施，提高了系统的稳定性和开发效率。通过使用现代化的技术栈和架构模式，成功缩小故障爆炸半径，提升了业务稳定性和服务质量，实现了在保持业务不断线的情况下进行系统升级。</p><p><a href="https://mp.weixin.qq.com/s/fg2Dy0Dbhcrn5QaNydp1WQ" target="_blank" rel="noopener noreferrer">《这些年背过的面试题——JVM篇》</a>。本文详细介绍了面试中经常问到的JVM相关问题和答案，涉及JVM内存划分、对象创建步骤、垃圾回收机制与算法、类加载过程和双亲委派机制等核心话题。文章深入探讨了JVM的内存区域、类加载机制、垃圾收集器类型与选择依据、以及JVM性能调优和新特性等内容。还提供了如何进行现场问题排查的实用建议，包括如何使用各种命令行工具查询JVM状态信息，至关重要的内存泄漏和性能瓶颈分析，以及解决故障的各个步骤。对于准备Java面试的求职者以及需要加深对JVM理解的Java开发者来说，本文是一篇宝贵的学习资源。</p><p><a href="https://mp.weixin.qq.com/s/bgLQQO2uNKbHxd9OSRvqpg" target="_blank" rel="noopener noreferrer">《Kafka Consumer 消费消息和 Rebalance 机制》</a>。本文深入探讨了Kafka消费者的消费机制与Rebalance机制。解释了消费组的概念，以及消费者如何进行消息的消费操作，包括订阅主题、拉取消息、提交位移等步骤。重点讲解了Consumer客户端的配置参数，例如bootstrap.servers、group.id、auto.offset.reset、max.poll.records等。文章也详细分析了Rebalance机制的触发条件和分区分配策略。最后提供了一系列基于Kafka消费者的高频面试问题，如命令行工具的使用、Kafka Producer的执行过程、消息的有序性保证、线程安全性等，为Kafka用户和求职者提供了宝贵的参考信息。</p><p><a href="https://mp.weixin.qq.com/s/MQAX7YyVbm96RB73FMfQ1Q" target="_blank" rel="noopener noreferrer">《40 张图搞懂分布式追踪》</a>。楼仔在本文中详述了分布式追踪系统的原理及应用实践，特别是在微服务架构中如何追踪请求调用路径与分析性能问题。文章介绍了OpenTracing标准规范、分布式追踪核心概念如Trace、Span、SpanContext，并绘制直观示意图说明整个分布式追踪机制如何运作。文中具体分析了SkyWalking框架的自动数据采集、context跨进程传递、traceId的全局唯一性保证和性能优化的关键技术与实现方式。通过实际案例，展示了如何整合SkyWalking到现有监控体系并进行个性化插件扩展，让读者深刻理解分布式追踪在微服务环境下的关键价值和技术细节。</p><p><a href="https://mp.weixin.qq.com/s/JTWdbs2anBSusGwdI7s5ag" target="_blank" rel="noopener noreferrer">《小红书离线数仓提效新思路，提升百倍回刷性能》</a>。本文由黄猿、马尔科和凌波三位作者共同撰写，介绍了小红书为提升离线数仓的效率与性能，转而采用StarRocks数据仓库引擎替代Spark的部分任务。通过引入StarRocks，小红书成功将任务资源消耗大幅降低，数据产出时间提前，回刷时间及成本分别减少了90%以上。文中详细讲解了数仓分层设计、数据回刷机制、资源优化策略以及StarRocks的核心技术，包含向量化查询加速、物化视图、Colocation Join等。此外，文章还展望了未来探索StarRocks在湖仓一体和存算分离场景的应用。</p><p><a href="https://mp.weixin.qq.com/s/pGWS0QHwPWf5Ry2hdPLaeA" target="_blank" rel="noopener noreferrer">《ElasticSearch常见用法，看这一篇就够了(文末送书)》</a>。本文为ElasticSearch的入门教程，详细介绍了其基本概念和常用操作，如索引的创建、查询、删除以及文档的增删改查。特别强调了ElasticSearch的分布式特性、全文搜索能力及Query DSL的高级查询功能。文中通过具体的RESTful API示例，使读者能够快速掌握每个操作。此外，还涵盖了高亮查询、分页、排序等高级功能，文章用清晰的结构为读者提供了ElasticSearch实用性和灵活性的全面了解，并在文末提供了一本关于ElasticSearch的进阶书籍赠送。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://juejin.cn/post/7344719913019277323" target="_blank" rel="noopener noreferrer">《在 2023 年屌爆了一整年的 shadcn/ui 用的 Headless UI 到底是何方神圣?》</a>。文章探讨了 shadcn/ui 这个在 2023 年大受欢迎的 React UI 组件库，及其基础——Headless UI 的概念和优点。Headless UI 是一种前端开发模式，将 UI 逻辑和样式分离，让开发者能够构建无样式但包含完整逻辑和功能的组件。文章讲解了 Headless UI 的起源、发展历程，以及为何在现代前端开发中变得如此重要。此外，作者分析了传统 UI 组件的限制和 Headless UI 的应用场景，强调了它的灵活性、定制性和轻量级特点，并提出在跨平台和定制化高的项目中，Headless UI 是非常适合的选择。</p><p><a href="https://juejin.cn/post/7331996679548485667" target="_blank" rel="noopener noreferrer">《年底了，聊聊在字节做了一学期工程化的心路历程》</a>。该文章由一位在字节跳动实习并从事工程化工作的作者分享了他的实习经历和心得。文章讲述了作者如何从一名对工程化知之甚少的实习生，在mentor的引导下，通过实际项目实践，逐渐积累经验并在工程化领域取得了质的飞跃。具体的工作内容包括实现monorepo项目支持路径别名源码引用、主项目构建工具的升级、lint工具的升级以及新增CI卡点等。整个实习过程中，作者不仅学习到了如何实际应用工程化知识，还体会到了工作中的成就感与挑战，并鼓励其他开发者通过实践来提升自己的工程化能力。</p><p><a href="https://mp.weixin.qq.com/s/-KLst5tr-jfo0lHdm7mH4g" target="_blank" rel="noopener noreferrer">《托文档搜索的福，我终于在实战中用上了AI!》</a>。广州小井在文章中分享了他使用人工智能文本向量化技术来解决文档搜索中的“语义模糊”问题。文中详细讲述了ElasticSearch在处理关键词搜索时的局限性，并介绍了向量化搜索的原理和应用。作者首先阐述了向量化能够有效地处理自然语言的非结构化数据，然后通过Milvus向量数据库实现搜索功能，以便在类似情况下有效检索出内容相关的文档。此外，文章还讨论了如何通过NLP模型将文本转化为向量，并将这些向量嵌入数据库中，以改善搜索的精确度。</p><p><a href="https://mp.weixin.qq.com/s/9Qp_tcHyn_rneFM_ES3LZw" target="_blank" rel="noopener noreferrer">《云音乐会员支付链路优化实践》</a>。云音乐团队展开了对会员支付链路的多方位优化实践，以应对营收业务增长带来的稳定性和支付效率挑战。优化包括对收银台性能的提升，采用RN离线包、拆包以及Hermes引擎优化页面加载速度，以及在IAP支付流程中预取数据和集成StoreKit 2 来降低错误率并提升支付成功率。此外，也通过支付SDK升级、动态导入等技术手段，改进RN应用加载时的性能。优化结果显示在技术指标和业务指标上有明显提升，提高了用户购买体验和订单转化率。</p><p><a href="https://mp.weixin.qq.com/s/N4CdVvl8O672bUOqEU3nag" target="_blank" rel="noopener noreferrer">《Vue3中我是这样玩Echart的》</a>。本文介绍了作者在Vue3和TypeScript环境下，如何使用ECharts库进行数据可视化图表的开发。作者详细描述了基础的ECharts图表设置与渲染流程，并介绍了如何通过自定义Hook <code>useEcharts</code> 来优化图表实例的处理。同时，文章还探讨了如何实现一键换肤功能，包括色彩主题的动态切换和自定义色彩选择，以及如何基于 <code>tvision-color</code> 库生成配色方案。这篇文章对于前端开发者在实现复杂的图表展示与交互功能时提供了实用的指南和技术参考。</p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/3月17日内容汇总">3月17日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-03-17T00:00:00.000Z" itemprop="datePublished">March 17, 2024</time> · <!-- -->52 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/maxresdefault-ffb8f11e1c31c2d1464780924ffb5d89.jpg" width="1280" height="720" class="img_astN"></p><p>封面图：Safe by construction - Roberto Clapis</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/2VTiWmu1zoWF3sfSLvuJ-w" target="_blank" rel="noopener noreferrer">《首个AI软件工程师Devin完整技术报告出炉，还有人用GPT做出了「复刻版」》</a>。该文章介绍了机器之心报道的 Cognition AI 团队发布的首个 AI 软件工程师 Devin。Devin 在不需要人类辅助的情况下，在 SWE-bench 基础测试中解决了 13.86% 的问题，远高于目前 SOTA 模型的解决率。SWE-bench 是一个复杂的软件工程系统自动化基准测试，用以测试系统解决现实世界代码库中问题的能力。文章还展示了 Devin 在多步规划和定性案例分析中的表现，并说明了其运行方式和评估标准。同时，报告了社区已经产生了复刻版的 Devin，展示了 AI 在软件工程领域的先进能力和潜在的行业变革。</p><p><a href="https://juejin.cn/post/7345690943076089856" target="_blank" rel="noopener noreferrer">《大模型基础应用框架(ReACT\SFT\RAG)技术创新及零售业务落地应用》</a>。本篇文章由九数算法中台分享，探讨了在零售行业中融入大模型技术应用框架——ReACT、SFT（指令微调）、RAG（检索增强生成）的创新与实际应用。文章提出了这些大模型技术在解决特定领域知识不足、减少内容幻觉、确保数据安全等方面的挑战，并详述了如何通过有监督微调来提升大模型在零售领域的专业知识水平。同时，介绍了京东在多个业务试点应用自研的SFT框架和RAG技术，突显了大模型在零售业务中从理论到实践的转换，以及在多种复杂使用场景中的潜在价值。</p><p><a href="https://mp.weixin.qq.com/s/QBORpQmZrumppLl81aWAxA" target="_blank" rel="noopener noreferrer">《南洋理工发布多模态金融交易Agent，平均利润提高36%！》</a>。本文介绍了南洋理工大学发布的多模态金融交易Agent，通过融合大语言模型（LLMs）和多模态数据处理，提高了金融交易的效益。传统基于规则的交易系统在适应市场波动方面存在不足，而基于强化学习的系统虽然适应性更好，但在处理多模态数据和可解释性方面仍面临挑战。该文中提出的FinAgent是一种先进的多模态基础代理，能够综合分析多种形式的金融数据，提供精确的市场趋势分析和决策支持。实验证明，使用FinAgent进行金融交易可以平均提高36%的利润。论文链接：<a href="https://arxiv.org/pdf/2402.18485.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2402.18485.pdf</a></p><p><a href="https://mp.weixin.qq.com/s/kek5xGP96UOJ3Rpfw3V-FQ" target="_blank" rel="noopener noreferrer">《大模型推理:A100/H100 太贵，何不用 4090?》</a>。本文介绍了大模型推理时，为什么可以考虑使用4090显卡。相比于A100和H100显卡，4090在性价比上更高，尤其在极致优化的情况下，甚至可以达到H100的2倍性能。文章指出，A100、H100和4090在算力方面的差距并不大，最大的区别在通信和内存方面。由于大模型训练使用高性能的通信，4090通信效率相对较低，因此在大模型训练中并不适用。然而，在推理（inference/serving）方面，4090在性价比上有优势，尤其是相对于H100显卡而言。文章还提到了GPU的训练性能和成本对比，以及大模型训练所需的算力和GPU数量等问题。详细内容可参考文章链接。</p><p><a href="https://mp.weixin.qq.com/s/tKVHsoR_opgBqtCMDHbv6Q" target="_blank" rel="noopener noreferrer">《精度提升!南加大等 | 提出分治Prompt策略，提升LLM分辨力》</a>。本文介绍了一种基于分治算法的Prompt策略，旨在提高大语言模型（LLM）的分辨力。现有的提示策略在处理涉及重复子任务和含有欺骗性内容的任务时存在一定限制。为了解决这个问题，研究人员提出了一种基于分治算法的提示策略，利用分治程序来引导LLM的求解过程。该策略将任务划分为子问题并分别求解，然后合并子问题的答案。通过实验证明，这种分治策略能够提升模型在大整数乘法、幻觉检测和新闻验证等任务中的性能，相比传统提示策略具有更好的准确率和性能指标。论文地址：<a href="https://arxiv.org/pdf/2402.05359.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2402.05359.pdf</a></p><p><a href="https://mp.weixin.qq.com/s/sxgfJf4vxvaxhO5L7-Npwg" target="_blank" rel="noopener noreferrer">《开源版“Devin”AI程序员炸场:自己分析股票、做报表、建模型》</a>。这篇文章介绍了一个基于MetaGPT的开源项目Data Interpreter，该项目旨在处理数据实时变化、任务之间的复杂依赖关系、流程优化需求以及执行结果反馈的逻辑一致性等挑战。通过演示，展示了Data Interpreter在分析股票、预测葡萄酒质量、自动抠图、预测疾病进展和预测机器运行状态等方面的能力。该项目由MetaGPT团队与多所高校合作推出，提供了一种自主进行数据分析和建模的开源工具。</p><p><a href="https://mp.weixin.qq.com/s/n98IZHs7LTXMzzS3KmHvrA" target="_blank" rel="noopener noreferrer">《【原创】一文读懂RAG的来源、发展和前沿》</a>。本文介绍了检索增强生成（RAG）技术，该技术结合了检索和生成过程，旨在提高机器生成文本的相关性、准确性和多样性。文章详细解释了幻觉问题的存在以及解决幻觉问题的几种常见方法。RAG利用外部数据源进行信息检索，将检索到的信息作为上下文输入到生成模型中，从而帮助生成正确的响应。讨论了RAG的核心部件，如向量数据库、查询检索和重新排序。同时介绍了RAG在知识图谱和树结构方面的拓展。</p><p><a href="https://mp.weixin.qq.com/s/NoREsyLXNVk1aABtSkhBDA" target="_blank" rel="noopener noreferrer">《万字长文解析:大模型需要怎样的硬件算力》</a>。这篇文章探讨了大模型在算力、存储、通信等多个方面上硬件资源的挑战和瓶颈。文章分析了以Transformer结构为核心的大模型在算力瓶颈、显存瓶颈和通信瓶颈方面的困境，以及当前所采取的硬件资源优化技术。此外，文章还提供了对大模型参数量和算力需求的量化估算，为选择合适的硬件设备和评估资源需求提供了指导。</p><p><a href="https://mp.weixin.qq.com/s/lbLOqiW-DoHq_S9qpYcbCQ" target="_blank" rel="noopener noreferrer">《什么是好的大模型训练数据?》</a>。本文基于Lilian Weng的博客，讨论了大模型如LLM在训练过程中对高质量数据的需求。认为高质量数据来源于“高质量人类”产生的标注数据，并强调了数据处理的重要性，提到了数据标注、质量控制和错误修正的重要步骤。文章还讨论了用于评估数据质量的多种方法，如Influence Functions和Noisy Cross-Validation，并提出了专注于“搭建高质量的数据标注pipeline”的企业方向。最后指出，在AI时代大量产出的数据中维护数据质量，是一个值得关注的挑战。</p><p><a href="https://mp.weixin.qq.com/s/dA757HASxJPYuAbRZ7KvUQ" target="_blank" rel="noopener noreferrer">《读过的最白话讲清楚RAG原理的文章》</a>。这篇文章直观地阐释了检索增强生成（RAG）的概念和工作原理，它是一种结合检索和生成的问答系统。该系统首先通过检索步骤找到与用户问题最相关的知识库内容，然后将这些内容与问题共同输入大型语言模型（例如ChatGPT）以生成答案。文章详细介绍了如何利用嵌入模型对知识库文本进行索引，以便协助语言模型进行精确的检索。此外，它还探讨了语义搜索背后的核心原则和技术细节点，如何通过嵌入找到与用户输入最匹配的知识，以及如何格式化文档以供语言模型使用，以便获得更高效的回答。</p><p><a href="https://zhuanlan.zhihu.com/p/685794495" target="_blank" rel="noopener noreferrer">《LLM推理算法简述》</a>。本文介绍了用于提高大型语言模型(LLM)推理性能的关键技术与策略。内容涵盖显存优化方法，如KV Cache减少显存浪费、MQA和GQA减少KV-Cache数量、Page Attention进行显存管理，以及提高推理速度的FlashAttention改进。文章还探讨了算子融合技术，比如FasterTransformer和DeepSpeed Inference的应用，以及调度优化策略如Async Serving和Dynamic Batch，最后介绍了用于处理大模型的分布式并行技术。这些优化手段能显著提高LLM推理过程中的性能与效率。</p><p><a href="https://mp.weixin.qq.com/s/V8Tz5X81FlOva9B6bCprqg" target="_blank" rel="noopener noreferrer">《数学推理增强!微软 | 提出数据合成框架:KPDDS，微调Mistral-7B性能超34B模型!》</a>。微软的研究团队为提升大型语言模型(Large Language Models, LLMs)在数学推理任务的性能，提出了关键点驱动的数据合成(KPDDS)框架。KPDDS利用真实数据源中的关键点和示例对生成高质量问答对来训练语言模型。研究者基于此框架创建了KPMath数据集，进一步结合推理密集型数据形成KPMath-Plus数据集。在MATH测试集上，微调后的Mistral-7B模型达到了39.3%的零样本通过率，超越了数量更多的34B模型，证明了KPDDS的有效性与创新性。这一成果标志着LLMs在数学推理方面的性能得到显著提升。</p><p><a href="https://mp.weixin.qq.com/s/QkkYAilf4_XZyBRqSIEL2Q" target="_blank" rel="noopener noreferrer">《首个AI软件工程师上线!已通过公司面试抢程序员饭碗，华人创始团队手握10块IOI金牌》</a>。在这篇文章中介绍了由华人创立的Cognition AI公司开发出来的首个人工智能软件工程师Devin。与现有GPT-4等模型不同，Devin能够独立完成复杂的编程任务，并已成功通过人工智能公司的面试和在自由职业平台Upwork上接单。得益于Cognition AI在长期推理和规划方面的进步，Devin在做决策和执行任务时，能回想相关上下文、随时间学习并修复错误。这标志着人工智能在理解真实世界软件工程问题方面取得了突破，为AI领域迈向更高层级的自动化及监督性工作开辟道路。</p><p><a href="https://mp.weixin.qq.com/s/q_lgeiXFzTU4WEt9wpUG3w" target="_blank" rel="noopener noreferrer">《向数字世界AGI迈进!智能体已经从头开玩「荒野大镖客 2」了》</a>。这篇文章展示了如何使用Cradle这一通用计算机控制智能体框架进行AI的研究与应用，在无需内部API支持下控制键盘和鼠标以及与各类软件交互。文章来源于北京智源人工智能研究院、新加坡南洋理工大学和北京大学的联合研究。Cradle由六大模块组成，包括信息收集、自我反思、任务推断、技能管理、行动计划和记忆模块。这些模块让智能体能够自主进行决策和任务执行。研究团队通过将Cradle部署于《荒野大镖客 2》这一复杂的3A游戏中证明其通用性，Cradle能够自主完成游戏主线和探索开放世界。智能体的这种通用能力标志着智能体研究向通用人工智能（AGI）迈进的重要一步。</p><p><a href="https://mp.weixin.qq.com/s/U2472bnEvCE9lMPP-z0ysw" target="_blank" rel="noopener noreferrer">《深入浅出 LangChain 与智能 Agent:构建下一代 AI 助手》</a>。文章深入讲解了LangChain工具箱及其如何赋能智能Agent，以构建更加智能的AI助手。LangChain利用大型语言模型如GPT-4，提供了一个开源软件框架，可助力开发者搭建基于语言模型的应用。它提供了六大类组件，如模型、提示模板、索引、文档加载器、文本分割器和向量存储，让GPT-4等模型不仅能处理语言，还能与外部API互动、管理用户上下文。文章以构建人脸技术问题排查助手为例，展示如何运用LangChain来协助问题诊断与智能交互，朝向自主、高效的智能应用发展。</p><p><a href="https://mp.weixin.qq.com/s/AAkITPRodLzvl61oALEI2Q" target="_blank" rel="noopener noreferrer">《使用零一万物 200K 模型和 Dify 快速搭建模型应用》</a>。本文详细介绍了如何使用零一万物的200K模型和Dify（LLM IDE）快速构建模型应用程序。作者首先对一个机器学习电子书进行翻译，并分享了源代码，然后引导读者如何申请和配置零一万物模型API。随后，作者说明了如何使用Dify IDE快速搭建和调试模型应用程序，以及如何使用Golang和AI模型自动化电子书的翻译过程。最后，作者总结了自动翻译程序的构建过程并展示了批量翻译内容的方法。整篇文章不仅是使用Dify的实操指南，还提供了一种效率化、自动化处理文本内容的示例，适合那些在寻找快速开发和集成大语言模型到应用中的开发者参考。</p><p><a href="https://mp.weixin.qq.com/s/-9H0mLnvebzaLMaI6EKB6g" target="_blank" rel="noopener noreferrer">《一文看完多模态:从视觉表征到多模态大模型》</a>。本文为读者系统梳理了图文多模态与多模态大模型领域的发展，尤其聚焦在视觉表征和视觉与文本融合方法上。文章从卷积神经网络（CNN）及其预训练方法开始讲起，从图像处理的视角介绍了多模态融合的初期方法，如LXMERT、VL-BERT和UNITER等。进一步，文章论述了Vision Transformer（ViT）及其预训练方案如MAE和BEIT，以及基于ViT的多模态对齐与预训练技术，如CLIP和VILT等。作者通过丰富的示例和对比，使读者能够理解这些模型在结构和功能上的不同与联系，为进一步研究提供了宝贵的资源和视角。</p><p><a href="https://mp.weixin.qq.com/s/k7b55PKdLA622G6Qb5Q0hA" target="_blank" rel="noopener noreferrer">《浙大&amp;中科院让Agent学会自我进化，玩德州扑克心机尽显》</a>。Wenqi Zhang等研究者介绍了名为Agent-Pro的AI智能体，它使用大模型(GPT-4)为基础，配合自我优化的策略，能够运用虚张声势、主动放弃等复杂策略玩转德州扑克和21点等非完美信息博弈游戏。Agent-Pro的设计使其能够自我进化，适应复杂和动态的游戏环境，并通过策略层面的反思和世界模型的优化来提高自己的表现。该研究展示了AI在博弈领域的进步，同时为解决多agent现实世界问题提供了新策略。</p><p><a href="https://mp.weixin.qq.com/s/ZG3CuhZisI26taz4FQrdPg" target="_blank" rel="noopener noreferrer">《面向工业级推荐!“小”LLM也能做好推荐系统》</a>。本文由蚂蚁集团AI创新研发部门NextEvo撰写，介绍了他们的论文《Can Small Language Models be Good Reasoners for Sequential Recommendation?》获得WWW 2024 (Oral)录用。文章针对大语言模型（LLM）在推荐系统应用时代价高昂的问题，提出了一种名为SLIM的基于蒸馏的大模型推荐框架。SLIM通过知识蒸馏技术，将大模型的知识和推理能力迁移到较小的模型上，从而达到用更少参数实现高效推荐的效果。论文强调SLIM在处理长尾物品和新用户推荐的优势，改进了传统基于交互数据的推荐系统偏差问题，并在保持推荐准确度和可解释性的同时降低资源消耗。</p><p><a href="https://mp.weixin.qq.com/s/P7gOETO-EG3Ha7WjGs6Szg" target="_blank" rel="noopener noreferrer">《AIOps 智能运维:有没有比专家经验更优雅的错/慢调用分析工具?》</a>。本文介绍了阿里云应用实时监控服务 ARMS 最新推出的错/慢 Trace 分析功能。此功能不依赖专家经验，能对比分析错/慢 Trace 和正常 Trace 的每个维度，从而快速定位问题根源。针对生产环境下调用时延和错误调用的多种因素（如流量不均、单机故障等），ARMS 通过对错/慢 Trace 和正常 Trace 的对比，帮助用户发现异常的共同特征，从而定位到具体问题。这个工具提供了一种优于传统专家经验的快速、有效诊断系统问题的方法，并且附有最佳实践案例。文章最后提供了免登录的 demo 体验链接，引导用户了解和使用该功能。</p><p><a href="https://mp.weixin.qq.com/s/9RaOOrroywQKnOhanBApsA" target="_blank" rel="noopener noreferrer">《CUDA编程优化方法——Memory coalescing》</a>。这篇文章对CUDA编程中的内存合并技术—— Memory coalescing进行了详细介绍。文章首先解释了全局内存的特点以及为何访问速度慢，并阐述了Memory coalescing的目的是通过合并内存访问操作来有效地利用带宽。通过对多维数组的存储方式及访问模式的解析，文章进一步讲解了Memory coalescing的具体实现细节，如何在多维数组访问和矩阵乘法中实现内存访问的合并。最后，文章提供了优化策略，以改进计算的内存访问模式，并提高CUDA内存传输的效率。</p><p><a href="https://mp.weixin.qq.com/s/b6D-vipDxKtlyocbxTObVQ" target="_blank" rel="noopener noreferrer">《扩散模型如何构建新一代决策智能体?超越自回归，同时生成长序列规划轨迹》</a>。本篇文章介绍了扩散模型在强化学习中的多种应用场景，探讨了如何超越传统的自回归方法，同时生成长序列规划轨迹来模仿人类的决策过程。上海交通大学的团队所作的综述梳理了扩散模型在强化学习中的运用如轨迹规划、策略表征、数据合成，及其解决长序列规划误差累积、策略表达能力受限和数据稀缺等问题的巨大潜力。最终，文章对扩散模型未来的发展方向进行了展望，提出了生成式仿真环境、加入安全约束、检索增强生成及组合多种技能等多个研究方向。</p><p><a href="https://mp.weixin.qq.com/s/GII5CwvB4FuxkT7yzyf_4Q" target="_blank" rel="noopener noreferrer">《动手做一个最小RAG——TinyRAG》</a>。本文由不要葱姜蒜指导读者如何一步步实现基于检索增强生成技术（RAG）的简化模型——TinyRAG。TinyRAG仅包含RAG核心功能，即Retrieval（检索）和Generation（生成）两个模块。文章详细介绍了RAG的基本结构，包括向量化模块、文档加载与切分模块、数据库和检索模块，以及如何根据检索内容生成回答。此外，还提供了对应的开源项目<a href="https://github.com/KMnO4-zx/TinyRAG" target="_blank" rel="noopener noreferrer">代码</a>，助力理解语言模型与RAG的原理，并能够在实践中加以应用和拓展。</p><p><a href="https://mp.weixin.qq.com/s/1jTw_5_re4GWWLqgKnkSww" target="_blank" rel="noopener noreferrer">《聊一聊Transformer中的FFN》</a>。这篇文章探讨了为什么Transformer的前馈神经网络（FFN）部分长期以来几乎没有大的改动。文章通过比较不同的激活函数，如ReLU、GeLU和Swish等，分析它们在Transformer中的应用效果和局限性。同时探讨了线性投影的必要性、参数量及其对模型容量和记忆力的影响。此外，文章还涉及了混合专家模型（Mixture-of-Experts，MoE）以提升Transformer的效率，并讨论了构建通用人工智能（AGI）所需要的结构特性，特别是放缩定律（Scaling Law）、上下文学习（In-Context Learning）、效率提升（Better Efficiency）和终生学习（Life-long learning）的重要性，最后对未来结构创新给出透彻见解。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://go.dev/blog/execution-traces-2024" target="_blank" rel="noopener noreferrer">《More powerful Go execution traces》</a>。Go的runtime/trace包提供了用于理解和排查Go程序的强大工具，允许对goroutine的执行进行跟踪。新版本Go大幅度降低了执行跟踪的运行时开销，从多数应用中的10-20% CPU下降到1-2%。文章介绍了如何通过将trace分割，从而使得trace可以扩展且保持低开销，还实现了飞行记录功能，使得即使在事件发生后也能从trace中获取信息。Go也提供了一个实验性的trace读取API，使程序性的跟踪分析成为可能。</p><p><a href="https://mp.weixin.qq.com/s/TQpK1NiCkLJHecy-nPBAtA" target="_blank" rel="noopener noreferrer">《Go 和 Google、Cloud 融合的那么深，绝非偶然》</a>。文章作者煎鱼分析了 Go 语言与 Google 和 Cloud 融合深度的背后原因。从 2010 年 Go 在 Google 起步，到 2013 年 Google SRE 团队采用 Go 替换 Python，以及 Go 与 Kubernetes、Docker、Etcd 等云原生技术的结合，文章追溯了 Go 成功的关键节点。2016 年至 2017 年，Go 在 Google 内部增长放缓后，团队提出将 Go 应用拓展至 Cloud 领域，并最终获得了管理层的支持。加入 Cloud 部门后，Go 成为了 Cloud 的一部分，得到了更多的发展机会。文章强调，Go 与 Google 的核心开发者亲自推广及高密度的人才对 Go 发展起到了关键作用。预计未来 Go 将在云原生生态中继续崭露头角。</p><p><a href="https://mp.weixin.qq.com/s/vFe8ggFqYcm_GQ9gcmrcxw" target="_blank" rel="noopener noreferrer">《Uber 出了个代码静态分析工具 NilAway，还挺实用!》</a>。文章介绍了 Uber 开发的新静态分析工具 NilAway，它专门用于在 Go 程序编译时捕获可能导致 nil panic 的问题，以减少生产中的潜在错误。NilAway 的特点包括完全自动化、快速性能和实用性，并且在大型代码库上也表现良好。通过具体代码例子，文章展示了 NilAway 如何识别出可能导致 nil panic 的代码，并提供了安装方式和使用方法。该工具基于 go/analysis 标准开发，未来有望与 golangci-lint 等工具集成，值得关注其更新和开发进展。</p><p><a href="https://juejin.cn/post/7346394191264710666" target="_blank" rel="noopener noreferrer">《Rust: 实现比特币的交易模型》</a>。本文详细介绍了比特币的交易模型中的UTXO（未花费交易输出）模型，并使用 Rust 语言来实现和展示其运作过程。UTXO 模型与传统的账户余额模型不同，将用户的余额分散存储在多个UTXO中。每个UTXO代表比特币网络上一笔可用于未来交易的输出。文章解释了UTXO模型的工作原理、优势以及交易处理流程，包括选择输入、生成输出、签名交易和广播交易。接着，文章提供了一个 Rust 实现的简化示例，展示了如何定义交易结构体、输入、输出以及UTXO集合，并介绍了基本的操作方法。如果你对比特币交易模型和 Rust 编程感兴趣，可以阅读该文章了解更多细节。</p><p><a href="https://juejin.cn/post/7309692103055507491" target="_blank" rel="noopener noreferrer">《深入理解 Go Modules: 高效管理你的 Golang 项目依赖》</a>。本文详细介绍了 Go Modules 在 Golang 项目中的使用方法和原理。文章首先回顾了 Go 依赖管理的历史，从 GOPATH、Go Vendor 到 Go Module 的演进过程。然后讲解了模块、包和版本的概念，包括模块路径、包路径以及版本的格式和语义。接着，文章介绍了 Go Modules 的环境配置，包括 go env 环境变量和依赖管理文件（go.mod 和 go.sum）的作用和使用方法。最后，文章提供了一些实用技巧和常见问题的解答，帮助读者更好地理解和应用 Go Modules。如果你对 Golang 项目的依赖管理感兴趣，可以阅读该文章了解更多详情。</p><p><a href="https://mp.weixin.qq.com/s/GxTtiqMpcrDWK9toaK5CMw" target="_blank" rel="noopener noreferrer">《Kubernetes集群节点处于Not Ready问题排查》</a>。当Kubernetes集群中的节点显示为&quot;Not Ready&quot;状态时，这篇文章提供了一系列的排查步骤。首先，通过运行特定的kubectl命令来确认节点的状态并获取节点详细信息，检查可能的错误消息或者警告。接着，进入节点系统查看各种系统日志，并使用相关命令如grep、cat或tail来辅助分析。文章还建议检查kubelet服务状态和配置文件，确认系统资源是否充足，试图解决可能存在的磁盘空间和网络问题。最后，通过使用诸如ping、traceroute等诊断工具确保节点能够与主节点通信，并检查重要的网络端口是否开放。确保Kubelet能正确连接到Kubernetes API，并使用Kubernetes的诊断工具如kubectl get componentstatus检查组件状态。通过这些步骤，可以系统地排查并解决&quot;Not Ready&quot;的问题，保持集群健康。</p><p><a href="https://mp.weixin.qq.com/s/iuzDw7_w20jtjJUlynv9NA" target="_blank" rel="noopener noreferrer">《Go 错误处理: 用 select-case 来解决这个历史难题?》</a>。煎鱼在这篇文章中介绍了一个新的Go语言错误处理提案，这个提案尝试用<code>select-case</code>结构作为错误检查的替代。这个新语法允许在<code>select</code>关键字之后声明一个变量为“陷阱”，赋值给该变量时触发<code>case</code>检查，以减少传统的<code>if err != nil</code>检查的繁琐性。新提案保持了Go1代码的兼容性，尝试提供一个更简洁、向后兼容的错误处理方式，尽管目前社区内对此仍未达成共识。</p><p><a href="https://mp.weixin.qq.com/s/Dc5wOBAE_jSiTKqPc6M4Dg" target="_blank" rel="noopener noreferrer">《K8s蓝绿部署:优雅应对应用程序更新挑战》</a>。本文详细探讨了使用Kubernetes（K8s）进行蓝绿部署的方法，以达到无缝更新应用程序并最小化宕机时间。蓝绿部署是一个运行两个相同生产环境的模式，能够在更新时切换流量，确认无误后便去除旧环境。文章指导了从创建命名空间、创建和应用部署、服务及其路由规则、执行蓝绿切换，到最后的验证和回滚过程。这一过程不仅优化了应用版本的滚动更新，也为开发者提供了快速回滚的方案，以应对可能出现的问题。</p><p><a href="https://mp.weixin.qq.com/s/RzglzZ0xY9NmsgujdHa-Tw" target="_blank" rel="noopener noreferrer">《Go 中的高速数据包处理:从 net.Dial 到 AF_XDP》</a>。文章介绍了使用 Go 语言进行高速数据包处理的多种方法，包括 net.Dial、原始套接字、系统调用、pcap 和 AF_PACKET，直至最新的 AF_XDP 方式。作者详细对比了每种方法的性能，从简单的 net.Dial 模式演进到 AF_XDP，逐步提高数据包每秒处理数量，同时指出各方法的使用场合和限制。通过基准测试，发现使用 AF_XDP 可实现最高性能，处理速度是使用 net.Dial 方法的4倍多。这些技术探讨对于需要大量网络数据包处理的场景，如网络监控、性能评估等都是非常重要的。</p><p><a href="https://mp.weixin.qq.com/s/dCQPOx2n2w36Q3P3hCKe8A" target="_blank" rel="noopener noreferrer">《数据库不应放在容器中?- B站Kubernetes有状态服务实践(Elasticsearch/Clickhouse)》</a>。文章探讨了在云原生时代下，有状态服务（如生产环境的数据库）是否适用于容器化并由Kubernetes进行管理的问题。以B站Elasticsearch和Clickhouse的容器化和Kubernetes编排实践为例，文章详细介绍了在容器环境中部署这些有状态服务的挑战和解决方案，包括控制器的选择、持久化存储、磁盘调度、调度器、容器网络、服务发现以及如何保证集群和数据的高可用性。作者分享了通过Operator管理有状态服务应用、使用本地盘PV提升性能、LVM技术的动态扩缩容方案以及通过macvlan进行容器间高效通信的技术细节。</p><p><a href="https://mp.weixin.qq.com/s/-TXbvQiR-tpB0RgQ5d-QDw" target="_blank" rel="noopener noreferrer">《一文带您探索 Kubernetes 中的容器类型》</a>。文章介绍了在 Kubernetes 系统中常见的四种容器类型：初始化容器(Init Container)、边车容器(Sidecar Container)、临时容器(Ephemeral Container)和多容器(Multi Container)。初始化容器用于运行 Pod 中主容器启动前的准备工作，而边车容器则与主应用容器并行运行，为其提供支持服务。临时容器主要用于故障排除，而多容器 Pods 允许并行运行多个容器，共享资源和数据。文章提供了每种容器的详细使用案例、配置方法和命令，并强调了各自的特点与应用场景。</p><p><a href="https://mp.weixin.qq.com/s/iylZAKZfxLL6SYruww_8zA" target="_blank" rel="noopener noreferrer">《4 秒处理 10 亿行数据! Go 语言的 9 大代码方案，一个比一个快》</a>。软件工程师Ben Hoyt挑战使用Go语言处理10亿行数据，并提出了9种解决方案，其中最快在4秒内完成。这些方案只使用Go标准库，包括简单但优化的map处理、并行化处理等。Ben的方案虽未最快，但展现了独立思考的价值。他的测试表明，彻底地数据处理和算法优化可显著提高性能，减少计算成本。</p><p><a href="https://mp.weixin.qq.com/s/aS-azhReZL5epoG_3n0hyg" target="_blank" rel="noopener noreferrer">《Go arena 民间库来了，可以手动管理内存!》</a>。文中作者煎鱼介绍了Go语言的一个新的第三方库ortuman/nuke，这个库允许开发者手动管理内存。文章首先回顾了Go官方对于arena手动内存管理提案的停滞现状，然后重点介绍了如何使用ortuman/nuke库进行内存管理，包括库的安装、使用案例以及如何在并发场景下保持线程安全。文章详细讲解了arena内存管理的优点，例如高效率和一次性释放，并对库的实际用法，如通过context在HTTP请求周期中管理内存，进行了展示。最后，基于性能考虑，文章还提供了并发与非并发业务场景下的基准测试结果以及性能差异。</p><p><a href="https://mp.weixin.qq.com/s/xRxRe6DkWJVcGKXOt1oGlQ" target="_blank" rel="noopener noreferrer">Go 语言中如何大小端字节序？int 转 byte 是如何进行的</a></p><p><a href="https://mp.weixin.qq.com/s/USKjmlyTtexSQtToOg481g" target="_blank" rel="noopener noreferrer">Go 中如何实现三元运算符？Rust 和 Python 是怎么做的</a></p><p><a href="https://mp.weixin.qq.com/s/mFZewdDxlK4O_wUWR6mVjg" target="_blank" rel="noopener noreferrer">Go语言中 enum 实现方式有哪些？一定要绝对类型安全吗</a></p><p><a href="https://mp.weixin.qq.com/s/obOG_Kior34ktLek3_-GZg" target="_blank" rel="noopener noreferrer">Go 中如何打印结构体？ 代码调试效率提升</a></p><p><a href="https://mp.weixin.qq.com/s/9ARiVYpYRy4FCuSJ5IKuGw" target="_blank" rel="noopener noreferrer">《快看! Go 1.22 对for循环进行了两个大更新》</a>。文章讨论了Go语言在 1.22 版本中针对for循环作出的两项主要更新：1. 每次迭代的for循环都将定义一个新的变量，不再共用同一个变量；2. 引入了对整数范围的循环迭代支持。这些更新解决了闭包在并发执行时共享变量带来的问题，同时也简化了循环结构，提高了编写对整数范围进行迭代代码的方便性。文中提供了详细的代码示例来展示新旧版本之间的差异，并说明了如何利用新特性来编写更高效的Go代码。</p><p><a href="https://mp.weixin.qq.com/s/lxp9OqiVAHtoX75UoaHipw" target="_blank" rel="noopener noreferrer">《从慢速到SIMD》聊Go边界检查消除》</a>。本文讨论了Go语言中边界检查消除（BCE）的相关技巧和最佳实践。文章首先回答了为何在Go代码中优化时选择使用<code>a[i:i+4:i+4]</code>而不是<code>a[i:i+4]</code>的问题，指出前者能减少编译器工作量从而提高性能。然后，介绍了Go101提出的BCE技术详解与应用实例，以及如何使用编译命令来检测边界检查的存在。文中还全面梳理了Go BCE技术的发展历程，以及在不同场景下消除冗余边界检查的方法，包括利用循环变量、常量索引等策略来提高代码执行效率。最后，提供了多种编程技巧以及相关讨论和参考资料，针对遇到的编程问题提出解决方案。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/pufzm-rIWMMnFl-ObJ-A9w" target="_blank" rel="noopener noreferrer">《RocketMQ 流存储解析:面向流场景的关键特性与典型案例》</a>。文章探讨了 RocketMQ 5.0 版本中流存储的关键特性，并针对流处理场景下的数据集成提供了详细解析。主要介绍了流存储访问模式与消息访问模式的区别，强调了流存储在大数据集成中起到异步解耦的作用。文章详细解释了 RocketMQ 5.0 版本对流存储弹性的新方案，包括静态 Topic 扩容模式和逻辑队列的引入，旨在解决传统弹性机制的限制。此外，文章还讲述了流场景对消息存储系统的高吞吐和状态维护要求，并举例了如何通过 CompactTopic 维护流状态。介绍了 Schema 概念的引入，以支持消息结构描述、提高类型安全并提升数据集成效率。最后，文章展示了流存储应用于日志采集和异构数据库同步的案例，以阐明其在实际数据架构中的作用。</p><p><a href="https://juejin.cn/post/7329413905028579340" target="_blank" rel="noopener noreferrer">《分库分表已成为过去式，使用分布式数据库才是未来》</a>。本文讨论了随着Mysql数据库性能下降，分库分表的局限性及其所引发的问题，如性能、事务、数据迁移等，并提出使用分布式数据库作为解决方案。文章详细介绍了TiDB这款分布式数据库的架构、特性和优势，包括其金融级的高可用性、水平扩容能力、兼容性以及云原生设计。文章强调TiDB在处理大规模数据时的效率和可维护性，终结分库分表的做法，并通过性能测试展示了TiDB与MySQL在不同场景下的性能表现。最终总结，对于数据量大的应用场景，采用TiDB来适应未来数据存储的需求是一个更优的策略。</p><p><a href="https://juejin.cn/post/7337247324681093129" target="_blank" rel="noopener noreferrer">《手把手带你精简代码-京东零售后端实践》</a>。本文分享了京东零售后端在面临代码库日渐庞大和腐化的问题时，采用的代码精简方法。文章分为背景介绍、代码精简步骤和实施方法三部分，着重介绍了使用IntelliJ IDEA自带工具和PMD插件进行静态代码检查的步骤、配置和优缺点，以及如何借助京东jacoco流水线进行动态代码检查。本文旨在降低代码维护成本、提升可理解性，并详细阐述了代码精简的实践过程和预期结果。</p><p><a href="https://mp.weixin.qq.com/s/ZSXAPM8oFiCGztqbs1kksQ" target="_blank" rel="noopener noreferrer">《跟着iLogtail学习无锁化编程》</a>。文章探讨了在多线程情况下，如何通过无锁化编程优化软件性能。详细讲述了iLogtail在实现无锁高效日志采集时采取的策略，比如自旋锁的使用、原子操作、内存顺序、内存屏障等概念。还分析了不同类型的锁的适用场景与特点，包括互斥锁、递归互斥锁和读写锁等。此外，文章还描述了如何将大的锁细分为多个小锁，通过降低锁粒度提升并发性能，以及在iLogtail中如何通过双Buffer机制来读写分离，减少锁的争用。最终，通过无锁化编程提高了iLogtail的日志采集性能，实现了低资源消耗和高性能。</p><p><a href="https://mp.weixin.qq.com/s/GtU4xBKzfK3q3IsPuQV6pQ" target="_blank" rel="noopener noreferrer">《MYSQL 是如何保证binlog 和redo log同时提交的?》</a>。文章讨论了如何确保在MYSQL中binlog（备份和主从同步用的日志）与redo log（InnoDB引擎层的日志，用于崩溃恢复）同步提交，以及为什么这一点对于防止主从数据不一致至关重要。文中解释了事务处理中的两个关键参数：<code>innodb_flush_log_at_trx_commit</code>和<code>sync_binlog</code>，这两个值设置为1时可以确保两种日志的同步提交。该文还介绍了MYSQL的两阶段提交机制如何工作，并提出了业务开发中两阶段提交逻辑的思考，指出在有依赖关系的服务操作中，通过预锁定资源、请求成功后递减资源来保持数据的最终一致性。</p><p><a href="https://mp.weixin.qq.com/s/jVKgmbvha6Q-iNxvVzg3nw" target="_blank" rel="noopener noreferrer">《这些年背过的面试题——分布式篇》</a>。本文从分布式系统的基础概念、发展历程及核心问题出发，详细介绍了分布式系统设计中的关键技术点。文章涵盖了负载均衡、服务的拆分与集群、分布式事务、数据一致性问题以及分区容错性等话题，并探讨了CAP理论与BASE理论在实际应用中的权衡。同时，文中还详细解读了常见的一致性算法如2PC、3PC、Paxos、Raft的机制和用例。此外，作者针对如何实现分布式Session、如何确保分布式事务的一致性等常见面试题目提供了详尽的解答，适合做为面试备考资料。</p><p><a href="https://mp.weixin.qq.com/s/y1-A-SHAkGdg9IOTeUtPxg" target="_blank" rel="noopener noreferrer">《RocketMQ为什么这么快?我从源码中扒出了10大原因!》</a>。这篇文章详细分析了RocketMQ高性能的10个关键因素：批量发送消息降低通信次数，消息压缩减少带宽和存储压力，基于Netty的高效网络通信模型，零拷贝技术优化磁盘读写性能，顺序写提高数据写入速度，高效数据存储结构，异步机制包括异步刷盘和异步主从复制提升存储效率，批量处理减少网络通信次数和资源消耗，锁优化以及线程池隔离提升并发处理能力。作者通过深入分析源码给出了RocketMQ快速处理和拉取消息的内在原因，并深入讨论了每种技术的优势和实现。</p><p><a href="https://mp.weixin.qq.com/s/39t_G3InMtHg9ETj_xYR7Q" target="_blank" rel="noopener noreferrer">《领导叫我接手一个新业务系统，我是这样熟悉项目的!》</a>。本文作者小许分享了接手新业务系统的熟悉流程和实践方法。包括与产品经理交流了解业务现状，绘制用例图、ER图以明确业务与数据模型，梳理后端模型和核心流程，并运用状态机流转图和时序图深度解析复杂逻辑。最后，还提到了绘制类图以理解代码结构。文章提供了一套系统性的工具和方法，目的是帮助新成员或负责新项目的开发人员快速掌握业务逻辑，有效推进项目进度。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/GqSoZR3bSeuLWiULHt8Zvg" target="_blank" rel="noopener noreferrer">《Tango 低代码引擎沙箱实现解析》</a>。本文介绍了Tango低代码引擎的沙箱实现。Tango是一个用于快速构建低代码平台的低代码设计器框架，通过对源代码进行执行和渲染前端视图，实现了低代码可视化搭建能力。借助Tango构建的低代码工具或平台可以实现源码进出的效果，并与企业内部现有的研发体系进行无缝集成。Tango的设计器引擎部分已经开源，并提供了相应的开源代码库、文档和社区讨论组。欢迎加入社区参与到Tango低代码引擎的开源建设中。更多相关文章可以在文中提供的链接中找到。</p><p><a href="https://mp.weixin.qq.com/s/U6ZQwLiW5sfkknz_bayosg" target="_blank" rel="noopener noreferrer">《未来只需要 2% 的程序员?》</a>。DHH在这篇文章中提出一个激进的观点，预测未来程序员的需求可能会大幅度减少。他比较了农业从97%的人口需求降至2%的变迁，暗示软件开发也可能面临着类似缩减。尽管这个行业曾经经历招聘热潮，但现在许多程序员面临职业前景不稳定。文章讨论了人工智能的发展给程序员职业带来的压力，同时也指出职业变革的不确定性。DHH认为，未来大多数程序员可能无需手动编程，但同时指出科技行业将更加融合进社会，并提高了它的价值。他鼓励程序员接受这一变化，并享受行业的黄金时代。</p><p><a href="https://mp.weixin.qq.com/s/tiolzTwPKPZF4b8zZbvYpA" target="_blank" rel="noopener noreferrer">《前端智能化，扣子(coze.cn)能做什么?》</a>。这篇文章探讨了扣子（coze.cn）平台如何通过提供一个简单的交互式界面来创建聊天机器人（Chatbot）。用户通过与扣子的对话，可以快速设置一个Chatbot，如自动化微信订阅号内容发布等。文章强调了平台的易用性和界面友好性，同时指出了一些潜在缺点，包括无法解决深度问题和偶尔遇到的技术故障。另外，通过知识库和数据库的集成，可进一步提升Bot的功能。作者对扣子的机器人创建过程、优势、建议和改进进行了详细介绍，并通过实操案例展示了前端智能化机器人的搭建过程。</p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/3月10日内容汇总">3月10日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-03-10T00:00:00.000Z" itemprop="datePublished">March 10, 2024</time> · <!-- -->35 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/maxresdefault-5b23cca3601cf7ebe54f3cb5023d859a.jpg" width="1280" height="720" class="img_astN"></p><p>封面图：Understanding the Go runtime - Jesus Espino</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://arxiv.org/abs/2401.11624" target="_blank" rel="noopener noreferrer">《In-context Learning with Retrieved Demonstrations for Language Models: A Survey》</a>。这篇题为 &quot;In-context Learning with Retrieved Demonstrations for Language Models: A Survey&quot; 的文章，主要讨论了语言模型，尤其是大型预训练语言模型如何通过获取的演示进行少量情景学习。这项技术能有效地改进学习过程的效率和可扩展性，并降低手动选择样例时的固有偏见。文章对此领域进行了广泛的研究回顾，对检索模型、检索训练过程和推理算法的不同设计选择进行了讨论和比较。</p><p><a href="https://mp.weixin.qq.com/s/NUhEy0YLTjtzY3BGVXhfrw" target="_blank" rel="noopener noreferrer">《碾压LoRA！Meta &amp; CMU | 提出高效大模型微调方法：GaLore，内存可减少63.3%》</a>。Meta和CMU合作提出了一种新的大模型微调方法——Gradient Low-Rank Projection（GaLore）。GaLore通过梯度的低秩投影代替权重的低秩适配，不仅支持全参数学习，而且显著降低了内存占用，减少了63.3%的内存需求。不同于LoRA的低秩权重更新，GaLore利用权重梯度的低秩特性，结合逐层权重更新和8位优化器，有效地优化了内存效率。此外，GaLore还引入了可调整的超参数，提高了其适应性。经实验验证，GaLore的表现优于LoRA，尤其是在预训练模型微调上表现更佳，为大模型训练提供了新的解决策略。</p><p><a href="https://juejin.cn/post/7316592794109198387" target="_blank" rel="noopener noreferrer">使用 GPT4V+AI Agent 做自动 UI 测试的探索 | 京东云技术团队</a></p><p><a href="https://mp.weixin.qq.com/s/ZSDCNDRu-tCkOlC9jz2j4w" target="_blank" rel="noopener noreferrer">Gemini修bug神了！录网页视频把代码库甩给它就行，网友坐不住了：想要访问权限</a></p><p><a href="https://mp.weixin.qq.com/s/GXwftkv-UpDQSjiTMn9TFA" target="_blank" rel="noopener noreferrer">一键开启 GPU 闲置模式，基于函数计算低成本部署 Google Gemma 模型服务</a></p><p><a href="https://mp.weixin.qq.com/s/YDwL3dV-Fq5zcEyrL__NGw" target="_blank" rel="noopener noreferrer">《Yi技术报告细节分享》</a>。该文章分享了Yi模型的具体实现细节和思路，强调了模型设计围绕模型规模、数据规模和数据质量。Yi模型的预训练阶段数据处理流程包括启发式过滤、学习式过滤、聚类过滤以及去重等步骤，以提高数据质量。微调阶段，Yi模型仅采用了10K数据进行模型微调，强调数据质量胜过数量。在分词器、模型结构及微调参数方面，Yi模型采用了一系列优化措施，包括Transformer-Decoder结构、Grouped-Query Attention等。总的来说，Yi模型通过优化数据处理流程、微调策略、调整模型结构和参数等多方面实现了高效的技术实现。</p><p><a href="https://mp.weixin.qq.com/s/lBXwSVvRHB2Yn0fYoOkDeQ" target="_blank" rel="noopener noreferrer">重新定义大模型推理！Google | 提出SELF-DISCOVER框架，大模型可自写推理结构！</a></p><p><a href="https://mp.weixin.qq.com/s/cB5tgMUPqg8fsXjNrzQpbg" target="_blank" rel="noopener noreferrer">《斯坦福 &amp;&amp; 微软 | 发布前端代码生成大模型：Design2Code-18B，助力前端自动化！》</a>。这篇文章主要介绍了一种新的前端代码生成大模型：Design2Code-18B，它可以将网页视觉设计转换成功能性代码。文章首先介绍了将网页视觉设计转换成功能性代码的挑战性和现有方法的局限性，然后提出了Design2Code基准和多模态提示方法，以激发多模态大型语言模型（如GPT-4V和Gemini）的潜力。接着，文章介绍了开源的18B微调模型Design2Code-18B，它基于CogAgent-18B，在多种数据集上进行了预训练，并使用了Huggingface发布的WebSight数据集进行微调。最后，文章展示了Design2Code-18B在Design2Code基准上的优越性能，并提供了一些未来研究方向。</p><p><a href="https://mp.weixin.qq.com/s/Pdp6_z_rxBl-kph41Lb8Ww" target="_blank" rel="noopener noreferrer">可控文本生成新方法，人大&amp;&amp;南开 | 提出DATG架构，准确性提升19.29%，效率提升1倍</a></p><p><a href="https://mp.weixin.qq.com/s/53jEDw58dkZlJAVzr31G8A" target="_blank" rel="noopener noreferrer">《Auto-Prompt | 大模型提示(Prompt)优化新方法IPC：可根据用户意图进行定向优化》</a>。这篇文章提出了一种名为 Intent-based Prompt Calibration（IPC）的系统，主要目的是通过使用合成案例样本来优化大型语言模型的提示工程。它基于模型生成的数据集进行提示优化，以解决大语言模型对给定提示的敏感性等问题。这种方法的核心思想是根据用户意图迭代细化提示。同时，文章还对 IPC 系统的整体架构和实现流程进行了详细介绍，并展示了一些实验结果。</p><p><a href="https://mp.weixin.qq.com/s/1d2_kHEQnug9iR0cU_0nAA" target="_blank" rel="noopener noreferrer">《更智能的 Agent，Plan-and-Execute Agents 计划和执行》</a>。这篇文章介绍了几种新型的智能 Agent 设计方法，包括 Plan-and-Execute Agents、ReWOO Agent 和 LLMCompiler。Plan-and-Execute Agent 设计法通过明确规划来优化智能 Agent 功能。ReWOO Agent 设计法凭借变量分配功能使得不必对每个任务都使用 LLM。LLMCompiler 则通过任务格式化为 DAG 来提高工具调用的效率。这些新型设计都在不同程度上优化了智能 Agent 的工作流程，提高了工作效率。</p><p><a href="https://mp.weixin.qq.com/s/F2s3pKycoNDT7Z-6piRHWg" target="_blank" rel="noopener noreferrer">《OpenAI Function Calling 与 LangChain Agent 工作原理及区别》</a>。这篇文章介绍了OpenAI Function Calling 与 LangChain Agent的工作原理及它们之间的区别。文章首先列举了大型语言模型的限制，并解释了为何需要Agent。然后，文章介绍了React Agent的工作方式，通过“Reason Only”（向内求索）、“Act Only”（向外探索）和“ReAct”（内外兼修）三种模式优化模型的功能。此外，文章还以一个简单的实例，解释了如何利用ReAct Agent来解答一个包含搜索和计算两个步骤的问题，展示了其实际应用的流程。</p><p><a href="https://mp.weixin.qq.com/s/iM45toKEHr3_rJxuwbgp4w" target="_blank" rel="noopener noreferrer">《ReAct Agent 回答 RAG 系统中的复杂问题》</a>。这篇文章主要讲述了“ReAct Agent 用于回答 RAG 系统中复杂问题的方式”。随着输入问题的复杂度升高，使用传统的聊天机器人已不能足够有效。于是，作者提出了利用 ReAct Agent，通过自然语言模型（LLMs）逐步规划并执行处理问题的步骤，并定义功能性工具（如时间计算、文本搜索、列表长度计算、百分比变化计算等）以辅助任务完成。这种方法能够更好地干预和控制问题的解决过程，从而提高任务的完成质量。</p><p><a href="https://mp.weixin.qq.com/s/1d2_kHEQnug9iR0cU_0nAA" target="_blank" rel="noopener noreferrer">更智能的 Agent，Plan-and-Execute Agents 计划和执行</a></p><p><a href="https://mp.weixin.qq.com/s/KF7joY-MkK4BZ8Rf8bLArw" target="_blank" rel="noopener noreferrer">ChatGPT也能画图？教你一键生成时序图、类图、流程图、状态图以及用例图</a></p><p><a href="https://mp.weixin.qq.com/s/E2xwi9SNYQ7sdzhYlaDQFg" target="_blank" rel="noopener noreferrer">三个被忽视的大模型提示</a></p><p><a href="https://mp.weixin.qq.com/s/u2LCRgBhKKcGZhY29PjIng" target="_blank" rel="noopener noreferrer">关于Sora和Stable Diffusion 3，你需要知道的一切</a></p><p><a href="https://mp.weixin.qq.com/s/z6IFIuHawVZI6ZOfgvgKuA" target="_blank" rel="noopener noreferrer">消费级显卡可用！李开复零一万物发布并开源90亿参数Yi模型，代码数学能力史上最强</a></p><p><a href="https://mp.weixin.qq.com/s/IBh3ytd3gtizAQd5PI2uig" target="_blank" rel="noopener noreferrer">详解大模型微调全流程</a></p><p><a href="https://mp.weixin.qq.com/s/UzC3J_TOzJPEx_86-lRwuw" target="_blank" rel="noopener noreferrer">南大俞扬教授：什么是world models/世界模型</a></p><p><a href="https://mp.weixin.qq.com/s/Gi6pzD7wAMyzlCBSSWkVLA" target="_blank" rel="noopener noreferrer">深入浅出LangChain与智能Agent：构建下一代AI助手</a></p><p><a href="https://mp.weixin.qq.com/s/T9YRVRGMgkwRSTl7Movadg" target="_blank" rel="noopener noreferrer">尤洋教授：开源完整的Sora复现方案来了！</a></p><p><a href="https://mp.weixin.qq.com/s/8WYWrHyE4oryCgO9AemImA" target="_blank" rel="noopener noreferrer">《T-RAG=RAG+微调+实体识别》</a>。这篇文章名为&quot;T-RAG=RAG+微调+实体识别&quot;，主要介绍了T-RAG技术，这是一种将RAG架构与微调语言模型和实体树向量数据库相结合的方法，用于支持语境检索。它概述了在敏感文档的背景下如何保护数据隐私，以及如何在有限的计算资源和基于现有文档建立的小型训练数据集中保证用户提问的准确回答。文中还着重介绍了T-RAG的工作流程和实体树的作用。最后，还提出了一个新的评估指标“Correct-Verbose”，用以评价生成回复的质量。此研究不仅是理论研究，也是实践中LLM应用的经验总结，具有实际的指导意义。</p><p><a href="https://mp.weixin.qq.com/s/de3UxM9WTrHNjnOKSny0aw" target="_blank" rel="noopener noreferrer">《高级 RAG（Self-Reflective RAG）》</a>。这篇文章名为&quot;高级 RAG(Self-Reflective RAG)&quot;，主要介绍了Self-Reflective RAG的理念和工作流程。在基本的RAG pipeline中，我们的过程往往受限于被动的检索和生成，而实际操作中，我们需要根据生成的结果进行优化，如改变问题或筛选和排列内容。为了解决这个问题，文章介绍了一种新的自我修正框架，包括Corrective RAG(CRAG)和Self-Reflective RAG。这两种RAG都围绕着对检索和生成内容的评估和反馈进行自我修正，并通过特定标识进行调控。在一定条件下，进一步改进了RAG，使其产生更好的检索和生成效果。</p><p><a href="https://mp.weixin.qq.com/s/WuJEubctUDsAmdhHcDItAg" target="_blank" rel="noopener noreferrer">RAG不够聪明？打造更强大的智能体</a></p><p><a href="https://mp.weixin.qq.com/s/b_eWGauwi6v0w4CoSOnU5w" target="_blank" rel="noopener noreferrer">Anthropic发布Claude3，效果已超越GPT4</a></p><p><a href="https://mp.weixin.qq.com/s/nMWTuKBnQVjgAM7Du6oOFQ" target="_blank" rel="noopener noreferrer">从0开始预训练1.4b中文大模型实践</a></p><p><a href="https://mp.weixin.qq.com/s/W5W582CqxvRhF3wnKwIdiQ" target="_blank" rel="noopener noreferrer">《分类算法入门:以鸢尾花数据集为例》</a>。这篇文章以鸢尾花数据集为例，全面而详细地阐述了机器学习中的分类算法基础知识。首先介绍了人工智能、机器学习和深度学习的基本概念，讲解了机器学习各种分类方法的理论背景。随后通过鸢尾花数据集，展示了如何使用 Python 工具（包括 pandas、sklearn、matplotlib 和 seaborn）进行数据处理、分析和可视化。文章详细讲述了决策树、逻辑回归、支持向量机、K近邻等经典的分类算法，并用图形化的方式展示了分类效果。最后，读者可以通过本文所提供的丰富学习资料来深化对机器学习分类任务的理解和应用。</p><p><a href="https://mp.weixin.qq.com/s/fkRG7n4tOQKwU85xiEx0Eg" target="_blank" rel="noopener noreferrer">《万字详解LLM Agents的现状，问题与未来》</a>。这篇文章名为&quot;写在跨年之前：聊聊LLM Agents的现状，问题与未来&quot;，主要涉及到LLM Agents的当前状态，面临的问题和未来的可能发展。文章探讨了包括全参微调、Prompt Tuning、LoRA、P-Tuning等在内的SFT(Selective Fine Tuning)范畴的各种技术。其中尤其强调了对于{prompt，response}的单轮问答对的微调是最简单的SFT实现方式。具体的内容细节大概需要阅读原文才能获得更深入的理解。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://go.dev/blog/generic-slice-functions" target="_blank" rel="noopener noreferrer">《Robust generic functions on slices》</a>。这篇文章名为&quot;Robust generic functions on slices&quot;，主要探讨了Go的slices包如何提供对切片进行操作的通用函数。该文章首先介绍了如何通过类型参数，一次性为所有类型的切片编写类似slices.Index等函数，而无需针对每种不同的元素类型重新实现。随后，文章深入讲述了新的函数（如Insert, Replace，Delete等）如何修改切片，并通过详述切片在内存中的表现形式及其对垃圾回收器的影响，来帮助读者理解这些函数的工作方式和正确使用它们。文章特别指出，新的Delete函数提供了更清晰地表达程序员意图的方式，而且它不需要分配新的数组，这样就可以在适当时清除无用的元素，帮助垃圾回收。文章强调，调用这些函数后，必须认为原始切片已无效，因为底层数组已被修改。最后，文章还讨论了在处理内存泄漏和元素零值设置等问题时的策略和选项，它们在新版本Go给出的解决方案，以及这些改变可能导致的一些测试问题。此外，作者鼓励开发人员正确使用新功能，并尽量避免上述列举的陷阱。</p><p><a href="https://go.dev/blog/routing-enhancements" target="_blank" rel="noopener noreferrer">《Routing Enhancements for Go 1.22》</a>。这篇文章名为&quot;Routing Enhancements for Go 1.22&quot;，主要介绍了 Go 1.22 版本中 net/http 包的路由器提供的新特性：方法匹配和通配符。这些新特性让你可以使用模式，而非 Go 代码，来表达常见的路由。这种新功能，尽管简单易懂，但要选择出多个匹配请求的最佳模式却是一项挑战。文章还详细阐释了如何在新版 Go 中使用这些新特性，以及这些引入的变化如何影响了 ServeMux 方法 handle 和 handleFunc 。此外，还描述了新模式如何更具优先级，并解释了其背后的原理。同时，为了保持新旧版本的兼容性，作者们也努力使新的模式语法能覆盖旧的，并使新的优先级规则能泛化旧的规则。总体上，这些改变是 Go 语言团队不断努力使 Go 成为构建生产系统的优秀语言的一个持续过程的一部分。</p><p><a href="https://mp.weixin.qq.com/s/IH1FGDpClrsnlfjg7OF3lg" target="_blank" rel="noopener noreferrer">听GPT 讲Rust源代码--compiler(6)</a></p><p><a href="https://mp.weixin.qq.com/s/JCU3dwkwpMP3qMKqg9ed6g" target="_blank" rel="noopener noreferrer">使用Apache Kafka的Golang实践指南</a></p><p><a href="https://mp.weixin.qq.com/s/RFsHfFByarSRAA-f1Rs13g" target="_blank" rel="noopener noreferrer">《Go 为什么不支持从 main 包中导入函数》</a>。这篇由煎鱼撰写的文章，题为 &quot;Go 为什么不支持从 main 包中导入函数?&quot;，对于这个话题进行了深度解析。其首先提到，虽然Go的规范并没有明确禁止从main包中导入函数，但我们在实际运行中会被拒绝，提示main包是一个程序而非可以导入的包。这一现象的原因来自于经过多次变动的规定，如2011年移除了 &quot;程序中的其他包都不能命名为 main&quot; 的要求，然后在2015年又新增了限制。这样的变化主要是为了避免增加复杂度和不安全性。比如，一个函数可能会做出自己拥有完全控制权的假设，所以如果引入多个main包中的函数，可能会产生在初始化顺序、全局变量的注册等方面的冲突。这篇文章认为Go官方的做法在理论上可以解决复杂度和安全性问题，但对于有历史债务的项目，对于需要维护多个Go项目工程，相当于磨灭了一条道路，其实比较尴尬。</p><p><a href="https://mp.weixin.qq.com/s/zxLO4IhLqQmIaUDzwwjU1w" target="_blank" rel="noopener noreferrer">《fasthttp是如何做到比net/http快十倍的》</a>。这篇文章讲解了fasthttp如何做到比net/http快十倍的原理。fasthttp相比于net/http在处理流程上有所差异，net/http是一个连接新建一个goroutine，当连接数非常多的时候会给系统带来一定的压力。而fasthttp则是建立了workerPool，每个workerChan在后台都会有一个Goroutine来处理其中的连接。此外，fasthttp的快速也得益于几个方面的优化：连接复用，大量使用了sync.Pool进行内存复用以及通过unsafe.Pointer指针进行<!-- -->[<!-- -->]<!-- -->byte和string转换来避免内存分配和拷贝的消耗。</p><p><a href="https://mp.weixin.qq.com/s/fx-FTVpM3CXIPUwTC_juDQ" target="_blank" rel="noopener noreferrer">《万字长文讲解Golang pprof 的使用》</a>。这篇文章主要讲述了Golang的pprof工具的使用。pprof工具是Golang中用于性能分析的一个工具，它可以分析出cpu使用情况、内存占用、阻塞情况、线程和协程等信息。文章中详细阐述了如何使用此工具，主要有两种方式，一种是通过http接口的方式暴露出pprof的采集控制界面，另一种是在程序中通过代码来启动相应指标的采集示例。文章还详细介绍了如何解析通过这两种方式获取的输出信息。本文的主要目的是将pprof工具的使用方式用思维导图的形式展示出来，这样可以帮助读者更好地理解和使用pprof工具。</p><p><a href="https://mp.weixin.qq.com/s/xYvMI0JieO6RxHIdWf1ujQ" target="_blank" rel="noopener noreferrer">《一篇实用的关于云上K8s应用分账实践》</a>。本文讲述云上Kubernetes（K8s）应用的成本分摊实践，涵盖了成本分摊的核心概念及阿里云ACK FinOps套件的应用。文中首先以前期预算为集群规划的依据，并讨论了随着业务发展对成本分摊精准度的提升需求。介绍了如何根据Pod的核/时成本，通过ACK集群、计算节点、命名空间和应用Pod这四个维度进行费用分摊。文章还分析了单资源和混合资源分摊模型，并讨论了如何设置Request和Limit来优化资源利用。对于多云和混合云场景，分享了如何通过ACK One实现统一管理和成本分析。针对复杂业务场景，讲述了自定义定价模版的使用方式，允许通过配置实现成本定制需求。对于追求细节管理和精细化运营的团队，这篇文章提供了宝贵的指导。</p><p><a href="https://mp.weixin.qq.com/s/6xx3-qow8A5Hdp_72jswow" target="_blank" rel="noopener noreferrer">《如何使用 K8s 两大利器&quot;审计&quot;和&quot;事件&quot;帮你摆脱运维困境》</a>。这篇文章主要讲述了如何使用 Kubernetes（K8s）的&quot;审计&quot;和&quot;事件&quot;功能来帮助进行日常集群运维工作。文章首先指出了运维工作中可能出现的一些问题，例如应用被删除、Apiserver负载突变、集群节点出现问题、节点自动扩容等。随后，文章进一步解释了 Kubernetes的审计和事件是如何运作的，强调了善用这两种工具可以提高集群的可观察性，为运维工作带来极大的便利。总的来说，这篇文章为运维人员提供了一种解决方案，通过使用 Kubernetes的审计和事件，可以更好地管理和监测集群的状态。</p><p><a href="https://mp.weixin.qq.com/s/lxEAFe2Ewmc8YvTqn8UcLQ" target="_blank" rel="noopener noreferrer">【Go 工具】竞态条件检测神器 Race Detector</a></p><p><a href="https://mp.weixin.qq.com/s/Y67J4_D1yyMa-eb7XmgTcA" target="_blank" rel="noopener noreferrer">使用Redis入门Golang</a></p><p><a href="https://mp.weixin.qq.com/s/qDFM-nVo-jeh9VdcBfMreA" target="_blank" rel="noopener noreferrer">一道面试题: Top K 问题</a></p><p><a href="https://mp.weixin.qq.com/s/sTd3SVh0swGTnaGugsw1SA" target="_blank" rel="noopener noreferrer">《理解 Docker 容器中 UID 和 GID 的工作原理》</a>。这篇文章详细解析了 Docker 容器中 UID 和 GID 的工作原理。首先，作者概述了用户名、组名、用户ID（UID）和组ID（GID）在容器内运行的进程与主机系统之间的映射对于构建安全系统的重要性。随后，文章分析了uid/gid在Linux系统的安全性，强调了单一内核概念以及uid/gid的分配方式。接着，作者运用实例解释了Docker运行的过程以及如何通过Dockerfile定义和启动不同用户。最后，文章讲述了如何掌控和控制容器的访问权限。在阐述以上内容的同时，文章也提供了一些实际示例来说明这些观点。</p><p><a href="https://mp.weixin.qq.com/s/yUuo1IjeXY78_5u4QpkuTA" target="_blank" rel="noopener noreferrer">《如何基于Docker镜像逆向生成Dockerfile》</a>。这篇文章介绍了如何将Docker镜像逆向生成Dockerfile。文章主要讲述了利用开源工具Dedockify的操作方法与工作原理。该工具通过Python脚本，利用存储在每个镜像层旁边的元数据，逐步遍历层级树，收集与每个层相关联的命令，重建镜像构建过程中执行的命令序列，从而得到近似的Dockerfile。不过，因为无法访问执行原始docker build命令时存在的构建上下文，如果使用了COPY或ADD指令，生成的输出可能不完全匹配原始的Dockerfile。</p><p><a href="https://mp.weixin.qq.com/s/KkRWQyljuo86-XbBxEnGPA" target="_blank" rel="noopener noreferrer">《通过多阶段构建减小Golang镜像的大小》</a>。本篇文章主要介绍了如何通过多阶段构建减小Golang镜像的大小。首先，作者提出了一个通用的Dockerfile，并指出其生成的镜像大小超过300MB，主要因为包含了所有的Golang工具。然后，作者提出了多阶段构建的方法，它能从不同的基础镜像构建，有选择地将文件从一个阶段传递到下一个阶段，从而减小镜像大小。在本例中，通过二级构建，镜像大小已降至11.7MB。最后，还探讨了使用名为scratch的空白镜像进一步减小镜像大小的可能性，使得镜像最后降至6.34MB，但作者强调这需要慎重考虑，因为最后生成的镜像将完全没有任何工具。</p><p><a href="https://mp.weixin.qq.com/s/dckA1ezcABndN5WSg1BOBA" target="_blank" rel="noopener noreferrer">《k8s 到底是什么，架构是怎么样的》</a>。这篇文章主要讲述了 Kubernetes（K8s）的基本概念、架构和工作原理。Kubernetes，因单词过长，我们通常简化为k8s。k8s 是一种容器的协调工具，位于应用服务和服务器之间，能以策略的方式协调和管理多个应用服务。通过一个 yaml 文件的配置，可以定义应用的部署顺序等信息，自动部署应用到各个服务器上，还能让它们崩溃后自动重启，可以自动扩容和缩容。Kubernetes 的服务器分为两部分：控制平面和工作节点，前者负责控制和管理各个节点，后者则负责实际运行各个应用服务。k8s 的命令行工具为 kubectl，用于执行各类操作命令。</p><p><a href="https://mp.weixin.qq.com/s/vjmntyGwzURz_elg27vpXg" target="_blank" rel="noopener noreferrer">《Go 泛型有没有可能在后期改为 <code>&lt;&gt;</code> 尖括号》</a>。这篇文章主要讨论了Go语言在处理泛型时，为何并没有采用类似Java和C++的 <code>&lt;&gt;</code> 尖括号表示法，而是选择了中括号 <code>[]</code>. 首先，使用尖括号可能导致语义混淆，如 <code>a, b := w &lt; x, y &gt; (z)</code> 此句，如果使用尖括号，程序可能在编译阶段无法确定该行表达式的具体含义。其次，使用圆括号也会导致同样的问题，比如 <code>func F(T any)(v T)(r1, r2 T)</code>, 无法快速准确判断出参数和返回值部分。此外，Go官方也不希望使用非ASCII的字符。作者还提到社区中对Go的处理方式存在一些争议，部分社区成员认为如果使得编译器解释尖括号不再困难，就可以采用这种符号。然而，总的来说，基于已有的实践和规范，Go语言在未来可能也不会改变其泛型的表示方式。</p><p><a href="https://mp.weixin.qq.com/s/arI9sip-5JH9YSu45XJ83w" target="_blank" rel="noopener noreferrer">《Rust中channel的使用》</a>。这篇文章主要介绍了Rust编程语言中Channel的用法。其中，Channel是Rust中用于在不同线程间传递信息的通信机制，实现了线程间的消息传递。每个Channel由发送端和接收端两部分组成，其设计理念是“通过通信来共享内存，而非通过共享内存来通信”，以此避免了数据竞争和共享内存的复杂性。该文章进一步详细介绍了如何在Rust中创建和使用Channel，并给出了相关代码示例。最后，文章阐述了多种Channel模型，包括Rust标准库中所使用的MPSC（多生产者，单消费者）模型。</p><p><a href="https://juejin.cn/post/7272006755266002959" target="_blank" rel="noopener noreferrer">K8s部署方式大全：从基础到进阶，一文带你掌握所有技巧</a></p><p><a href="https://juejin.cn/post/7301584578342289423" target="_blank" rel="noopener noreferrer">k8s从入门到精通 -- 更适合中国宝宝体质</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/NABg5tGizHsmdXgUO6NeVw" target="_blank" rel="noopener noreferrer">《万字+33张图探秘OpenFeign核心架构原理》</a>。本篇文章深入探讨了SpringCloud核心组件OpenFeign的核心架构原理。文章分为四个部分，首先解释原始Feign的使用和基于SpringCloud的进化过历程；然后详细讲解了Feign底层工作原理，依赖于JDK动态代理和核心组件如Contract、Encoder、Decoder等；接下来分析了SpringCloud是如何整合Feign的，并且讨论了OpenFeign的多种配置方式及其优先级；最后，文章通过丰富的图示和代码示例，使读者可以更好地理解并运用这一工具。这篇文章对于理解和运用OpenFeign非常有帮助，无论是对于初学者还是有经验的开发者。</p><p><a href="https://mp.weixin.qq.com/s/1Qe29y3nrbi39Kpaspme7Q" target="_blank" rel="noopener noreferrer">《三万字长文：如何去排查JVM内存问题》</a>。这篇文章是一份详尽的指导，讲述了如何排查JVM内存问题。文中首先定位了技术问题的范围，确定适用于JDK8至JDK11。接着，作者提出了系统化的排查原则，并提供了一步步的诊断流程，从基本信息收集、判断内存增长原因，到具体分析内存问题的可能来源。文章详细介绍了如何利用不同的命令和工具（如jmap、jstat、Arthas等）进行详细的分析，并根据内存使用情况，向读者展示了如何确定是堆内存问题还是堆外内存问题。总之，文章为那些需要深入理解和处理JVM内存问题的开发者和运维人员提供了宝贵的知识和技巧。</p><p><a href="https://mp.weixin.qq.com/s/WLPo8s_M3AzxwB3o3ehY3w" target="_blank" rel="noopener noreferrer">《如何避免MYSQL主从延迟带来的读写问题》</a>。这篇文章讨论了如何处理在MySQL主从部署架构中普遍存在的主从同步延迟问题，以保持读写操作的一致性。文章首先介绍了主从延迟产生的场景及其对读写分离原则的影响。然后，详细解释了主从复制的原理，并提出了两种避免主从数据不一致的技术方案：一是使用select master_pos_wait函数来等待从库同步至特定的binlog位置点；二是在开启GTID模式的情况下，通过select wait_for_executed_gtid_set函数检查GTID集合是否已同步。这两种方法均旨在确保从库数据的准确性，从而整体上减轻主库的压力。总体上，文章为MySQL数据库管理员提供了缓解主从延迟导致的读写问题的具体实施方案。</p><p><a href="https://mp.weixin.qq.com/s/dt_14etV_2ynAmyMa_uyug" target="_blank" rel="noopener noreferrer">《这些年背过的面试题——ES篇》</a>。这篇文章是一篇针对Elasticsearch(ES)的面试指南，它涵盖ES基础知识点和面试过程中常见问题。内容包括ES的功能特性介绍（如分布式架构、全文搜索、数据分析等）、主要的使用场景描述、与其他搜索引擎的对比（Lucene和Solr）、以及ES的基本概念解释。文章还详细探讨了ES的高级特性，如映射、DSL查询、聚合分析和智能搜索建议器。此外，作者还分享了关于数据索引优化的实战技巧和策略，提供了写优化、读优化和索引重建的方案，这些方案对ES数据存储和查询的性能有显著影响，最后还对Deep Paging性能问题提供了解决方法。对正在准备面试或者希望巩固ES知识的读者而言，这篇文章是一个宝贵的资源。</p><p><a href="https://mp.weixin.qq.com/s/gAJFm3q5510PfRBe4F11PQ" target="_blank" rel="noopener noreferrer">《什么是MySQL锁？有哪些锁类型》</a>。这篇文章详细地介绍了MySQL中的锁定机制及其类型。起初概述了锁的作用，即协调多进程或线程对资源的并发访问，在数据库环境下，锁对于保持事务的正确性与一致性至关重要。作者明确区分了MySQL中锁的级别，从全局锁、表锁（读锁、写锁）到元数据锁、意向锁，直到行锁的多种形式（记录锁、间隙锁和临键锁）。文中还探讨了AUTO-INC锁的作用和相关优化，举例说明了其在INSERT操作中的应用。此外，文章也涉及了如何根据不同的情况优化锁的使用以及如何避免由锁产生的性能瓶颈。这篇文章为理解MySQL的各种锁类型和锁机制提供了宝贵的信息，特别对于数据库管理员和那些需要管理并发数据访问问题的开发人员来说，具有很高的实用价值。</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/m-Ae6dbFuW22u2xSDWcciw" target="_blank" rel="noopener noreferrer">Vue 团队正式开源 Rolldown：基于 Rust 的超快 JavaScrip 打包工具！</a></p><p><a href="https://mp.weixin.qq.com/s/MVR5rV2LkH8_GHCtP6SHug" target="_blank" rel="noopener noreferrer">打造舒适的vscode开发环境</a></p><p><a href="https://mp.weixin.qq.com/s/pY4-RqqamTmPXnRPfw0hRA" target="_blank" rel="noopener noreferrer">相比于 Node.js，Deno 和 Bun 到底能带来什么</a></p><p><a href="https://mp.weixin.qq.com/s/yBTK4Rds28aJ88mVgkoYJA" target="_blank" rel="noopener noreferrer">MDH Weekly 122 - 《招人》</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/3月3日内容汇总">3月3日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-03-03T00:00:00.000Z" itemprop="datePublished">March 3, 2024</time> · <!-- -->4 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/image-abab847b03119684181cda4a9b7bdb44.png" width="1080" height="308" class="img_astN"></p><p>封面图：用 switch-case 来解决 Go 错误处理的难题</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/II_6lb9KjKOmz-DIgnaz7g" target="_blank" rel="noopener noreferrer">LangChain 实战：Agent思维</a></p><p><a href="https://mp.weixin.qq.com/s/tl32MrTPMi0i7BN53ELb2w" target="_blank" rel="noopener noreferrer">详解大模型RLHF过程（配代码解读）</a></p><p><a href="https://mp.weixin.qq.com/s/J8yEbS-XTJY0aFyJAl1ypA" target="_blank" rel="noopener noreferrer">PromptFlow高质量AI应用 - 基于LLM的文档QA机器人</a></p><p><a href="https://mp.weixin.qq.com/s/gPVwXysJsV2S2FgP3c6Qpw" target="_blank" rel="noopener noreferrer">图解大模型计算加速系列：Flash Attention V1，从硬件到计算逻辑</a></p><p><a href="https://mp.weixin.qq.com/s/yfou0pEkbbUZxe2NS1jnag" target="_blank" rel="noopener noreferrer">使用搭载骁龙 8 Gen 3 的安卓手机运行 AI 大模型</a></p><p><a href="https://mp.weixin.qq.com/s/ws3U1NBouPivqatUb_ldQA" target="_blank" rel="noopener noreferrer">生成式 AI 的发展方向，是 Chat 还是 Agent</a></p><p><a href="https://mp.weixin.qq.com/s/U1IqQElxkfHfQoxygMnSOg" target="_blank" rel="noopener noreferrer">聊聊大模型Agent技术，及和具身智能又有什么异同</a></p><p><a href="https://mp.weixin.qq.com/s/eWlms4IxTd4wzka4V7Gu6w" target="_blank" rel="noopener noreferrer">复旦NLP团队发布80页大模型Agent综述，一文纵览AI智能体的现状与未来</a></p><p><a href="https://mp.weixin.qq.com/s/cZB90npCcz88IJ6W00LnMA" target="_blank" rel="noopener noreferrer">知识问答系统的优化实践：LLM与RAG的结合艺术</a></p><p><a href="https://mp.weixin.qq.com/s/xxFcMRMl--HPcGAkAYaW7w" target="_blank" rel="noopener noreferrer">一文解构大模型RAG问答关键环节及与LLM微调对比总结</a></p><p><a href="https://mp.weixin.qq.com/s/K0yFNjpcBk5OL-1DRHSeGA" target="_blank" rel="noopener noreferrer">Mistral AI发布Mistral Large模型</a></p><p><a href="https://mp.weixin.qq.com/s/rvIJLIEvvzQ5n8v7ZF6pWw" target="_blank" rel="noopener noreferrer">Mistral AI新模型对标GPT-4，不开源且与微软合作，网友：忘了初心</a></p><p><a href="https://mp.weixin.qq.com/s/gTFVNbWRsxONnoE_fq2S3A" target="_blank" rel="noopener noreferrer">大模型微调新范式：当LoRA遇见MoE</a></p><p><a href="https://mp.weixin.qq.com/s/P5XktjiRgY2Q6V1pLyqYAw" target="_blank" rel="noopener noreferrer">Mistral Large，Le Chat来了！Mistral AI连放两个大招！</a></p><p><a href="https://mp.weixin.qq.com/s/1zc4klUCCsgeFDaA5K2Rgg" target="_blank" rel="noopener noreferrer">探索2024年1月的AI研究前沿：模型合并、专家混合与小型LLM的崛起</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/PCFDz_fVsk_6M144VpBAww" target="_blank" rel="noopener noreferrer">Cargo的自定义命令扩展功能</a></p><p><a href="https://mp.weixin.qq.com/s/CXnLIoYhI1k3SNP3IWz8dQ" target="_blank" rel="noopener noreferrer">听GPT 讲Rust源代码--compiler(2)</a></p><p><a href="https://mp.weixin.qq.com/s/vg8MfMBEs8I-FQl3Nuay6Q" target="_blank" rel="noopener noreferrer">元老与新秀：Go sort.Search()和sort.Find()</a></p><p><a href="https://mp.weixin.qq.com/s/oM8JS_eMQjeU2tJzfO7f5w" target="_blank" rel="noopener noreferrer">KisFlow-基于Golang的流式计算框架实战(6)-Connector</a></p><p><a href="https://mp.weixin.qq.com/s/1DuY0WXZ_GsG87Ahuk_9rw" target="_blank" rel="noopener noreferrer">跳槽必看のMySQL索引：B+树原理揭秘与索引优缺点分析</a></p><p><a href="https://mp.weixin.qq.com/s/QfE-dnHlIv49ae205RrJ_Q" target="_blank" rel="noopener noreferrer">听GPT 讲Rust源代码--compiler(1)</a></p><p><a href="https://mp.weixin.qq.com/s/xVBT-E3IiYsiOtHF2V22Xw" target="_blank" rel="noopener noreferrer">KisFlow-基于Golang的流式计算框架实战(5)</a></p><p><a href="https://mp.weixin.qq.com/s/MkWxrN_kQFNn9rMeJXs3PA" target="_blank" rel="noopener noreferrer">用 switch-case 来解决 Go 错误处理的难题</a></p><p><a href="https://mp.weixin.qq.com/s/7C7Jxe7XEN-vQKiY2MJMtw" target="_blank" rel="noopener noreferrer">KisFlow-基于Golang的流式计算框架实战(4)</a></p><p><a href="https://mp.weixin.qq.com/s/SHLh2ofDUteQCafXZo8mmw" target="_blank" rel="noopener noreferrer">KisFlow-基于Golang的流式计算框架实战(3)</a></p><p><a href="https://mp.weixin.qq.com/s/WoUYmpvYH6ixYSDwFga59g" target="_blank" rel="noopener noreferrer">图文讲透Golang标准库 net/http实现原理 -- 客户端</a></p><p><a href="https://mp.weixin.qq.com/s/TqAQ9kP4HlFN9UdLq0tavQ" target="_blank" rel="noopener noreferrer">使用docker init编写Dockerfile和docker-compose配置</a></p><p><a href="https://mp.weixin.qq.com/s/tqAcoskLYd2UV6B_6AeIjw" target="_blank" rel="noopener noreferrer">Go语言中常见100问题-#完结撒花</a></p><p><a href="https://mp.weixin.qq.com/s/9Pg8blMjqECaCY_W9MbYHg" target="_blank" rel="noopener noreferrer">KisFlow-基于Golang的流式计算框架实战(2)</a></p><p><a href="https://mp.weixin.qq.com/s/4ufuA3n9aaFcQ9zDItUHaQ" target="_blank" rel="noopener noreferrer">golang 高性能无 GC 的缓存库 bigcache 是怎么实现的</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/5BwWCekb_wIu6LrCdmoGCQ" target="_blank" rel="noopener noreferrer">从0到1构建一个稳定、高性能Redis集群</a></p><p><a href="https://mp.weixin.qq.com/s/KetCuZNb9jR0HSY7Jqh0NA" target="_blank" rel="noopener noreferrer">这些年背过的面试题——SpringCloud篇</a></p><p><a href="https://mp.weixin.qq.com/s/hCZanLARApXcW2_6r3g-5A" target="_blank" rel="noopener noreferrer">如何设计订单超时自动取消</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/H9_kt3L6l6fj0aBP9UonhA" target="_blank" rel="noopener noreferrer">2024 AI &amp; 前端：回首展望，光芒未至，破晓之前！</a></p><p><a href="https://mp.weixin.qq.com/s/kZOpaaIfogWzeB7KwdTkRw" target="_blank" rel="noopener noreferrer">看完zustand源码后，我的TypeScript水平突飞猛进</a></p><p><a href="https://mp.weixin.qq.com/s/Q1vvgM_A7QEtO-0a3GLUsw" target="_blank" rel="noopener noreferrer">ElTable 二次封装：我用 Vue3.3 新特性完美解决了列插槽数据无类型提示问题！！！</a></p><p><a href="https://mp.weixin.qq.com/s/WgtUG0vp3fk0_388svrGXg" target="_blank" rel="noopener noreferrer">ECharts 迎来重大更新，运行时包体积可减少 98%！</a></p><p><a href="https://mp.weixin.qq.com/s/1XmH55nqs7wavsWJNT-tSw" target="_blank" rel="noopener noreferrer">FFmpeg前端视频合成实践</a></p><p><a href="https://mp.weixin.qq.com/s/8D6yD3A5-KPod85zsxRPZQ" target="_blank" rel="noopener noreferrer">2024 使用 TS 搭建 Node.js 服务器 - 快速教程</a></p><p><a href="https://mp.weixin.qq.com/s/udt61U0aaoFJqnzFKhGTjw" target="_blank" rel="noopener noreferrer">前端食堂技术周刊第 113 期：Node 年终总结、Node 新吉祥物、Qwik 2.0、React Labs 工作进展</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/2月25日内容汇总">2月25日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-02-25T00:00:00.000Z" itemprop="datePublished">February 25, 2024</time> · <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://arxiv.org/pdf/2402.13446" target="_blank" rel="noopener noreferrer">Large Language Models for Data Annotation: A Survey</a></p><p><a href="https://arxiv.org/pdf/2402.13547.pdf" target="_blank" rel="noopener noreferrer">ACTIVERAG: Revealing the Treasures of Knowledge via Active Learning</a></p><p><a href="https://arxiv.org/pdf/2209.02646.pdf%EF%BC%8Chttps://github.com/chq1155/A-Survey-on-Generative-Diffusion-Model?tab=readme-ov-file" target="_blank" rel="noopener noreferrer">关于Generative-Diffusion-Model的全面综述，可以作为了解sora的基础知识</a></p><p><a href="https://mp.weixin.qq.com/s/f2A6r5dVSBwDO_h27dlj6A" target="_blank" rel="noopener noreferrer">云音乐 CMS 平台 AIGC 实践与新特性实现总结</a></p><p><a href="https://mp.weixin.qq.com/s/Oc1f3thZYIONsF4OWWEcSw" target="_blank" rel="noopener noreferrer">云音乐D2C设计稿转代码建设实践</a></p><p><a href="https://mp.weixin.qq.com/s/2O5z9rAvLxU3ZsU7k4xdhA" target="_blank" rel="noopener noreferrer">云音乐 AI Agent 探索实践</a></p><p><a href="https://mp.weixin.qq.com/s/jaIiVI636uJBOOKsXuHCpw" target="_blank" rel="noopener noreferrer">云音乐低代码 + ChatGPT 实践方案与思考</a></p><p><a href="https://www.bilibili.com/video/BV1vJ4m1s7Zn" target="_blank" rel="noopener noreferrer">🦜🕸️ LangGraph：Plan-Execute Agents 实战</a></p><p><a href="https://mp.weixin.qq.com/s/G1DYQiAjUL9zphJ8ajrrtg" target="_blank" rel="noopener noreferrer">Pinecone总结一：大模型角度</a></p><p><a href="https://mp.weixin.qq.com/s/N6RI456ouuczWjyqXOSPNQ" target="_blank" rel="noopener noreferrer">使用 Hugging Face 微调 Gemma 模型</a></p><p><a href="https://mp.weixin.qq.com/s/fsvgtS3stS1cfrIT78XBCA" target="_blank" rel="noopener noreferrer">开源大语言模型作为 LangChain 智能体</a></p><p><a href="https://mp.weixin.qq.com/s/tJj0ZCX8fRS2Xcr0v85C8g" target="_blank" rel="noopener noreferrer">200万上下文窗口创飞Gemini 1.5！微软来砸谷歌场子了（doge）</a></p><p><a href="https://mp.weixin.qq.com/s/idr60a1a66gdGFSZrOnC0w" target="_blank" rel="noopener noreferrer">如何利用大模型进行数据标注与知识蒸馏：兼看ActiveRAG上下文去噪的大模型RAG问答范式</a></p><p><a href="https://mp.weixin.qq.com/s/NNkVs_TnaStvjWdmfrM88Q" target="_blank" rel="noopener noreferrer">树形结构与RAG的完美结合：T-RAG方法在组织内部信息查询中的突破</a></p><p><a href="https://mp.weixin.qq.com/s/MsaCUnTsJYxJFgnNGT6DTA" target="_blank" rel="noopener noreferrer">领先99%小白的Sora关键信息！</a></p><p><a href="https://mp.weixin.qq.com/s/Js9YAibVSeVwfy4-xESDRg" target="_blank" rel="noopener noreferrer">AI, Machine Learning和 Deep Learning有什么差异</a></p><p><a href="https://mp.weixin.qq.com/s/qImKOQXLoZqLTW-SVISKHA" target="_blank" rel="noopener noreferrer">模型融合、混合专家、更小的LLM，几篇论文看懂2024年LLM发展方向</a></p><p><a href="https://mp.weixin.qq.com/s/_iCYfqmXA3enKn3Hm-DwSA" target="_blank" rel="noopener noreferrer">开源大模型王座易主！谷歌Gemma杀入场，笔记本可跑，可商用</a></p><p><a href="https://mp.weixin.qq.com/s/H2ie4vuhLqr4UKtgvZZtEQ" target="_blank" rel="noopener noreferrer">关于Google开源Gemma的一些想法</a></p><p><a href="https://mp.weixin.qq.com/s/0xzCAqiXOsscBItpN9R0lA" target="_blank" rel="noopener noreferrer">LangChain原理学习笔记</a></p><p><a href="https://mp.weixin.qq.com/s/gHyMnVxh-QVe58TvZMvl8Q" target="_blank" rel="noopener noreferrer">工具增强型大模型：引领智能新时代</a></p><p><a href="https://mp.weixin.qq.com/s/YAGfwy5fUHbTW5f3bUSYVg" target="_blank" rel="noopener noreferrer">AI 实战：手把手教你使用「扣子/coze」来搭建个人blog知识库</a></p><p><a href="https://mp.weixin.qq.com/s/W9iVW7niyi_HvEWxOcnwuA" target="_blank" rel="noopener noreferrer">大模型推理优化实践：KV cache复用与投机采样</a></p><p><a href="https://mp.weixin.qq.com/s/06w7_lb8Hc4Ee2GG9I4wLg" target="_blank" rel="noopener noreferrer">NLP研究在大模型时代的创新飞跃</a></p><p><a href="https://mp.weixin.qq.com/s/delaJc2KDxLWfUUtGo-V-A" target="_blank" rel="noopener noreferrer">下一代RAG范式：RAG-Fusion</a></p><p><a href="https://mp.weixin.qq.com/s/5K6yNj23NmNLcAQofHcT4Q" target="_blank" rel="noopener noreferrer">图解大模型计算加速系列：Flash Attention V2，从原理到并行计算</a></p><p><a href="https://mp.weixin.qq.com/s/yr_VAbEIresEH352Iyehjg" target="_blank" rel="noopener noreferrer">如何在小公司做大模型</a></p><p><a href="https://mp.weixin.qq.com/s/j52XdHyD5w_Ug-hpWlPIgQ" target="_blank" rel="noopener noreferrer">机器学习简介: 寻找函数的艺术</a></p><p><a href="https://mp.weixin.qq.com/s/3reFjJNHuL8J24EyLmsSPA" target="_blank" rel="noopener noreferrer">OpenAl 视频生成模型 —— Sora技术报告解读</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/oL_G8H_ROSF3TjtzBOGCow" target="_blank" rel="noopener noreferrer">etcd存储引擎之主干框架</a></p><p><a href="https://mp.weixin.qq.com/s/5PovYOUzHFcCU2JjDLEnnA" target="_blank" rel="noopener noreferrer">Rust 高性能编程指南</a></p><p><a href="https://mp.weixin.qq.com/s/n0v8Xtz1q9XRvZuI4tPoXg" target="_blank" rel="noopener noreferrer">Go map 加有序排序的一些挣扎</a></p><p><a href="https://mp.weixin.qq.com/s/uYmSCyTZtbSpiIL6Qet5_A" target="_blank" rel="noopener noreferrer">云音乐 GitOps 最佳实践</a></p><p><a href="https://mp.weixin.qq.com/s/UNr11UvRX9kzKefKttX4wg" target="_blank" rel="noopener noreferrer">KisFlow-基于Golang的流式计算框架实战(1)</a></p><p><a href="https://mp.weixin.qq.com/s/-oQITzwDo51TkUyzUs0BQQ" target="_blank" rel="noopener noreferrer">相同型号物理机，容器性能不如虚拟机</a></p><p><a href="https://mp.weixin.qq.com/s/-zgXvXuUlqywbEPUygmv7w" target="_blank" rel="noopener noreferrer">听GPT 讲Rust源代码--library/portable-simd</a></p><p><a href="https://mp.weixin.qq.com/s/r-HbSxbvrpIltUdCXCEzSw" target="_blank" rel="noopener noreferrer">Go deadcode：查找没意义的死代码，对于维护项目挺有用！</a></p><p><a href="https://mp.weixin.qq.com/s/Be6VYGlSa-AXcDkuhCQ1HA" target="_blank" rel="noopener noreferrer">通俗易懂剖析Go Channel：理解并发通信的核心机制</a></p><p><a href="https://mp.weixin.qq.com/s/-C-wIjkKM7N1M7fcCd7HSQ" target="_blank" rel="noopener noreferrer">竟然是&quot;你&quot;偷走了那0.001的服务可用性</a></p><p><a href="https://mp.weixin.qq.com/s/BqNLR9rsWSPtTJpzOX1uOw" target="_blank" rel="noopener noreferrer">精心设计的 DNS Failover 策略在 Go 中竟然带来了反效果，发生了什么</a></p><p><a href="https://mp.weixin.qq.com/s/Sx2Bo_KUVh2w6twwb_XBVA" target="_blank" rel="noopener noreferrer">Go语言中常见100问题-#100 Not understanding the impacts of running Go</a></p><p><a href="https://mp.weixin.qq.com/s/2AWWhbkEhwTJcgCjL-9pcQ" target="_blank" rel="noopener noreferrer">《从慢速到SIMD》聊Go 边界检查消除</a></p><p><a href="https://mp.weixin.qq.com/s/fmlzQfwmIwMgP38op0Ebmg" target="_blank" rel="noopener noreferrer">Go项目中的Labels</a></p><p><a href="https://mp.weixin.qq.com/s/dnF3bxT0H_OfAsml9m976w" target="_blank" rel="noopener noreferrer">Go 更强的代码洁癖，可以把 gofmt 给换了！</a></p><p><a href="https://mp.weixin.qq.com/s/b1cLEth3cgQsTmMCgw9Bog" target="_blank" rel="noopener noreferrer">Go 终于把这个傻缺特性去掉了，多少陈年老BUG都是因为它！</a></p><p><a href="https://mp.weixin.qq.com/s/10cPBDKOuSuyW1XTUxuqiw" target="_blank" rel="noopener noreferrer">Go 1.22 slices 库的更新：高效拼接、零化处理和越界插入优化</a></p><p><a href="https://mp.weixin.qq.com/s/KUiTxRBQcywcyHsHmOFvEQ" target="_blank" rel="noopener noreferrer">Go 1.22中值得关注的几个变化</a></p><p><a href="https://mp.weixin.qq.com/s/Gp4yLILc2rWQonn2Bg-FTg" target="_blank" rel="noopener noreferrer">Go中最常用的数据校验库</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/8DT0tNYbuPjXkKwMMUABYg" target="_blank" rel="noopener noreferrer">美团面试：说说OOM三大场景和解决方案？ （绝对史上最全）</a></p><p><a href="https://mp.weixin.qq.com/s/5RehBI0KwDFzkY5ssuivEQ" target="_blank" rel="noopener noreferrer">(九)深入并发编程之并发容器：阻塞队列、写时复制容器、锁分段容器原理详谈</a></p><p><a href="https://mp.weixin.qq.com/s/BJ9ju3Ov6ZwgpbjoM2SDqA" target="_blank" rel="noopener noreferrer">(八)深入并发之Runnable、Callable、FutureTask及CompletableFuture原理分析</a></p><p><a href="https://mp.weixin.qq.com/s/n4OGEkfJ_ql-gifHVaN7ZA" target="_blank" rel="noopener noreferrer">四十五图，一万五千字！一文让你走出迷雾玩转Maven！</a></p><p><a href="https://mp.weixin.qq.com/s/iKz_iABnlibNb1fRM3RXmA" target="_blank" rel="noopener noreferrer">踩了一堆坑，终于把微服务系统全面升级 JDK17 和 SpringBoot3 了</a></p><p><a href="https://mp.weixin.qq.com/s/VGgT1faRKGnUuQ-HHQ3Q5g" target="_blank" rel="noopener noreferrer">奇思妙想的SQL｜兼顾性能的数据倾斜处理新姿势</a></p><p><a href="https://mp.weixin.qq.com/s/3xi9uu5OXVRS0dX1PxW9UA" target="_blank" rel="noopener noreferrer">如何成为一线 Leader</a></p><p><a href="https://mp.weixin.qq.com/s/f3yorGDYOFVeLydwkAPvFw" target="_blank" rel="noopener noreferrer">ForkJoinPool：大任务拆分，让并行嗨起来！</a></p><p><a href="https://mp.weixin.qq.com/s/h6Bhgcu7QqV0nMUvOUThsg" target="_blank" rel="noopener noreferrer">写了这么多年DateUtils，殊不知你还有这么多弯弯绕！</a></p><p><a href="https://mp.weixin.qq.com/s/8UNtMIllJ03ULZwE9WtVdg" target="_blank" rel="noopener noreferrer">这些年背过的面试题——Kafka篇</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/UXZa0lJfQznseNfRnld1_g" target="_blank" rel="noopener noreferrer">🤯 <!-- -->[<!-- -->性能优化<!-- -->]<!-- --> 浏览器跨域带来的一些性能问题</a></p><p><a href="https://mp.weixin.qq.com/s/uIupFpxXkbrKiEkCl_1ZYg" target="_blank" rel="noopener noreferrer">🧐 <!-- -->[<!-- -->跨端开发<!-- -->]<!-- --> 如何定位 Hybrid Web 页面中 Native 注入的 JS 代码</a></p><p><a href="https://sorrycc.com/book-a-philosophy-of-software-design" target="_blank" rel="noopener noreferrer">413 - 《读书笔记：A Philosophy of Software Design》</a></p><p><a href="https://www.totaltypescript.com/forwardref-with-generic-components" target="_blank" rel="noopener noreferrer">如何在泛型组件中使用 forwardRef</a></p><p><a href="https://sorrycc.com/hot-module-replacement-is-easy" target="_blank" rel="noopener noreferrer">译：Hot Module Replacement 原理</a></p><p><a href="https://mp.weixin.qq.com/s/ga5-g5sOTccc7z1ZCQ29jg" target="_blank" rel="noopener noreferrer">MDH Weekly 121 - 《开工大吉》</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/2月18日内容汇总">2月18日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-02-18T00:00:00.000Z" itemprop="datePublished">February 18, 2024</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/image-d2a0b993dc7670c91648bb3cd9ddb230.png" width="1080" height="538" class="img_astN"></p><p>封面图：牛逼了！2月编程语言榜单：Go首次进入前十</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://towardsdatascience.com/how-to-cut-rag-costs-by-80-using-prompt-compression-877a07c6bedb" target="_blank" rel="noopener noreferrer">How to Cut RAG Costs by 80% Using Prompt Compression</a></p><p><a href="https://arxiv.org/abs/2401.08406" target="_blank" rel="noopener noreferrer">RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture</a></p><p><a href="https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7" target="_blank" rel="noopener noreferrer">RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application</a></p><p><a href="https://mp.weixin.qq.com/s/Nyu46KN0Hj2-r93vXVcbiQ" target="_blank" rel="noopener noreferrer">大语言模型之LlaMA系列- LlaMA 2及LLaMA2_chat(上)</a></p><p><a href="https://mp.weixin.qq.com/s/G8nKz4H3QSKBibSMYAzRvA" target="_blank" rel="noopener noreferrer">RAG还是微调？微软出了一份特定领域大模型应用建设流程指南</a></p><p><a href="https://mp.weixin.qq.com/s/FKC7Y-05L9VfukI-3EMvZw" target="_blank" rel="noopener noreferrer">谷歌全新大模型突然发布！100万token完爆GPT-4，仅靠提示词就能学会新语言</a></p><p><a href="https://mp.weixin.qq.com/s/iIIM3N1-1cE2SxBRdZ-ILg" target="_blank" rel="noopener noreferrer">扩展说明: 指令微调 Llama 2</a></p><p><a href="https://mp.weixin.qq.com/s/6q2LmwoFG2LcN0iHoZjjqw" target="_blank" rel="noopener noreferrer">社区供稿 | 图解大模型推理优化之 KV Cache</a></p><p><a href="https://mp.weixin.qq.com/s/va1Ua3koedNWKkln4v6Vvg" target="_blank" rel="noopener noreferrer">大模型性能优化之Prompt工程全面梳理：从zero shot到chain of thought再到花式XOT</a></p><p><a href="https://mp.weixin.qq.com/s/bJRFayNByx4D3ujGcEb47A" target="_blank" rel="noopener noreferrer">大模型RAG问答行业最佳案例及微调、推理双阶段实现模式：基于模块化(Modular)RAG自定义RAG Flow</a></p><p><a href="https://mp.weixin.qq.com/s/j07PkTCoxBzAhkyON1puPg" target="_blank" rel="noopener noreferrer">值得一看的大模型RAG问答总括性梳理：模块化(Modular)RAG范式的定义、构成及机遇</a></p><p><a href="https://www.bilibili.com/video/BV1tN4y1m78N" target="_blank" rel="noopener noreferrer">【有腔调的RAG】01 半结构化数据上的RAG</a></p><p><a href="https://www.bilibili.com/video/BV16w411J7sW" target="_blank" rel="noopener noreferrer">省钱！微软开源框架LLMLingua + LlamaIndex实现提示词压缩</a></p><p><a href="https://www.bilibili.com/video/BV1GK4y1q718" target="_blank" rel="noopener noreferrer">Ollama Python开发包实例 | 基于本地部署开源大模型的Streamlit聊天应用</a></p><p><a href="https://www.bilibili.com/video/BV1yH4y117oV" target="_blank" rel="noopener noreferrer">【隐私优先】Llama 2 + GPT4All + Chroma实现100%本地化RAG</a></p><p><a href="https://mp.weixin.qq.com/s/XZDG8ZaB4QqD5cgIDJT6vQ" target="_blank" rel="noopener noreferrer">大模型时代还不理解自注意力？这篇文章教你从头写代码实现</a></p><p><a href="https://mp.weixin.qq.com/s/4ZnL0_uMLBgbVCNVjPWGKg" target="_blank" rel="noopener noreferrer">陈丹琦团队新作：数据量砍95%，大模型性能更强了！Less is More</a></p><p><a href="https://juejin.cn/post/7298997940019314742" target="_blank" rel="noopener noreferrer">【AI 初体验】 llama2与LangChain 的 SQLDatabaseChain</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://juejin.cn/post/7306806944047415332" target="_blank" rel="noopener noreferrer">从物理机到K8S：应用系统部署方式的演进及其影响</a></p><p><a href="https://mp.weixin.qq.com/s/ujs3PT_g7yFHVW-klzTJNQ" target="_blank" rel="noopener noreferrer">Leetcode 算法题解精选</a></p><p><a href="https://mp.weixin.qq.com/s/HaVmckBGakEwu-EJ5JkONg" target="_blank" rel="noopener noreferrer">牛逼了！2月编程语言榜单：Go首次进入前十</a></p><p><a href="https://mp.weixin.qq.com/s/fQensm55bnzPKagMEVs8Ag" target="_blank" rel="noopener noreferrer">Go语言中常见100问题-#99 Not understanding how the GC works</a></p><p><a href="https://mp.weixin.qq.com/s/GwOvZYfT6Y7euZuum9868Q" target="_blank" rel="noopener noreferrer">Go语言中常见100问题-#98 Not using Go diagnostics tooling</a></p><p><a href="https://juejin.cn/post/7317462907302461475" target="_blank" rel="noopener noreferrer">一文搞懂Go GC演进史，讲的太细致了！</a></p><p><a href="https://juejin.cn/post/7307244392564408358" target="_blank" rel="noopener noreferrer">Rust 中的并发模型和所有权系统</a></p><p><a href="https://juejin.cn/post/7270326047342182419" target="_blank" rel="noopener noreferrer">Kitex：微服务架构下的高性能优化实践</a></p><p><a href="https://juejin.cn/post/7245919919223636023" target="_blank" rel="noopener noreferrer">探究 Go 的高级特性之 【处理1分钟百万请求】</a></p><p><a href="https://juejin.cn/post/7247428110165016613" target="_blank" rel="noopener noreferrer">探究 Go 的高级特性之 【领域驱动设计中篇】</a></p><p><a href="https://juejin.cn/post/7333027152139567113" target="_blank" rel="noopener noreferrer">用 Go 语言实现刘谦 2024 春晚魔术，还原尼格买提汗流浃背的尴尬瞬间!</a></p><p><a href="https://juejin.cn/post/7323087699479724042" target="_blank" rel="noopener noreferrer">还不敢写多线程程序？看看Go如何让并发控制简单有趣</a></p><p><a href="https://juejin.cn/post/7325733245166026793" target="_blank" rel="noopener noreferrer">从 fatal 错误到 sync.Map：Go中 Map 的并发策略</a></p><p><a href="https://juejin.cn/post/7330052230472663055" target="_blank" rel="noopener noreferrer">16. Go调度器系列解读（三）：GMP 模型调度时机</a></p><p><a href="https://juejin.cn/post/7327138554756857908" target="_blank" rel="noopener noreferrer">15. Go调度器系列解读（二）：Go 程序启动都干了些什么</a></p><p><a href="https://juejin.cn/post/7324931501926875170" target="_blank" rel="noopener noreferrer">14. Go调度器系列解读（一）：什么是 GMP</a></p><p><a href="https://juejin.cn/post/7319484272531701812" target="_blank" rel="noopener noreferrer">13. 入门 go 语言汇编，看懂 GMP 源码</a></p><p><a href="https://juejin.cn/post/7298645450554605568" target="_blank" rel="noopener noreferrer">8. 看 Go 源码，你需要了解 unsafe.Pointer</a></p><p><a href="https://juejin.cn/post/7293820517375164416" target="_blank" rel="noopener noreferrer">5. golang map 源码的逐句解读</a></p><p><a href="https://juejin.cn/post/7319418651069743167" target="_blank" rel="noopener noreferrer">一文搞懂Kubernetes 部署策略</a></p><p><a href="https://juejin.cn/post/7303075105390477323" target="_blank" rel="noopener noreferrer">滚动更新和回滚部署在 Kubernetes 中的工作原理</a></p><p><a href="https://juejin.cn/post/7291853227245764658" target="_blank" rel="noopener noreferrer">Go 项目标准布局？Go 官方出指南了</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/j_cslpQDjVIUm1CGjk9CQQ" target="_blank" rel="noopener noreferrer">阿里终面：Netty 如何做到单机百万并发</a></p><p><a href="https://mp.weixin.qq.com/s/9jKS_vW7lN3f-RwEDS7avw" target="_blank" rel="noopener noreferrer">8种专坑同事 SQL写法，性能降低100倍，不来看看</a></p><p><a href="https://mp.weixin.qq.com/s/GGvBCVWSLce7Gs0Z0B8Jvg" target="_blank" rel="noopener noreferrer">亿级推送，得物是怎么架构的</a></p><p><a href="https://mp.weixin.qq.com/s/cvuz0619FadtkzmjD47llg" target="_blank" rel="noopener noreferrer">详解Redis三大集群模式，轻松实现高可用！</a></p><p><a href="https://mp.weixin.qq.com/s/AMkub_c3bTk8O0NzsdW35Q" target="_blank" rel="noopener noreferrer">阿里Java面试官：CopyOnWriteArrayList底层是怎么保证线程安全的</a></p><p><a href="https://mp.weixin.qq.com/s/PlizO3EnFRmqn4Cl6nqiGA" target="_blank" rel="noopener noreferrer">还搞不懂ConcurrentHashMap底层源码，看这篇就够了</a></p><p><a href="https://mp.weixin.qq.com/s/gb9nqVfqrClZ5o4-B4Eadg" target="_blank" rel="noopener noreferrer">只需七步，教你轻松解决Redis热点Key问题</a></p><p><a href="https://mp.weixin.qq.com/s/FPYE1B839_8Yk1-YSiW-1Q" target="_blank" rel="noopener noreferrer">一文详解Redis中BigKey、HotKey的发现与处理</a></p><p><a href="https://mp.weixin.qq.com/s/dpXMqMSq_ZrXOeEInxlC_Q" target="_blank" rel="noopener noreferrer">Java 十亿行数据计算，最快6秒出结果，你能吗</a></p><p><a href="https://juejin.cn/post/7249380394457694263" target="_blank" rel="noopener noreferrer">从Kafka中学习高性能系统如何设计 | 京东云技术团队</a></p><p><a href="https://juejin.cn/post/7256104538230571067" target="_blank" rel="noopener noreferrer">由浅入深的介绍扣减业务中的一些高并发构建方案（上）</a></p><p><a href="https://juejin.cn/post/7226525442176778277" target="_blank" rel="noopener noreferrer">如何在微服务下保证事务的一致性 | 京东云技术团队</a></p><p><a href="https://juejin.cn/post/7309373606272761895" target="_blank" rel="noopener noreferrer">【Redis高可用系列】主从复制原理和复制方式分析</a></p><p><a href="https://juejin.cn/post/7300809038246608948" target="_blank" rel="noopener noreferrer">Redis删除数据后，为什么内存占用率还是很高</a></p><p><a href="https://juejin.cn/post/7290725204266287158" target="_blank" rel="noopener noreferrer">感觉Redis变慢了，这些可能的原因你查了没 (上)</a></p><p><a href="https://juejin.cn/post/7292975471448113192" target="_blank" rel="noopener noreferrer">感觉Redis变慢了，这些可能的原因你查了没 (下)</a></p><p><a href="https://juejin.cn/post/7280435879541637176" target="_blank" rel="noopener noreferrer">位图(bitmap)原理以及实现</a></p><p><a href="https://juejin.cn/post/7329694104118362139" target="_blank" rel="noopener noreferrer">亿万用户在线，一张bitmap统计全解密</a></p><p><a href="https://juejin.cn/post/7282666872218107915" target="_blank" rel="noopener noreferrer">如何使用Redis数据类型进行亿级别统计数据</a></p><p><a href="https://juejin.cn/post/7319273137765449763" target="_blank" rel="noopener noreferrer">MySQL事务未提交redolog能持久化到磁盘吗</a></p><p><a href="https://juejin.cn/post/7269296778226597927" target="_blank" rel="noopener noreferrer">结合MySQL更新流程看 undolog、redolog、binlog</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://juejin.cn/post/7275978708644511802" target="_blank" rel="noopener noreferrer">致所有渴望学习Rust的人的信</a></p><p><a href="https://juejin.cn/post/7327867132037611539" target="_blank" rel="noopener noreferrer">前端项目里都有啥</a></p><p><a href="https://juejin.cn/post/7302310196310294580" target="_blank" rel="noopener noreferrer">白嫖ChatGPT4.0 (第二弹)</a></p><p><a href="https://mp.weixin.qq.com/s/XuigLACJa95rJ9iJQhIDDg" target="_blank" rel="noopener noreferrer">字节跳动最热门的 15 个前端开源项目</a></p><p><a href="https://mp.weixin.qq.com/s/PUywO7JtYuO9H0fnLGsz-w" target="_blank" rel="noopener noreferrer">刘谦春晚魔术揭秘：约瑟夫环的数学魅力，JS实现下！</a></p><p><a href="https://mp.weixin.qq.com/s/tk_E1NP6ra0yxuSVumH6UA" target="_blank" rel="noopener noreferrer">我写了一个根据项目自动切换node版本的插件，再也不用手动使用命令切换了</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/2月11日内容汇总">2月11日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-02-11T00:00:00.000Z" itemprop="datePublished">February 11, 2024</time> · <!-- -->4 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/image-4ddfe3a33bcfd972300e1fa8e273d003.png" width="900" height="520" class="img_astN"></p><p>封面图：Go1.22 正式发布！包含语言变化、性能提高、标准库变动等重要特性</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://arxiv.org/pdf/2401.15391.pdf" target="_blank" rel="noopener noreferrer">MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries</a></p><p><a href="https://mp.weixin.qq.com/s/fV-dnbT5g8j_B3RXgRsuZQ" target="_blank" rel="noopener noreferrer">手把手教你，从零开始实现一个稀疏混合专家架构语言模型（MoE）</a></p><p><a href="https://mp.weixin.qq.com/s/jtpXKlABXwzlN8QjzT-sPA" target="_blank" rel="noopener noreferrer">苹果为自家芯片打造开源框架MLX，实现Llama 7B并在M2 Ultra上运行</a></p><p><a href="https://mp.weixin.qq.com/s/dSleYYKtE41RQ9AUf5ruMw" target="_blank" rel="noopener noreferrer">如何用LLM和自有知识库搭建智能Agent</a></p><p><a href="https://mp.weixin.qq.com/s/MY7sWGct2IxvDYvthY6A0g" target="_blank" rel="noopener noreferrer">万字详解专家混合：MoE模型</a></p><p><a href="https://mp.weixin.qq.com/s/JloI284hBrKyV0d2s7V3ug" target="_blank" rel="noopener noreferrer">Prompt Engineering：大模型 PUA 指南！</a></p><p><a href="https://mp.weixin.qq.com/s/IxQy6UMXaFn2odVFLhEXHw" target="_blank" rel="noopener noreferrer">Mixtral-8x7B 模型挖坑</a></p><p><a href="https://mp.weixin.qq.com/s/BITRn0NkpaVP0niiqevUaQ" target="_blank" rel="noopener noreferrer">精彩手绘全解：RAG技术，从入门到精通</a></p><p><a href="https://mp.weixin.qq.com/s/qeWEEmWlomjtFP5wQxUAcg" target="_blank" rel="noopener noreferrer">单卡3小时训练专属大模型Agent-基于LLaMA Factory实战</a></p><p><a href="https://mp.weixin.qq.com/s/DGeey6v3ntGhIorOd_eB3w" target="_blank" rel="noopener noreferrer">白话Embedding：普通人都能懂的科普文</a></p><p><a href="https://mp.weixin.qq.com/s/GGY-hvcNphj4fvPxJPLLrQ" target="_blank" rel="noopener noreferrer">Mixtral 8x7B: 超越GPT-3.5与Llama 2 70B的稀疏混合专家架构新篇章</a></p><p><a href="https://mp.weixin.qq.com/s/NSfAdIBXNzG9WNrz9jP1eA" target="_blank" rel="noopener noreferrer">3B模型不输7B LLaVA！北大多模态MoE模型登GitHub热榜</a></p><p><a href="https://mp.weixin.qq.com/s/HUW8MX2GhsdE3qFBvb1-Hg" target="_blank" rel="noopener noreferrer">GPT-4推理能力暴涨32%，谷歌新型思维链效果超CoT，计算成本可降至1/40</a></p><p><a href="https://mp.weixin.qq.com/s/Ddn-8zI7SF5VfoQPcoYuPg" target="_blank" rel="noopener noreferrer">阿里大模型春节礼包来了：代码可执行率超GPT-4，1.5版本全系列开源</a></p><p><a href="https://mp.weixin.qq.com/s/V3abZ1R-NYG7nMRngheYbA" target="_blank" rel="noopener noreferrer">刚刚，谷歌弃Bard发布超大杯Gemini，全面对标GPT-4，前2个月免费！</a></p><p><a href="https://mp.weixin.qq.com/s/O9PP4Oc_Ee3R_HxKyd31Qg" target="_blank" rel="noopener noreferrer">无需RLHF显著提升GPT-4/Llama2性能，北大团队提出Aligner对齐新范式</a></p><p><a href="https://mp.weixin.qq.com/s/mPO13cCbTgIkWZBfKSjFvA" target="_blank" rel="noopener noreferrer">手撕LangChain代码，新手请进</a></p><p><a href="https://mp.weixin.qq.com/s/Ks6X9RSCuNnTU2ZlQiGpqA" target="_blank" rel="noopener noreferrer">MoE 卷起来啦！又一微调版 Mixtral-8x7B 发布，试试效果怎么样</a></p><p><a href="https://mp.weixin.qq.com/s/lGcatebmosW9BerZyVRlBQ" target="_blank" rel="noopener noreferrer">不是 GPT4 用不起，而是本地运行 Mixtral-8x7B 更有性价比</a></p><p><a href="https://mp.weixin.qq.com/s/mmG8NQbG6fnmc4lHL1zHWQ" target="_blank" rel="noopener noreferrer">在 Mac 运行 OpenChat 3.5 大模型，AI推理APP仅2MB 完全可移植</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/4bd77FfQubPqdhcNJPFrsQ" target="_blank" rel="noopener noreferrer">代码验证斯特林公式的准确性</a></p><p><a href="https://mp.weixin.qq.com/s/-8IcAjN6T6LeE29p0nkqcQ" target="_blank" rel="noopener noreferrer">一些笔记工具工具以及memos介绍</a></p><p><a href="https://mp.weixin.qq.com/s/vr_-5HD0hFZYHmnnisByiA" target="_blank" rel="noopener noreferrer">Go 1.22.0 可称之为一次史诗级更新</a></p><p><a href="https://mp.weixin.qq.com/s/SFMKam051BIZI4gwz8nrKg" target="_blank" rel="noopener noreferrer">Go1.22 正式发布！包含语言变化、性能提高、标准库变动等重要特性</a></p><p><a href="https://mp.weixin.qq.com/s/8JAQxUQSfIggAIArokeL9g" target="_blank" rel="noopener noreferrer">实现基于 Grafana Loki 的日志报警</a></p><p><a href="https://mp.weixin.qq.com/s/P8E52qK6qeigwTMPWECBsw" target="_blank" rel="noopener noreferrer">齐活了，Grafana 发布大规模持续性能分析开源数据库 - Phlare</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/IsEDEu33HqHffFdv-A7WBw" target="_blank" rel="noopener noreferrer">DDD落地：从携程订单系统重构，看DDD的巨大价值</a></p><p><a href="https://mp.weixin.qq.com/s/QGmOz8jUjNo-3xKqVcWGmg" target="_blank" rel="noopener noreferrer">一次由于八股文引起的内存泄漏</a></p><p><a href="https://mp.weixin.qq.com/s/tNOhR16aC-cr5EqKiwbAOQ" target="_blank" rel="noopener noreferrer">网易面试：请设计一个高可用性的软件架构，说明设计思路</a></p><p><a href="https://mp.weixin.qq.com/s/L26rI11OV8hrfJVy5Yu78g" target="_blank" rel="noopener noreferrer">这些年背过的面试题——MySQL篇</a></p><p><a href="https://mp.weixin.qq.com/s/2I3gFQZY03OKhdJa1AVhmw" target="_blank" rel="noopener noreferrer">天天写业务代码，如何破局业务开发的本质</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/z5zzBWel6DooAS0bzY702g" target="_blank" rel="noopener noreferrer">瀑布流优化：我把小红书的瀑布流虚拟列表撕出来了</a></p><p><a href="https://mp.weixin.qq.com/s/GYtd3k0JXns1GZQyZzvHaQ" target="_blank" rel="noopener noreferrer">心遇APP站内玩法H5体验优化实践</a></p><p><a href="https://sorrycc.com/ssr-local-dates-without-fouc" target="_blank" rel="noopener noreferrer">译：如何避免 SSR 渲染本地日期时的 FOUC 问题</a></p><p><a href="https://sorrycc.com/danger-rehydration" target="_blank" rel="noopener noreferrer">译：危险的注水</a></p><p><a href="https://sorrycc.com/react-19-new-hooks" target="_blank" rel="noopener noreferrer">译：React 19 计划推出的新 Hook</a></p><p><a href="https://sorrycc.com/promise-with-resolvers" target="_blank" rel="noopener noreferrer">译：使用 Promise.withResolvers 延迟 Promise</a></p><p><a href="https://web.dev/articles/5-css-snippets-every-front-end-developer-should-know-in-2024" target="_blank" rel="noopener noreferrer">2024 年你需要知道的 5 个 CSS 代码片段</a></p><p><a href="https://www.youtube.com/watch?v=MTcPrTIBkpA" target="_blank" rel="noopener noreferrer">Partial Prerendering 的 What、Why 和 How</a></p><p><a href="https://www.robinwieruch.de/react-starter/" target="_blank" rel="noopener noreferrer">2024 年如何启动 React 项目</a></p><p><a href="https://mp.weixin.qq.com/s/fY-wz2LzkiZrvpblpSWlVw" target="_blank" rel="noopener noreferrer">MDH Weekly 120 - 《小册》</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_XMSB" itemprop="headline"><a itemprop="url" href="/frontend-weekly/2024/2月4日内容汇总">2月4日内容汇总</a></h2><div class="container_fJtn margin-vert--md"><time datetime="2024-02-04T00:00:00.000Z" itemprop="datePublished">February 4, 2024</time> · <!-- -->5 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/img/IMG_0687.JPG" alt="加菲猫"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Jiacheng787" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">加菲猫</span></a></div><small class="avatar__subtitle" itemprop="description">前端开发 @NETEASE</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alt text" src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/images/image-a5ba8682f95c9c3d63a2f2a7a0fb4e99.png" width="1279" height="592" class="img_astN"></p><p>封面图：图文吃透Golang net/http 标准库--服务端</p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-ai-相关">🌟 AI 相关<a href="#-ai-相关" class="hash-link" aria-label="Direct link to 🌟 AI 相关" title="Direct link to 🌟 AI 相关">​</a></h2><p><a href="https://arxiv.org/abs/2402.00157" target="_blank" rel="noopener noreferrer">Large Language Models for Mathematical Reasoning: Progresses and Challenges</a></p><p><a href="https://arxiv.org/abs/2401.15347" target="_blank" rel="noopener noreferrer">A Comprehensive Survey of Compression Algorithms for Language Models</a></p><p><a href="https://arxiv.org/abs/2401.14887" target="_blank" rel="noopener noreferrer">The Power of Noise: Redefining Retrieval for RAG Systems</a></p><p><a href="https://arxiv.org/abs/2401.15884" target="_blank" rel="noopener noreferrer">Corrective Retrieval Augmented Generation</a></p><p><a href="https://mp.weixin.qq.com/s/tFl0RQd3ex98_SAOIIfM_Q" target="_blank" rel="noopener noreferrer">从零构建现代深度学习框架(TinyDL-0.01)</a></p><p><a href="https://mp.weixin.qq.com/s/Z0iZR6iGSBe298eK1Er1Ow" target="_blank" rel="noopener noreferrer">本地运行面壁智能的“贺岁模型”：MiniCPM 2B</a></p><p><a href="https://mp.weixin.qq.com/s/Ni_vVDlxBaoUcgoVORw31A" target="_blank" rel="noopener noreferrer">「我在淘天做技术」2024年看AIGC是如何让1688主图焕发新春的</a></p><p><a href="https://mp.weixin.qq.com/s/em-mnps_Oqe1PLLpJ9hB-A" target="_blank" rel="noopener noreferrer">大模型推理框架RTP-LLM对LoRA的支持</a></p><p><a href="https://mp.weixin.qq.com/s/chxksL3zqbwyqHev1x43kw" target="_blank" rel="noopener noreferrer">LLM之LangChain（五）| 使用LangChain Agent分析非结构化数据</a></p><p><a href="https://mp.weixin.qq.com/s/a5uKQAxwfsREnXd0XPhu1A" target="_blank" rel="noopener noreferrer">LLM之RAG理论（六）| 高级RAG指南和技巧</a></p><p><a href="https://mp.weixin.qq.com/s/gDtzzSRunUrKjoIUGSHCvA" target="_blank" rel="noopener noreferrer">从零手搓MoE大模型，大神级教程来了</a></p><p><a href="https://juejin.cn/post/7325993514702258230" target="_blank" rel="noopener noreferrer">RAG进阶 多用户多文档</a></p><p><a href="https://juejin.cn/post/7325831147563958308" target="_blank" rel="noopener noreferrer">RAG 进阶 LlamaIndex多文档</a></p><p><a href="https://juejin.cn/post/7325724706139996201" target="_blank" rel="noopener noreferrer">RAG 进阶 多模态图片检索</a></p><p><a href="https://juejin.cn/post/7325800661232140327" target="_blank" rel="noopener noreferrer">RAG 进阶 半结构化数据</a></p><p><a href="https://juejin.cn/post/7310347016982069288" target="_blank" rel="noopener noreferrer">LlamIndex二 RAG应用开发</a></p><p><a href="https://juejin.cn/post/7310786591940165641" target="_blank" rel="noopener noreferrer">LlamaIndex 一 简单文档查询</a></p><p><a href="https://mp.weixin.qq.com/s/9cTNa_oya2Zj9YdDYodCvw" target="_blank" rel="noopener noreferrer">使用 Docker 快速上手中文版 LLaMA2 开源大模型</a></p><p><a href="https://mp.weixin.qq.com/s/_WStiyaAk7G-w2j6SVe4CA" target="_blank" rel="noopener noreferrer">部署必备—triton-inference-server的backend（一）——关于推理框架的一些讨论</a></p><p><a href="https://mp.weixin.qq.com/s/J1EdNtAx3B0yeQ7zeSDLQg" target="_blank" rel="noopener noreferrer">TensorRT-LLM初探（一）运行llama，以及triton tensorrt llm backend服务化</a></p><p><a href="https://mp.weixin.qq.com/s/xcNQBG69XkS6mOstzqROAw" target="_blank" rel="noopener noreferrer">H100推理飙升8倍！英伟达官宣开源TensorRT-LLM，支持10+模型</a></p><p><a href="https://mp.weixin.qq.com/s/jnQs5XhWeAqoitahmDhziQ" target="_blank" rel="noopener noreferrer">大语言模型推理提速：TensorRT-LLM 高性能推理实践</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="️-go--云原生--rust-相关">⭐️ Go &amp; 云原生 &amp; Rust 相关<a href="#️-go--云原生--rust-相关" class="hash-link" aria-label="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关" title="Direct link to ⭐️ Go &amp; 云原生 &amp; Rust 相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/_RHDJ1VGfqolE_Uzorosbw" target="_blank" rel="noopener noreferrer">Go1.22 新特性：性能提高、Trace 大修、工作区支持 vendor 等</a></p><p><a href="https://mp.weixin.qq.com/s/h8SNvIVN1bFy8gBUB63_NA" target="_blank" rel="noopener noreferrer">json.Marshal为什么会对[]byte类型进行base64编码处理</a></p><p><a href="https://mp.weixin.qq.com/s/PvdZ_Ay9xgrY_SrDt-Sddw" target="_blank" rel="noopener noreferrer">Go调度器系列解读（二）：Go 程序启动都干了些什么</a></p><p><a href="https://mp.weixin.qq.com/s/MNuk0poC3s2tTx_DjyJAQA" target="_blank" rel="noopener noreferrer">Go语言中的Pinner.Pin</a></p><p><a href="https://mp.weixin.qq.com/s/wQqMu41e8pnLpnAZo0GLow" target="_blank" rel="noopener noreferrer">Kubernetes 调度器队列 - 设计与实现</a></p><p><a href="https://mp.weixin.qq.com/s/CNTlXMWSmQ4dNbbCQpbjYg" target="_blank" rel="noopener noreferrer">Go语言通知协程退出(取消)的几种方式</a></p><p><a href="https://mp.weixin.qq.com/s/SC1tg6XxDi_y1bjj6lkw6w" target="_blank" rel="noopener noreferrer">Go语言中常见100问题-#97 Not relying on inlining</a></p><p><a href="https://mp.weixin.qq.com/s/_z801oBwANP27C-BXbHNZA" target="_blank" rel="noopener noreferrer">程序员才懂的乐趣：10亿行的挑战</a></p><p><a href="https://mp.weixin.qq.com/s/vHr56wXPVAl-b4tbnvhS5w" target="_blank" rel="noopener noreferrer">Kubernetes 调度器 - 核心流程 (下篇)</a></p><p><a href="https://mp.weixin.qq.com/s/g4NdoFWrcGmSMeQt8q1XtA" target="_blank" rel="noopener noreferrer">Go调度器系列解读（一）：什么是 GMP</a></p><p><a href="https://mp.weixin.qq.com/s/4hZ6laeQc5P2o2n1yKD_8w" target="_blank" rel="noopener noreferrer">Kubernetes 调度器 - 核心流程 (上篇)</a></p><p><a href="https://mp.weixin.qq.com/s/e7Z_kZrayTFx7y0hlzoTdg" target="_blank" rel="noopener noreferrer">图文讲透Golang标准库 net/http实现原理 -- 服务端</a></p><p><a href="https://mp.weixin.qq.com/s/b7dHVIVYsL-19gyzUujktA" target="_blank" rel="noopener noreferrer">利用 ChatGPT 高效搜索Go问题：举一反三的思考方式，高效查找解决方案</a></p><p><a href="https://mp.weixin.qq.com/s/d5nczMvDpELt8R5ZB08Yow" target="_blank" rel="noopener noreferrer">Go语言中常见100问题-#96 Not knowing how to reduce allocations</a></p><p><a href="https://mp.weixin.qq.com/s/l6Tq_bVDmMpwZg_rPfi1DQ" target="_blank" rel="noopener noreferrer">从慢速到SIMG: 一个Go优化的故事</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-后端相关">📒 后端相关<a href="#-后端相关" class="hash-link" aria-label="Direct link to 📒 后端相关" title="Direct link to 📒 后端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/jwAawzeKq_vTTYw58rvgVA" target="_blank" rel="noopener noreferrer">8种专坑同事的 SQL 写法，性能降低100倍，不来看看</a></p><p><a href="https://mp.weixin.qq.com/s/YF5D3RRvmVXNJ_Njsa1Txw" target="_blank" rel="noopener noreferrer">批量执行Redis命令的四种方式！</a></p><p><a href="https://mp.weixin.qq.com/s/hmO2BKuMMU8ZPxW0lj9ZHw" target="_blank" rel="noopener noreferrer">阿里面试：设计一个大并发、大数据的系统架构，说说设计思路</a></p><p><a href="https://mp.weixin.qq.com/s/mspeViqHosmh4kUI8S8ajA" target="_blank" rel="noopener noreferrer">码哥字节 124 篇优秀文章精选</a></p><p><a href="https://mp.weixin.qq.com/s/vzbLWE4JteqjkOFJwcgRhg" target="_blank" rel="noopener noreferrer">Kafka性能篇：为何Kafka这么&quot;快&quot;</a></p><p><a href="https://mp.weixin.qq.com/s/z4VjDaDDbspFz1rIBwazIA" target="_blank" rel="noopener noreferrer">Redis 核心篇：唯快不破的秘密</a></p><p><a href="https://mp.weixin.qq.com/s/NU-W6rpwH-6_RQnSgbfZqQ" target="_blank" rel="noopener noreferrer">链路追踪落地过程中的挑战与解决方案</a></p><p><a href="https://mp.weixin.qq.com/s/TbxisH1zzE58u7YoRi04yA" target="_blank" rel="noopener noreferrer">美团面试：Sentinel底层滑动时间窗限流算法怎么实现的</a></p><p><a href="https://mp.weixin.qq.com/s/sMeLfLachYpUq261usr4tQ" target="_blank" rel="noopener noreferrer">字节二面：Spring Boot Redis 可重入分布式锁实现原理</a></p><p><a href="https://mp.weixin.qq.com/s/nJeRvz7jb4i2eXzc4vpdvw" target="_blank" rel="noopener noreferrer">纠正误区：这才是 SpringBoot Redis 分布式锁的正确实现方式</a></p><p><a href="https://mp.weixin.qq.com/s/W5vbjWMG86zEca3CPvAadg" target="_blank" rel="noopener noreferrer">分库分表的 21 条法则，hold 住！</a></p><p><a href="https://mp.weixin.qq.com/s/DLmXspbokYhQ-j5tLnUMgw" target="_blank" rel="noopener noreferrer">腾讯二面：epoll性能那么高，为什么</a></p><h2 class="anchor anchorWithStickyNavbar_B0by" id="-前端相关">📒 前端相关<a href="#-前端相关" class="hash-link" aria-label="Direct link to 📒 前端相关" title="Direct link to 📒 前端相关">​</a></h2><p><a href="https://mp.weixin.qq.com/s/ZkMc3-T0swxjJ4yujp1R1w" target="_blank" rel="noopener noreferrer">扩展你的前端知识库，毫无废话！</a></p><p><a href="https://mp.weixin.qq.com/s/lRzS_ZoJhzHmuOx0HCDTnw" target="_blank" rel="noopener noreferrer">TypeScript 5.4 beta: NoInfer 类型、闭包类型分析优化、条件类型判断优化等</a></p><p><a href="https://mp.weixin.qq.com/s/48cn-JU3uCZkpsi30cloiQ" target="_blank" rel="noopener noreferrer">升级到 React 18 的经验和教训</a></p></div><footer class="row docusaurus-mt-lg"></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/frontend-weekly/2024/page/2"><div class="pagination-nav__label">Older Entries</div></a></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Blog</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/frontend-weekly/2024">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/garfield-dev-team/Garfield-cli" target="_blank" rel="noopener noreferrer" class="footer__link-item">Garfield-cli 前端工程化<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/Jiacheng787/Garfield-utils" target="_blank" rel="noopener noreferrer" class="footer__link-item">NPM 工程化规范<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/Jiacheng787/React-zero-to-one" target="_blank" rel="noopener noreferrer" class="footer__link-item">React 从零到一工程化指北<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/Jiacheng787/go-by-example" target="_blank" rel="noopener noreferrer" class="footer__link-item">Golang 学习<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/Jiacheng787/Bytedance-interview" target="_blank" rel="noopener noreferrer" class="footer__link-item">面试内容汇总<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Garfield Dev Team. Built with Docusaurus. Deploys on GitHub Pages.</div></div></div></footer></div>
<script src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/js/runtime~main.f604be39.js"></script>
<script src="https://frontend-weekly.oss-cn-hangzhou.aliyuncs.com/assets/js/main.3f218b19.js"></script>
</body>
</html>